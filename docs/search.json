[
  {
    "objectID": "Pages/schedule.html",
    "href": "Pages/schedule.html",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Note\n\n\n\nThis page will be updated as we progress through the quarter; please check back regularly for updates!\n\n\n\n\n\n\n\n\nNote\n\n\n\nPlease try to complete the readings before coming to the specified lecture/starting the specified lab.\n\n\n\n\n\n\n\n\nTextbook Abbreviations and Emoji Meanings\n\n\n\n\nR4DS = R for Data Science\nI2R = An Introduction to R\nIMS = Introduction to Modern Statistics, 2nd Ed.\n💻 = Lab\n🧑‍🏫 = Lecture\n📖 = Textbook Reading\n📄 = Paper Reading\n\n\n\n\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n  \n  \n    \n      WEEK\n      DATE\n      READING\n      TOPIC\n      MATERIALS\n    \n  \n  \n    1\n\nMon, Apr 1\nOptional Reading: \n📖 R4DS, Chapter 2: Workflow basics \n📖 R4DS, Chapter 27: A field guide to base R \n📖 I2R, Chapter 2: Some R Basics \n📖 I2R, Chapter 3: Data in R \n\n💻 Lab00: Intro to R and Dataframes\n\n\nIntro to R: (click here)\nIntro to Dataframes: (click here)\n\n\n    \nTue, Apr 2\n📖 R4DS, 1.2: First Steps \n📖 IMS, 1.2.2: Types of Variables \n\n🧑‍🏫 Lec01: Intro to Datascience\n\n🛝 Lec00 Slides\n🛝 Lec01 Slides\n\n    \nThu, Apr 4\n📖 R4DS, Chapter 5: Data tidying \n📖 R4DS, Chapter 3: Data transformation \n📄 Hadley Wichkam Tidy Data, Journal of Statistical Software (2014) \n\n🧑‍🏫 Lec02: Tidy Data\n\n🛝 Lec02 Slides\n\n    2\n\nMon, Apr 8\n📖 R4DS, Chapter 19: Joins \n\n💻 Lab01: Tidy Data and Databases\n\n\n    \nTue, Apr 9\n📖 R4DS, Chapter 1: Data visualization \n📖 R4DS, Chapter 9: Layers \n📄 Hadley Wichkam A Layered Grammar of Graphics, Journal of Computational and Graphical Statistics (2010) \n\n🧑‍🏫 Lec03: Graphics, Part I\n\n🛝 Lec03 Slides\n\n    \nWed, Apr 10\n\n\nLab01 Due Extended to Friday\n\n    \nThu, Apr 11\n📖 R4DS, Chapter 11: Communication \n📖 Chapters 2 - 5 of Fundamentals of Data Visualization, by Claus Wilke \n📖  IMS, Chapter 6: Applications: Explore\n\n🧑‍🏫 Lec04: Graphics, Part II\n\n🛝 Lec04 Slides\n\n    \nSun, Apr 14\n\n\nHomework 01 Due\n\n    3\n\nMon, Apr 15\n\n💻 Lab02: Statistical Visualizations\n\n\n    \nTue, Apr 16\n📖 R4DS, Chapter 10: Exploratory Data Analysis \n\n🧑‍🏫 Lec05: Exploratory Data Analysis\n\n🛝 Lec05 Slides\nLab02 Partial Walkthrough\n\n    \nWed, Apr 17\n\n\nLab02 Due Extended to Friday\n\n    \nThu, Apr 18\n📖 IMS, Chapter 2: Study Design \n\n🧑‍🏫 Lec06: Sampling Techniques and Study Design\n\n🛝 Lec06 Slides\n\n    \nSun, Apr 21\n\n\nMini-Project 01 Due\n\n    4\n\nMon, Apr 22\n\n💻 Lab03: Review for ICA01 (NOT TURNED IN)\n\n\n    \nTue, Apr 23\n\n🧑‍🏫 Lec07: Regular Expressions Prep for ICA01\n\n\n    \nWed, Apr 24\n\n\n\n    \nThu, Apr 25\n\n🧑‍🏫 In-Class Assessment 01\n\n\n    5\n\nMon, Apr 29\n📖 R4DS, Chapter 14: Strings \n📖 R4DS, Chapter 15: Regular expressions \n\n💻 Lab04: RegEx (Tentative)\n\n\n    \nTue, Apr 30\n\n🧑‍🏫 Lec09: Statistics, Part I\n\n\n    \nWed, May 1\n\n\nLab04 Due\n\n    \nThu, May 2\n📖 Selected Chapters from IMS: “Statistical Inference”\n\n🧑‍🏫 Lec10: Statistics, Part II\n\n\n    \nSun, May 5\n\n\nHomework 02 Due\n\n    6\n\nMon, May 6\n\n💻 Lab05: Optimization\n\n\n    \nTue, May 7\n📖 Selected Chapters from IMS: “Regression Modeling”\n\n🧑‍🏫 Lec11: Introduction to Statistical Modeling and Regression\n\n\n    \nWed, May 8\n\n\nLab05 Due\n\n    \nThu, May 9\n📖 Selected Chapters from IMS: “Regression Modeling”\n\n🧑‍🏫 Lec12: More Regression\n\n\n    \nSun, May 12\n\n\nMini-Project 02 Due\n\n    7\n\nMon, May 13\n\n💻 Lab06: Review of Linear Algebra\n\n\n    \nTue, May 14\n📖 TBD\n\n🧑‍🏫 Lec13: PCA\n\n\n    \nWed, May 15\n\n\nLab06 Due\n\n    \nThu, May 16\n📖 TBD\n\n🧑‍🏫 Lec14: Kernel Density Estimation\n\n\n    \nSun, May 19\n\n\nHomework 03 Due\n\n    8\n\nMon, May 20\n\n💻 Lab07: PCA/KDE\n\n\n    \nTue, May 21\n📖 TBD\n\n🧑‍🏫 Lec15: Review for ICA02\n\n\n    \nWed, May 22\n\n\nLab07 Due\n\n    \nThu, May 23\n\n🧑‍🏫 In-Class Assessment 02\n\n\n    9\n\nMon, May 27\n\nHOLIDAY: No Lab or Sections\n\n\n    \nTue, May 28\n📖 TBD\n\n🧑‍🏫 Lec17: Nonparametrics\n\n\n    \nWed, May 29\n\n\n\n    \nThu, May 30\n📖 TBD\n\n🧑‍🏫 Lec18: Classification\n\n\n    \nSun, Jun 2\n\n\nMini-Project 03 Due\n\n    10\n\nMon, Jun 3\n\n💻 Lab08: TBD\n\n\n    \nTue, Jun 4\n📖 TBD\n\n🧑‍🏫 Lec19: Clustering\n\n\n    \nWed, Jun 5\n\n\nLab09 Due\n\n    \nThu, Jun 6\n📖 R4DS, Chapter 18: Missing Values \nAdditional Readings to be posted\n\n🧑‍🏫 Lec20: Missingness\n\n\n    Finals\n\nTue, Jun 11\n\n\nFinal Project Due"
  },
  {
    "objectID": "Pages/schedule.html#course-schedule",
    "href": "Pages/schedule.html#course-schedule",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Note\n\n\n\nThis page will be updated as we progress through the quarter; please check back regularly for updates!\n\n\n\n\n\n\n\n\nNote\n\n\n\nPlease try to complete the readings before coming to the specified lecture/starting the specified lab.\n\n\n\n\n\n\n\n\nTextbook Abbreviations and Emoji Meanings\n\n\n\n\nR4DS = R for Data Science\nI2R = An Introduction to R\nIMS = Introduction to Modern Statistics, 2nd Ed.\n💻 = Lab\n🧑‍🏫 = Lecture\n📖 = Textbook Reading\n📄 = Paper Reading\n\n\n\n\n\n\n\n\n\n  \n    \n    \n    \n    \n    \n  \n  \n    \n      WEEK\n      DATE\n      READING\n      TOPIC\n      MATERIALS\n    \n  \n  \n    1\n\nMon, Apr 1\nOptional Reading: \n📖 R4DS, Chapter 2: Workflow basics \n📖 R4DS, Chapter 27: A field guide to base R \n📖 I2R, Chapter 2: Some R Basics \n📖 I2R, Chapter 3: Data in R \n\n💻 Lab00: Intro to R and Dataframes\n\n\nIntro to R: (click here)\nIntro to Dataframes: (click here)\n\n\n    \nTue, Apr 2\n📖 R4DS, 1.2: First Steps \n📖 IMS, 1.2.2: Types of Variables \n\n🧑‍🏫 Lec01: Intro to Datascience\n\n🛝 Lec00 Slides\n🛝 Lec01 Slides\n\n    \nThu, Apr 4\n📖 R4DS, Chapter 5: Data tidying \n📖 R4DS, Chapter 3: Data transformation \n📄 Hadley Wichkam Tidy Data, Journal of Statistical Software (2014) \n\n🧑‍🏫 Lec02: Tidy Data\n\n🛝 Lec02 Slides\n\n    2\n\nMon, Apr 8\n📖 R4DS, Chapter 19: Joins \n\n💻 Lab01: Tidy Data and Databases\n\n\n    \nTue, Apr 9\n📖 R4DS, Chapter 1: Data visualization \n📖 R4DS, Chapter 9: Layers \n📄 Hadley Wichkam A Layered Grammar of Graphics, Journal of Computational and Graphical Statistics (2010) \n\n🧑‍🏫 Lec03: Graphics, Part I\n\n🛝 Lec03 Slides\n\n    \nWed, Apr 10\n\n\nLab01 Due Extended to Friday\n\n    \nThu, Apr 11\n📖 R4DS, Chapter 11: Communication \n📖 Chapters 2 - 5 of Fundamentals of Data Visualization, by Claus Wilke \n📖  IMS, Chapter 6: Applications: Explore\n\n🧑‍🏫 Lec04: Graphics, Part II\n\n🛝 Lec04 Slides\n\n    \nSun, Apr 14\n\n\nHomework 01 Due\n\n    3\n\nMon, Apr 15\n\n💻 Lab02: Statistical Visualizations\n\n\n    \nTue, Apr 16\n📖 R4DS, Chapter 10: Exploratory Data Analysis \n\n🧑‍🏫 Lec05: Exploratory Data Analysis\n\n🛝 Lec05 Slides\nLab02 Partial Walkthrough\n\n    \nWed, Apr 17\n\n\nLab02 Due Extended to Friday\n\n    \nThu, Apr 18\n📖 IMS, Chapter 2: Study Design \n\n🧑‍🏫 Lec06: Sampling Techniques and Study Design\n\n🛝 Lec06 Slides\n\n    \nSun, Apr 21\n\n\nMini-Project 01 Due\n\n    4\n\nMon, Apr 22\n\n💻 Lab03: Review for ICA01 (NOT TURNED IN)\n\n\n    \nTue, Apr 23\n\n🧑‍🏫 Lec07: Regular Expressions Prep for ICA01\n\n\n    \nWed, Apr 24\n\n\n\n    \nThu, Apr 25\n\n🧑‍🏫 In-Class Assessment 01\n\n\n    5\n\nMon, Apr 29\n📖 R4DS, Chapter 14: Strings \n📖 R4DS, Chapter 15: Regular expressions \n\n💻 Lab04: RegEx (Tentative)\n\n\n    \nTue, Apr 30\n\n🧑‍🏫 Lec09: Statistics, Part I\n\n\n    \nWed, May 1\n\n\nLab04 Due\n\n    \nThu, May 2\n📖 Selected Chapters from IMS: “Statistical Inference”\n\n🧑‍🏫 Lec10: Statistics, Part II\n\n\n    \nSun, May 5\n\n\nHomework 02 Due\n\n    6\n\nMon, May 6\n\n💻 Lab05: Optimization\n\n\n    \nTue, May 7\n📖 Selected Chapters from IMS: “Regression Modeling”\n\n🧑‍🏫 Lec11: Introduction to Statistical Modeling and Regression\n\n\n    \nWed, May 8\n\n\nLab05 Due\n\n    \nThu, May 9\n📖 Selected Chapters from IMS: “Regression Modeling”\n\n🧑‍🏫 Lec12: More Regression\n\n\n    \nSun, May 12\n\n\nMini-Project 02 Due\n\n    7\n\nMon, May 13\n\n💻 Lab06: Review of Linear Algebra\n\n\n    \nTue, May 14\n📖 TBD\n\n🧑‍🏫 Lec13: PCA\n\n\n    \nWed, May 15\n\n\nLab06 Due\n\n    \nThu, May 16\n📖 TBD\n\n🧑‍🏫 Lec14: Kernel Density Estimation\n\n\n    \nSun, May 19\n\n\nHomework 03 Due\n\n    8\n\nMon, May 20\n\n💻 Lab07: PCA/KDE\n\n\n    \nTue, May 21\n📖 TBD\n\n🧑‍🏫 Lec15: Review for ICA02\n\n\n    \nWed, May 22\n\n\nLab07 Due\n\n    \nThu, May 23\n\n🧑‍🏫 In-Class Assessment 02\n\n\n    9\n\nMon, May 27\n\nHOLIDAY: No Lab or Sections\n\n\n    \nTue, May 28\n📖 TBD\n\n🧑‍🏫 Lec17: Nonparametrics\n\n\n    \nWed, May 29\n\n\n\n    \nThu, May 30\n📖 TBD\n\n🧑‍🏫 Lec18: Classification\n\n\n    \nSun, Jun 2\n\n\nMini-Project 03 Due\n\n    10\n\nMon, Jun 3\n\n💻 Lab08: TBD\n\n\n    \nTue, Jun 4\n📖 TBD\n\n🧑‍🏫 Lec19: Clustering\n\n\n    \nWed, Jun 5\n\n\nLab09 Due\n\n    \nThu, Jun 6\n📖 R4DS, Chapter 18: Missing Values \nAdditional Readings to be posted\n\n🧑‍🏫 Lec20: Missingness\n\n\n    Finals\n\nTue, Jun 11\n\n\nFinal Project Due"
  },
  {
    "objectID": "Pages/schedule.html#course-calendar",
    "href": "Pages/schedule.html#course-calendar",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Course Calendar",
    "text": "Course Calendar"
  },
  {
    "objectID": "Pages/materials.html",
    "href": "Pages/materials.html",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Acknowledgements: Special thanks to previous instructors Dr. Trevor Ruiz, Dr. Alex Franks, and Dr. Laura Baracaldo for graciously providing material and guidance for this course.\n\n\n\nWeek 1 (4/1 - 4/7)\n\n\nReadings:\n\nFor Tuesday:\n\nR4DS Chapter 2: Workflow: basics\nR4DS Chapter 27: A field guide to base R\n\nFor Thursday:\n\nHadley Wickham Tidy Data, Journal of Statistical Software (2014)\nR4DS Chapter 5: Data tidying\nR4DS Chapter 3: Data transformation\n\nR4DS Chapter 19: Joins\n\n\nOptional Reading:\n\nI2R, Chapter 2: Some R basics\nI2R, Chapter 3: Data in R\nLDS Chapter 2: Questions and Data Scope\nTidyverse Official Site\n\nLectures:\n\nTues. Lecture 1: Course Introduction; Intro to Data\nThurs. Lecture 2: Data, Part II\n\nLab:\nThere is no required lab for this week, as we will not be having any Sections on Monday. However, please keep in mind the following:\n\nIf you have never programmed in R before, please read Chapter 2: Some R basics and Chapter 3: Data in R, from “An Introduction to R”, and Chapters 2 and 27 from R4DS.\n\nThis Lab provides a summary of important information about the basics of programming in R.\n\nIf you have some exposure to programming in R (or have already read Chapters 2 and 3 from I2R), but would like more practice with dataframes, we encourage you to complete the following lab: [Click Here]\n\nPlease note that, by virtue of being prerequisite, these concepts and topics are potentially testable on In-Class Assignments (and are also crucial for success in our future PSTAT 100 endeavors!).\n\n\n\n\n\n\nTextbook Abbreviations\n\nR4DS: R for Data Science\nLDS: Learning Data Science\nI2R: An Introduction to R\n\n\n\n\n\n\n\n\n\n\n\nWeek\nTopic\nLab\nHomework\nProject\n\n\n\n\n1\nIntroduction to Data\n\n\n\n\n\n2\nStatistical Graphics\nL1\nHW01\n\n\n\n3\nExploring and Cleaning Data\nL2\n\nMP01\n\n\n4\nSampling Techniques\nL3\n\n\n\n\n5\nMissingness, and KDE\nL4\nHW02\n\n\n\n6\nPrincipal Components Analysis, and an Intro to Statistics\nL5\n\nMP02\n\n\n7\nIntroduction to Statistical Modeling\nL6\nHW03\n\n\n\n8\nRegression\nL7\n\n\n\n\n9\nMore Regression\n\n\nMP03\n\n\n10\nClassification and Clustering\nL8\n\n\n\n\n11\nFinals\n\n\nFinal Proj.\n\n\n\n\nL: lab\nHW: Homework\nMP: Mini-Project"
  },
  {
    "objectID": "Pages/oh.html",
    "href": "Pages/oh.html",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Please note that Office Hours during Week 1 are different that Office Hours taking place throughout the rest of the quarter!"
  },
  {
    "objectID": "Pages/oh.html#course-calendar",
    "href": "Pages/oh.html#course-calendar",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Please note that Office Hours during Week 1 are different that Office Hours taking place throughout the rest of the quarter!"
  },
  {
    "objectID": "Pages/oh.html#weekly-office-hours",
    "href": "Pages/oh.html#weekly-office-hours",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Weekly Office Hours",
    "text": "Weekly Office Hours\n\nEthan:\n\nTuesdays, 4:30pm - 5:30pm over Zoom\nFridays, 2 - 3:30pm in ARTS 1349\n\nEthan:\n\nTuesdays, 4:30pm - 5:30pm over Zoom\nFridays, 2 - 3:30pm in ARTS 1349"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSTAT 100: Spring 2024",
    "section": "",
    "text": "PSTAT 100\nData Science Concepts and Analysis\nSpring 2024; Instructor: Ethan P. Marzban\n\n\nWelcome to the official course site for PSTAT 100, Spring 2024 with instructor Ethan P. Marzban. Here, you will find all relevant course material including lecture material, homework, labs, projects, and additional resources.\n\n\n\nQuick Navigation\n\n\n\nFor the syllabus and important course policies; navigate to the Policies page\nFor a calendar of all weekly course happenings (including lectures, sections, and Office Hours), along with the Weekly Course Schedule (containing links to all readings), navigate to the Course Schedule/Calendar page\nFor information on the Course Staff (including information about office hours beginning in week 2) navigate to the Course Staff page\n\n\n\nThe instructor would like to acknowledge Drs. Trevor Ruiz, Alexander Franks, and Laura Baracaldo for graciously providing material and support for this course."
  },
  {
    "objectID": "Labs/Lab00/df_basics.html",
    "href": "Labs/Lab00/df_basics.html",
    "title": "Lab 00: Dataframe Basics",
    "section": "",
    "text": "Tip\n\n\n\nThis lab is long! Use the floating table of contents (at the top-right of the screen) to jump to sections as needed."
  },
  {
    "objectID": "Labs/Lab00/df_basics.html#lab-objectives",
    "href": "Labs/Lab00/df_basics.html#lab-objectives",
    "title": "Lab 00: Dataframe Basics",
    "section": "Lab Objectives",
    "text": "Lab Objectives\nThis lab covers the following topics:\n\nBasics of dataframes in R"
  },
  {
    "objectID": "Labs/Lab00/df_basics.html#relevant-textbook-chapterssections",
    "href": "Labs/Lab00/df_basics.html#relevant-textbook-chapterssections",
    "title": "Lab 00: Dataframe Basics",
    "section": "Relevant Textbook Chapters/Sections:",
    "text": "Relevant Textbook Chapters/Sections:\n\nPortions of Chapter 27 in R4DS"
  },
  {
    "objectID": "Labs/Lab00/df_basics.html#using-slicingindexing",
    "href": "Labs/Lab00/df_basics.html#using-slicingindexing",
    "title": "Lab 00: Dataframe Basics",
    "section": "Using Slicing/Indexing",
    "text": "Using Slicing/Indexing\nIf we have a dataframe called df, the command df[i, j] extracts the entry at the ith row and the jth column. For example:\n\nmy_df[1, 2]\n\n[1] \"hello\"\n\n\nWe can select multiple columns and/or rows by passing in a vector of values on either side of the comma:\n\nmy_df[c(1, 2), 2]\n\n[1] \"hello\" \"happy\"\n\n\nIf we want to extract all elements of row i, we can simply leave the column index blank:\n\nmy_df[1, ]\n\n  col1  col2\n1    2 hello\n\n\nIf we want to extract all elements of column j, we can simply leave the row index blank:\n\nmy_df[, 2]\n\n[1] \"hello\" \"happy\" \"world\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is important to note that rows and/or columns extracted from dataframes are stored as vectors:\n\nis.vector(my_df[,2])\n\n[1] TRUE\n\n\n\n\nA useful thing to note is that the synax a:b, where a and b are integers satisfying a &lt; b, generates the set of consecutive integers starting at a and ending at b:\n\n3:10\n\n[1]  3  4  5  6  7  8  9 10\n\n\nAnother way to generate sequences in R is to use the seq() function, which allows you to specify a start value, a stop value, and either the amount of space between successive values in the sequence or the number of elements to be included in the sequence:\n\nseq(0, 1, by = 0.1)\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\nseq(0, 1, length = 11)\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\nseq(0, 1, length = 10)\n\n [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n [8] 0.7777778 0.8888889 1.0000000"
  },
  {
    "objectID": "Labs/Lab00/df_basics.html#using-column-names",
    "href": "Labs/Lab00/df_basics.html#using-column-names",
    "title": "Lab 00: Dataframe Basics",
    "section": "Using Column Names",
    "text": "Using Column Names\nWe can also access individual columns of a dataframe by using the $ operator, followed by the name of the column. For example:\n\nmy_df$col1\n\n[1] 2 4 6\n\n\nWe can further subset by indexing on the selected column (again, remember that columns extracted from a dataframe are stored as vectors):\n\nmy_df$col1[2:3]\n\n[1] 4 6\n\n\nIf we want to select multiple columns by name, we cannot use the $ operator but must instead use the select() function from the dplyr package (contained in the tidyverse):\n\nselect(my_df, c(col1, col2))\n\n  col1  col2\n1    2 hello\n2    4 happy\n3    6 world"
  },
  {
    "objectID": "Labs/Lab00/df_basics.html#updatingreplacing-values",
    "href": "Labs/Lab00/df_basics.html#updatingreplacing-values",
    "title": "Lab 00: Dataframe Basics",
    "section": "Updating/Replacing Values",
    "text": "Updating/Replacing Values\nTo replace an already-existing element in a dataframe with another value, we can access the value and the use the variable assignment operator (&lt;-) to overwrite the previous value. For example:\n\nmy_df[1, 2] &lt;- \"greetings\"\nmy_df\n\n  col1      col2\n1    2 greetings\n2    4     happy\n3    6     world"
  },
  {
    "objectID": "Labs/Lab00/df_basics.html#adding-columns",
    "href": "Labs/Lab00/df_basics.html#adding-columns",
    "title": "Lab 00: Dataframe Basics",
    "section": "Adding Columns",
    "text": "Adding Columns\nTo add a column, simply use the $ syntax to pretend you were accessing the column (even though it doesn’t exist yet), and then use the variable assignment operator to pass in a set of values:\n\nmy_df$col3 &lt;- c(\"red\", \"green\", \"blue\")\nmy_df\n\n  col1      col2  col3\n1    2 greetings   red\n2    4     happy green\n3    6     world  blue\n\n\nWhat happens if we try and add a column that has more values than rows in our dataframe? Well, let’s see:\n\nmy_df$col4 &lt;- c(TRUE, FALSE, TRUE, FALSE)\n\nError in `$&lt;-.data.frame`(`*tmp*`, col4, value = c(TRUE, FALSE, TRUE, : replacement has 4 rows, data has 3\n\n\nSo, this is something important to note: when adding a column to a dataframe, you must ensure that the number of values you are adding is the same as the number of rows in the dataframe.\nSay we really wanted to add a fourth colunmn to our my_df dataframe, with the values c(TRUE, FALSE, TRUE, FALSE). We could simply add a fourth row of missing values (NA) to the already-existing dataframe, and then append the column:\n\nmy_df[4,] &lt;- c(NA, NA, NA)\nmy_df$col4 &lt;- c(TRUE, FALSE, TRUE, FALSE)\nmy_df\n\n  col1      col2  col3  col4\n1    2 greetings   red  TRUE\n2    4     happy green FALSE\n3    6     world  blue  TRUE\n4   NA      &lt;NA&gt;  &lt;NA&gt; FALSE\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThere are pros and cons to doing this. On the one hand, we’ve successfully added all the values we wanted to into our new column. However, we have done so at the cost of injecting missingness into our data. Depending on what we plan to do with the dataframe this may or may not be a big deal- so, just think critically before doing something like this."
  },
  {
    "objectID": "Labs/Lab00/df_basics.html#changing-column-names",
    "href": "Labs/Lab00/df_basics.html#changing-column-names",
    "title": "Lab 00: Dataframe Basics",
    "section": "Changing Column Names",
    "text": "Changing Column Names\nThe column names of our my_df dataframe are pretty uninformative. Let’s see if we can give the columns more interesting names!\nTo access the column names of a dataframe, we can use either names() or colnames():\n\ncolnames(my_df)\n\n[1] \"col1\" \"col2\" \"col3\" \"col4\"\n\n\nTo rename our columns, we can simply assign (using the variable assignment operator) a new list of names:\n\ncolnames(my_df) &lt;- c(\"numbers\", \"words\", \"colors\", \"booleans\")\nmy_df\n\n  numbers     words colors booleans\n1       2 greetings    red     TRUE\n2       4     happy  green    FALSE\n3       6     world   blue     TRUE\n4      NA      &lt;NA&gt;   &lt;NA&gt;    FALSE\n\n\nWe can, if we like, do something similar to assign names to the rows of our dataframe:\n\nrownames(my_df) &lt;- c(\"row1\", \"row2\", \"row3\", \"row4\")\nmy_df\n\n     numbers     words colors booleans\nrow1       2 greetings    red     TRUE\nrow2       4     happy  green    FALSE\nrow3       6     world   blue     TRUE\nrow4      NA      &lt;NA&gt;   &lt;NA&gt;    FALSE"
  },
  {
    "objectID": "Labs/Lab00/intro2r.html",
    "href": "Labs/Lab00/intro2r.html",
    "title": "Lab 00: Introduction to R",
    "section": "",
    "text": "Tip\n\n\n\nThis lab is long! Use the floating table of contents (at the top-right of the screen) to jump to sections as needed."
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#lab-objectives",
    "href": "Labs/Lab00/intro2r.html#lab-objectives",
    "title": "Lab 00: Introduction to R",
    "section": "Lab Objectives",
    "text": "Lab Objectives\nThis lab covers the following topics:\n\nBasics of coding in R"
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#relevant-textbook-chapterssections",
    "href": "Labs/Lab00/intro2r.html#relevant-textbook-chapterssections",
    "title": "Lab 00: Introduction to R",
    "section": "Relevant Textbook Chapters/Sections:",
    "text": "Relevant Textbook Chapters/Sections:\n\nVarious chapters of I2R\nPortions of Chapter 2 in R4DS\nPortions of Chapter 27 in R4DS"
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#r-basics",
    "href": "Labs/Lab00/intro2r.html#r-basics",
    "title": "Lab 00: Introduction to R",
    "section": "R Basics",
    "text": "R Basics\nA mentioned previously, the programming language we will be using this quarter is R. Developed in the 1990s at Bell Labs, it was built upon the S language, with the crucial benefit of being freely available to the public.\nR understand many of the basic mathematical operations we use on paper:\n\n\n\nOperation\nR Symbol\nExample\n\n\n\n\nAddition\n+\n2 + 3\n\n\nSubtraction\n-\n2 - 3\n\n\nMultiplication\n*\n2 * 3\n\n\nExponentiation\n^\n2 ^ 3\n\n\nDivision\n/\n2 / 3\n\n\n\nFor example:\n\n((2 + 3) / 4) ^ 5\n\n[1] 3.051758\n\n\nNote: like most programming languages, R obeys the order of operations:\n\nParentheses\nExponentiation\nMultiplication\nDivision\nAddition\nSubtraction\n\nThe variable assignment operator in R (i.e. the symbol we use to assign a value to a variable) is &lt;-:\n\nx &lt;- 2\nx\n\n[1] 2\n\n\n\n\n\n\n\n\nTip\n\n\n\nTechnically, using = will also work for variable assignment:\n\ny = 2\ny\n\n[1] 2\n\n\nHowever, when programming in R, it is customary to use the &lt;- operator instead.\n\n\nThere are a couple of restrictions on what we can name variables in R:\n\nVariable names cannot start with a number (but they can contain numbers). So 2var is not a valid variable name, whereas var2 is.\nVariable names cannot start with a period (but they can contain periods). So .my_var is not a valid variable name but my.var is.\nVariable names cannot include special characters (e.g. +, *, etc.) anywhere. For instance, *myvar is not a valid variable name.\n\n\n\n\n\n\n\nNote for Python Users\n\n\n\nIf you are a Python user, you might not be used to using periods in variable names (since, in Python, periods typically deliniate the start of a method). In R, periods do not have any correspondence with methods or functions, so feel free to use them in your variable names!"
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#data-types-and-data-structures",
    "href": "Labs/Lab00/intro2r.html#data-types-and-data-structures",
    "title": "Lab 00: Introduction to R",
    "section": "Data Types and Data Structures",
    "text": "Data Types and Data Structures\nWe can think of data types as the fundamental classes to which objects belong. There are 4 main data types in R:\n\ndouble (aka numeric; refers to real numbers)\ninteger\ncharacter (aka string)\nlogical (aka boolean)\n\nWe can extract the particular data type of an object using the typeof() function:\n\ntypeof(1)\n\n[1] \"double\"\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(\"hello world\")\n\n[1] \"character\"\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n\nA note on booleans: in R, there are only two logical objects: TRUE (which is equivalent to T) and FALSE (which is equivalent to F). Pay close attention to the capitalization: True is NOT a valid logical type object in R (even though it is in Python)!\n\n\n\n\n\n\nNote\n\n\n\nThere are actually two more data types in R: \"complex\" and \"raw\". You may want to familiarize yourself with the \"complex\" type (which deals with complex numbers), but it is highly unlikely you will ever encounter the \"raw\" type in the wild.\n\n\nIndividual R objects can be collectively arranged into larger, more complex data structures. There are 6 main data structures in R:\n\nscalars: scalar values (i.e. single values)\nvectors: sequence of values, that must all be of the same type\nmatrices: rows and columns of values\narrays: rows, columns, and layers of values (you can think of these as essentially matrices stacked on top of each other, or, more mathematically, as akin to tensors), all of the same type\nlists: rows, columns, and layers of values, potentially of different types\nfactors: sequences of categorical values\ndataframes: rows and columns of values, potentially of different types\n\nAs you can see, there are some pairs of data structures that appear similar, but differ in the key aspect of whether or not they allow different data types. We will revisit this notion in a bit.\n\nVectors and Matrices\nFirst, let’s talk about how to create vectors in R. (In many ways, vectors form the fundamental unit in R.) The easiest way is to use the combine function, c():\n\nc(1, 2, \"hello\", \"world\")\n\n[1] \"1\"     \"2\"     \"hello\" \"world\"\n\n\n\n\n\n\n\n\nImportant\n\n\n\nDon’t forget the c when creating vectors! Simply listing the elements of a vector within a set of parentheses in R will result in an error:\n\n(1, 2, \"hello\", \"world\")\n\nError: &lt;text&gt;:1:3: unexpected ','\n1: (1,\n      ^\n\n\n\n\nTo create a matrix, we use the matrix() function:\n\nmatrix(c(1, 2, 3, 4), \n       nrow = 2,\n       byrow = T)\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\n\nNote the specification of byrow = T: this simply tells R to populate the elements of the matrix by rows. In contrast, we could have specified byrow = F:\n\nmatrix(c(1, 2, 3, 4), \n       nrow = 2,\n       byrow = F)\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n\nNow, let’s demonstrate what is meant by the fact that all objects in a matrix must be of the same type. Specifically, let’s try and create a matrix from the elements 1, 2, \"hello\", \"world\":\n\nmatrix(c(1, 2, \"hello\", \"world\"),\n       nrow = 2,\n       byrow = F)\n\n     [,1] [,2]   \n[1,] \"1\"  \"hello\"\n[2,] \"2\"  \"world\"\n\n\nNotice that R has automatically coerced all of the elements to be characters (even though the numbers 1 and 2 were originally specified using the double type)!\n\n\nDataframes\nIndeed, this is one of the motivating factors for using dataframes, instead of matrices. To create a dataframe from scratch, we use the data.frame() function, and specify the columns of the data frame:\n\ndata.frame(\n  c(1, 2),\n  c(\"hello\", \"world\")\n)\n\n  c.1..2. c..hello....world..\n1       1               hello\n2       2               world\n\n\nA couple of things to note:\n\nWe’ve managed to preserve the original data types of our objects.\nBy default, dataframes have column names (and the default names that R creates are pretty sucky…)\n\nLet’s explicitly specify our column names:\n\ndata.frame(\n  col1 = c(1, 2),\n  col2 = c(\"hello\", \"world\")\n)\n\n  col1  col2\n1    1 hello\n2    2 world\n\n\nIf we really wanted to, we could even specify row names:\n\ndata.frame(\n  col1 = c(1, 2),\n  col2 = c(\"hello\", \"world\"),\n  row.names = c(\"row1\", \"row2\")\n)\n\n     col1  col2\nrow1    1 hello\nrow2    2 world\n\n\nWe’ve posted a separate lab covering even more operations on dataframes, which can be accessed here.\n\n\nFactors\nAs mentioned above, factors are ideal when encoding categorical data. Recall (from Lecture 01) that categorical variables can be further subdivided into nominal and ordinal variables; analagously, R has factors and ordered factors.\nAs a simple example:\n\nfav_cols &lt;- factor(\n  c(\"red\", \"green\", \"blue\", \"green\", \"yellow\")\n)\nfav_cols\n\n[1] red    green  blue   green  yellow\nLevels: blue green red yellow\n\n\nTo extract the levels of a factor (i.e. the categories), we use the levels() function:\n\nlevels(fav_cols)\n\n[1] \"blue\"   \"green\"  \"red\"    \"yellow\"\n\n\nIf we wanted to create an ordered factor, we can still use the factor() function but now pass in an additional argument that states ordered = T:\n\nmy_grades &lt;- factor(\n  c(\"A+\", \"A-\", \"A\", \"A-\"),\n  ordered = T,\n  levels = c(\"A+\", \"A\", \"A-\")\n)\n\nmy_grades\n\n[1] A+ A- A  A-\nLevels: A+ &lt; A &lt; A-"
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#functions",
    "href": "Labs/Lab00/intro2r.html#functions",
    "title": "Lab 00: Introduction to R",
    "section": "Functions",
    "text": "Functions\nThe syntax of a function call in R is of the form:\n\nfunc_name(arg1, arg2, ...)\n\nFor example, to compute the sum of a vector we can use the sum() function:\n\nsum(c(1, 3, 5, 7))\n\n[1] 16\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo access the help file for a function func_name, type ?func_name (replacing func_name with the actual name of the function) in an R console.\n\n\nTo define a function in R, we use the syntax\n\nfunc_name &lt;- function(arg1 = default1, arg2 = default2, ...) {\n  &lt;body of function&gt;\n}\n\nNote that we do not need to specify defaults for any of the arguments of a function. For example:\n\nnew_function &lt;- function(x, y = 1) {\n  return(x^2 + y^2)\n}\n\nnew_function(1, 2)  # should return 1^2 + 2^2; i.e. 5\n\n[1] 5\n\nnew_function(1)     # should return 1^2 + 1^2; i.e. 2\n\n[1] 2"
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#comparisons-and-control",
    "href": "Labs/Lab00/intro2r.html#comparisons-and-control",
    "title": "Lab 00: Introduction to R",
    "section": "Comparisons and Control",
    "text": "Comparisons and Control\nWe can use any of our standard mathematical comparisons in R.\n\n\n\nSymbol\nExample\nMeaning\n\n\n\n\n==\na == b\nIs a equal to b?\n\n\n&lt;=\na &lt;= b\nIs a less than or equal to b?\n\n\n&gt;=\na &lt;= b\nIs a greater than or equal to b?\n\n\n&lt;\na &lt; b\nIs a less than b?\n\n\n&gt;\na &gt; b\nIs a greater than b?\n\n\n!\n!p\nNegation of p\n\n\n|\np | q\nVectorized ‘or’: p or q\n\n\n&\np & q\nVectorized ‘and’: p and q\n\n\n\nNote that the result of a comparison is a vector of logicals, with TRUE in positions where the comparison holds and FALSE in positions where the comparison does not hold. For example:\n\nx &lt;- c(1, 2, 3)\ny &lt;- c(2, 1, 4)\n\nThe way we interpret this output is:\n\nThe first element of x was less than or equal to the first element of y\nThe second element of x was not less than or equal to the second element of y\nThe third element of x was less than or equal to the third element of y\n\nWe most often use the result of comparisons in conditional statements (aka control flow). Conditional statements in R are structured as follows:\n\nif(cond1) {\n  &lt;executes if cond1 is true&gt;\n} else if(cond2) {\n  &lt;executes if cond2 is true&gt;\n} ... else {\n  &lt;executes if none of the previous conditions are true&gt;\n}\n\nFor example:\n\nx &lt;- 15\n\nif(x &lt;= 10) {\n  print(\"x is small\")\n} else if (x &lt;= 20) {\n  print(\"x is moderate\")\n} else {\n  return(\"x is massive!\")\n}\n\n[1] \"x is moderate\"\n\n\nOne thing to note is that each of the conditions must be a scalar of length 1:\n\nx &lt;- c(15, 15)\n\nif(x &lt;= 10) {\n  print(\"x is small\")\n} else if (x &lt;= 20) {\n  print(\"x is moderate\")\n} else {\n  return(\"x is massive!\")\n}\n\nError in if (x &lt;= 10) {: the condition has length &gt; 1\n\n\nIf we want to control based on vector conditions, and we have only two cases to consider, we can use the ifelse() function. For example:\n\nx &lt;- c(2, 3, 4, 5, 6) \n\nifelse(x %% 2 == 0, \"even\", \"odd\")\n\n[1] \"even\" \"odd\"  \"even\" \"odd\"  \"even\""
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#loops",
    "href": "Labs/Lab00/intro2r.html#loops",
    "title": "Lab 00: Introduction to R",
    "section": "Loops",
    "text": "Loops\nIn R, there are three types of loops: for loops, while loops, and repeat loops. Since I hope you have already been exposed to loops I’ll bypass a detailed discussion of how they work, opting instead to simply highlight the R syntax of loops.\n\nfor-loops\nA for loops is ideal when you want to repeat a task a fixed number of times. For example:\n\nfor(k in 2:4) {\n  print(k)\n}\n\n[1] 2\n[1] 3\n[1] 4\n\n\nWe […]\n\nfor( k in 1:6) {\n  if(k %% 2 == 0) {\n    print(paste(k, \"is even\"))\n  } else {\n    print(paste(k, \"is odd\"))\n  }\n}\n\n[1] \"1 is odd\"\n[1] \"2 is even\"\n[1] \"3 is odd\"\n[1] \"4 is even\"\n[1] \"5 is odd\"\n[1] \"6 is even\"\n\n\n\n\nwhile- and repeat-loops\nThe remaining two types of loops in R (while and repeat loops) aren’t used as frequently as for loops, but I feel it prudent to at least mention their existence. Unlike for loops, while and repeat loops do not (necessarily) run for a fixed number of iterations - rather, they continue looping until a condition is met.\n\nFor example, to convert the first for loop above to a while loop, we could use\n\nk &lt;- 2\nwhile(k &lt;= 4) {\n  print(k)\n  k &lt;- k + 1\n}\n\n[1] 2\n[1] 3\n[1] 4\n\n\nWe could also convert the loop above to a repeat loop:\n\nk &lt;- 2\nrepeat {\n  if(k &gt; 4) {\n    break\n  } else {\n    print(k)\n    k &lt;- k + 1\n  }\n}\n\n[1] 2\n[1] 3\n[1] 4"
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#packages",
    "href": "Labs/Lab00/intro2r.html#packages",
    "title": "Lab 00: Introduction to R",
    "section": "Packages",
    "text": "Packages\nIn R, we use the term packages to refer to collections of functions and objects stored under a common name. (This is the equivalent of what is often referred to as a module, in Python).\nTo install a package in R, we use the syntax\n\ninstall.packages(\"&lt;package_name&gt;\")\n\nIf you try to install a package you have already installed, R will give you a warning message prompting you to either update the package or cancel your command.\nTo load a package into a document or working environment, use the library() function:\n\nlibrary(&lt;package_name&gt;) # note the LACK of quotation marks!\n\nAs an example, you’ll notice a code chunk at the start of this lab with the command library(ottr)- this command loads the ottr package into our environment (which in turn gives us access to various autograder-related functionality).\n\n\n\n\n\n\nTip\n\n\n\nFor more information about R packages, consult this resource."
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#the-vectorization-of-r",
    "href": "Labs/Lab00/intro2r.html#the-vectorization-of-r",
    "title": "Lab 00: Introduction to R",
    "section": "The Vectorization of R",
    "text": "The Vectorization of R\nIt is often stated that R is vectorized. Effectively, this means that the fundamental object in R is a vector, and most functions, when applied to vectors, are applied element-wise.\nFor instance:\n\nc(1, 2, 3) + c(1, 1, 1)\n\n[1] 2 3 4\n\n\nis equivalent to\n\nc(1, 2, 3) + 1\n\n[1] 2 3 4\n\n\nSince columns and rows of matrices are effectively stored as vectors, this makes adding a scalar to each element of a matrix fairly easy:\n\nM &lt;- matrix(1:6, nrow = 3, byrow = T)\nM\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\n\nM + 2\n\n     [,1] [,2]\n[1,]    3    4\n[2,]    5    6\n[3,]    7    8\n\n\nMost functions are also vectorized; i.e. allow for vector-valued inputs. If you want to make a user-defined function vectorized, you can wrap your function in a call to the Vectorize() function. For example, consider the following implementation of the sign function:\n\nsgn_non_vectorized &lt;- function(x) {\n  if(x &lt; 0) {\n    return(\"negative\")\n  } else if(x == 0) {\n    return(\"zero\")\n  } else {\n    return(\"positive\")\n  }\n}\n\nCalling sgn_non_vectorized(-1) is fine:\n\nsgn_non_vectorized(-1)\n\n[1] \"negative\"\n\n\nhowever calling sgn_non_vectorized(c(-1, 1)) causes problems:\n\nsgn_non_vectorized(c(-1, 1))\n\nError in if (x &lt; 0) {: the condition has length &gt; 1\n\n\nWe can fix this using the Vectorize() function:\n\nsgn_vectorized &lt;- Vectorize(\n  function(x){sgn_non_vectorized(x)}\n)\nsgn_vectorized(c(-1, 1))\n\n[1] \"negative\" \"positive\"\n\n\nBy the way, note that the above example also demonstrates the following: unlike in Python, you do not need to explicitly include a return statement in the body of an R function. By default, R will return whatever the final non-assignment step of your code is.\n\nLeveraging Vectorization to Bypass Loops\nAn interesting consequence of the vectorized nature of R is that we can actually bypass loops in certain contexts. Functions that help us do this include (but are not limited to):\n\napply(): applies a function to either rows or columns (or both) of an array or matrix\nlapply() and sapply(): applies a function across a list (differences between the functions largely boil down to the data type/structure of output)\n\nAs an example, consider the following matrix M (which we encountered above)\n\nM\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\n\n\nTo compute row averages (i.e. averages across rows), we could use a for loop:\n\nrow_avgs &lt;- c()\nfor(k in 1:nrow(M)) {\n  row_avgs &lt;- c(row_avgs, mean(M[k,]))\n}\nrow_avgs\n\n[1] 1.5 3.5 5.5\n\n\nAlternatively, we could use the apply() function:\n\napply(M, MARGIN = 1, FUN = mean)\n\n[1] 1.5 3.5 5.5"
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#custom-error-messages-in-functions",
    "href": "Labs/Lab00/intro2r.html#custom-error-messages-in-functions",
    "title": "Lab 00: Introduction to R",
    "section": "Custom Error Messages in Functions",
    "text": "Custom Error Messages in Functions\nIf we like, we can build in descriptive errors into a function. For example, say we want to define a function called add_2() which takes in a single numerical input x and outputs the value of x + 2. Further suppose we’d like our function to return an error message stating \"Input must be of type 'double' or 'integer'\" if the input is not numerical (i.e. neither an integer nor a double). We can do so by using the stop() function:\n\nadd_2 &lt;- function(x) {\n  if(!(typeof(x) == \"double\") & !(typeof(x) == \"integer\")) {\n    stop(\"Input must be of type 'double' or 'integer'\")\n  } else {\n    return(x + 2)\n  }\n}\n\nadd_2(4.2)\n\n[1] 6.2\n\nadd_2(\"hello\")\n\nError in add_2(\"hello\"): Input must be of type 'double' or 'integer'"
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#recursion",
    "href": "Labs/Lab00/intro2r.html#recursion",
    "title": "Lab 00: Introduction to R",
    "section": "Recursion",
    "text": "Recursion\nYou have likely encountered the notion of recursion before, either in its mathematical or computing context. Loosely speaking, in computer science, we us the term recursion to describe a situation in which the current computational step depends on one or more computational steps that were completed in the past.\nA simple mathematical example of recursion is the Fibonacci Numbers, which is a sequence \\(\\{a_n\\}\\) of numbers defined through the recursive relationship \\[ a_0 = 0, \\quad a_1 = 1, \\quad a_{n} = a_{n - 1} + a_{n - 2} \\ (\\forall n \\geq 2) \\] For instance, the first 7 Fibonacci numbers are \\(\\{0, 1, 1, 2, 3, 5, 8\\}\\).\nLet’s say we want to create a function fib() that takes in a single integer input n and outputs the nth Fibonacci number. Firstly, this is not as simple as the examples we’ve seen before because there isn’t a closed-form formula for the nth Fibonacci number1.\n\nHowever, we can think of defining this function recursively. The key is to note that, if we have configured our fib() function correctly, we have that\n\nfib(n) = fib(n) + fib(n - 1)\n\nWe also know that\n\nfib(0) = 0\nfib(1) = 1\n\nThis motivates us to define our fib() function as follows:\n\nfib &lt;- Vectorize(function(n) {\n  if(n == 0) {\n    return(0)\n  } else if (n == 1) {\n    return(1)\n  } else {\n    return( fib(n - 1) + fib(n - 2))\n  }\n})\n\nAs an example:\n\nfib(1:7)\n\n[1]  1  1  2  3  5  8 13\n\n\nwhich matches what we computed “by hand”, above."
  },
  {
    "objectID": "Labs/Lab00/intro2r.html#footnotes",
    "href": "Labs/Lab00/intro2r.html#footnotes",
    "title": "Lab 00: Introduction to R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nactually, this is a lie- there does exist a closed form expression for the nth Fibonacci number, but for the purposes of this exercise we are going to ignore that fact↩︎"
  },
  {
    "objectID": "Projects/MP01.html",
    "href": "Projects/MP01.html",
    "title": "Mini-Project 1",
    "section": "",
    "text": "Welcome to the first PSTAT 100 Mini-Project! Please keep in mind that mini-projects will be (intentionally) a bit open-ended. This is because most “real-world” data science projects - whether they be in industry or in academia - are also open-ended. Instead of having a set series of questions that can be answered with only one or two methods, project-type questions can often be answered in many different ways, using many different techniques.\nWe do expect your final product to be more akin to a report than a homework set, though we will not necessarily expect all of the formality of an academic paper (we’re saving that for the final project). Having said that, here are some things to keep in mind:"
  },
  {
    "objectID": "Projects/MP01.html#background",
    "href": "Projects/MP01.html#background",
    "title": "Mini-Project 1",
    "section": "Background",
    "text": "Background\nAs a part of this project, you will be asked with generating a handful of maps. In the cartographic1 world, objects are typically identified by a pair of points called a coordinate. Geographical coordinates consist of a latitude and longitude value, which can be thought of like x- and y-coordinates in a Cartesian coordinate system, respectively.\n\n\n\n\n\nDepiction of Latitude and Longitude; source: https://cdn.britannica.com/07/64907-050-7ACA69C8/Facts-parallels-Lines-of-Latitude-angles-direction.jpg"
  },
  {
    "objectID": "Projects/MP01.html#data-description",
    "href": "Projects/MP01.html#data-description",
    "title": "Mini-Project 1",
    "section": "Data Description",
    "text": "Data Description\nThe data for this project is spread across several files (which is fairly common in data science projects);\n\na series of 12 files containing flight informations for each of the 12 months in 2023 (these files all have the name CA_Flights_&lt;month&gt;, where &lt;month&gt; represents the month represented in the file)\na file called Carrier_Codes.csv, which includes the full names for the various airline carriers included in the dataset\na filed called Airport_Info.csv, which contains geographical information about major US airports.\n\nEach of the CA_flights_&lt;month&gt;.csv files contain the following column names (and their description):\n\n\n\n\n\n\n\nVariable Name\nDescription\n\n\n\n\nyear\nthe year of observation\n\n\nmonth\nthe month of observation\n\n\nday_of_month\nthe day of month of observation\n\n\nop_unique_carrier\nthe airline carrier associated with the observation\n\n\norigin\nthe airport code of the origin (i.e. point-of-departure) of the observation\n\n\ndest\nthe airport code of the destination\n\n\ncrs_dep_time\nthe scheduled departure time\n\n\ndep_time\nthe actual departure time\n\n\ndep_delay\nthe amount of delay in departure; i.e. actual departure minus schedule departure (flights that departed early have a negative dep_delay value)\n\n\ncrs_arr_time\nthe scheduled arrival time\n\n\narr_time\nthe actual arrival time\n\n\narr_delay\nthe amount of delay in arrival; i.e. actual arrival minus schedule arrival (flights that arrived early have a negative dep_delay value)\n\n\ncrs_elapsed_time\nthe scheduled flight duration (in minutes)\n\n\nactual_elapsed_time\nthe actual flight duration (in minutes)\n\n\n\nAdditionally, all times are listed in the local time zone.\n\n\n\n\n\n\nNote\n\n\n\nIt is up to you to determine whether or not to use the Carrier_Codes.csv file."
  },
  {
    "objectID": "Projects/MP01.html#section-1-data-cleaning-and-eda",
    "href": "Projects/MP01.html#section-1-data-cleaning-and-eda",
    "title": "Mini-Project 1",
    "section": "Section 1: Data Cleaning and EDA",
    "text": "Section 1: Data Cleaning and EDA\nMost projects will begin with cleaning, merging, and exploring the datasets of interest. For instance, it’s a bit annoying that the data is spread across several files. Eventually, we’d like to make comparisons across time which is difficult to do with the current structure of our data.\n\nCombine all 12 months’ worth of data into a single data frame.\n\nYou can always read each monthly file into a separate variable, and then combine them together using a function like bind_rows(). (In the real world this is typically frowned upon since it is a little inefficient, however for the purposes of this mini-project it’ll be find if you do it this way.)\nAnother way is to:\n\nDefine a (vector) variable listing all of the filenames of the files you want to read in\nUse the lapply() function to apply the read.csv() function to each of the elements in your filename vector, thereby creating a list with 12 layers (each layer corresponding to one of the monthly data files)\nUse bind_rows() to effectively “collapse” your list of data frames into a single dataframe\n\n\nWhat are the observational units and variables in this dataset? How many of each are there?\nHow are missing values encoded? How can you tell?\n\n\n\n\n\n\n\nTip:\n\n\n\nRemember, your final PDF should have no code chunks showing. It’s fine if you leave some of your code output displayed, so long as you describe/analyze it right after. If you find yourself not referencing a particular output of code, simply hide the output.\nAs a reminder, to get a code chunk to run but not display you can change your code chunk header from ```{r} to ```{r, echo = F}.\n\n\nNow, our dataframe consisting of all observations does have origin and destination airports included, however the values of these variables are simply the airport abbreviations. It would be much nicer if we could translate those abbreviations into full airport names as well as latitude and longitude values. Thankfully, the airport_info.csv file does contain this information. However, it also contains information on more airports than we really need. The way we’ll pinpoint only the information we need is by utilizing a join.\nStart off by importing the airport_info.csv file, and store assign this to a variable.\nNow, we need to think a little bit about what information we want to include in our dataframe. Specifically, note that we have both origin and destination airports to keep track of. Hence, it makes sense to actually include six additional columns to our Part I dataframe: three indicating origin airport name, latitude, and longitude, and three indicating destination airport name, latitude, and longitude. For consistency, give these new columns the following names:\n\nORIGIN_ARPT_NAME\nlat_origin\nlon_origin\nDEST_ARPT_NAME\nlat_dest\nlon_dest\n\n\n\n\n\n\n\nNote\n\n\n\nAs we will see later in the course, this naming scheme is actually not typically considered to be a good one - specifically, mixing allcaps variable names with lowercase or mixed-case names is usually frowned upon. But, for now, we won’t worry about that too much.\n\n\nYou can, if you like, do this in two separate joins (one joining on origin airport information and another joining on destination airport information), but, if you like, you can actually do this in one command (making heavy use of the pipe operator). Here is some skeleton code you can use to accomplish the desired join (replace the ...s with your code):\n\nleft_join(\n  ...,\n  by = join_by(...)\n) %&gt;%\n  rename(\n    ...\n  ) %&gt;%\n  left_join(\n    ...\n    by = join_by(...)\n  ) %&gt;%\n  rename(\n    ...\n  )\n\nYou should also take this time to ensure that variables are encoded using the appropriate type (e.g. check that ordinal variables are stored as ordered factors, numerical variables are stored with the data type numeric, etc.). Also, make sure that months have descriptive names (e.g. don’t use 1 for January; instead, use Jan or January, etc.)."
  },
  {
    "objectID": "Projects/MP01.html#section-2-santa-barbara-airport",
    "href": "Projects/MP01.html#section-2-santa-barbara-airport",
    "title": "Mini-Project 1",
    "section": "Section 2: Santa Barbara Airport",
    "text": "Section 2: Santa Barbara Airport\nWe’ll start off by restricting our considerations to flights routing through Santa Barbara Airport (SBA). Keep in mind that this refers to flights both originating from and arriving at SBA.\n\nGeographic Considerations\n\nHow many airports have flights that connect with Santa Barbara? What are the names of these airports? (Include full airport names, not just airport abbreviations!)\nMake a map that displays the geographic locations of these airports. Also, clearly indicate the location of SBA on your map.\n\n\nAside: Maps\nHere is some code to get you started on the mapmaking portion:\n\nlibrary(tidyverse)\n\nstates &lt;- map_data(\"state\")\n\nggplot() +\n  geom_polygon(data = states,\n               aes(x = long, y = lat, group = group),\n               fill = \"grey90\",\n               colour = \"grey50\") +\n  coord_quickmap() +\n  theme_minimal()\n\n\n\n\n\n\n\nExploring Flights\nIt’s time to make some statistical visualizations!\n\nGenerate a line graph that visualizes the total number of monthly flights that route through SBA. Here, when we say “route through”, we mean either originate from or land in SBA. Use this graph to identify the “high” and “low” seasons for travel to and from Santa Barbara.\nNow, reproduce your graphic from the above step but facet based on whether the flights are departing from or landing in SBA. Are there any differences between the peaks and troughs in the originating-from and landing-in graphs?\nAre there any months in which the number of flights landing in SBA differs from the number of flights leaving SBA? You can answer this using either a graph, or by producing a table.\nNow, generate a doubly-grouped side-by-side boxplot that displays the distribution of flight durations for flights departing from and arriving in SBA. That is, you should have several pairs of boxplots (one pair for each of the airports served by SBA), with each pair consisting of a distribution of SBA-bound flight durations and SBA-departing flight durations. Use this graph to describe if there are any differences in the distribution of flight durations to and from SBA. As an example of what we mean by “doubly-grouped side-by-side boxplot” (as applied to a completely fictitious dataset containing response measurements resp on three difference dosages and three different genders):\n\n\nset.seed(123)\n\ndata.frame(\n  resp = rnorm(100, 10, 4),\n  dosage = c(rep(\"A\", 30), rep(\"B\", 20), rep(\"C\", 50)),\n  gender = c(rep(c(\"Male\", \"Female\", \"NonBinary\"), 33), \"Female\")\n) %&gt;%\n  ggplot(aes(x = dosage,\n             y = resp,\n             fill = gender)) +\n  geom_boxplot(staplewidth = 0.5) +\n  theme_minimal(base_size = 12) +\n  ggtitle(\n    \"Simulated Dataset\",\n    subtitle = \"Grouped by dosage and gender\"\n  )\n\n\n\n\n\n\nInvestigating Delays\nNow that we have a decent feel for the airports and flight durations included in the dataset, let’s start to investigate the delays. Again, we’ll (for now) only consider flights that route through SBA (i.e. have SBA as either their point-of-origin or their destination).\n\nGenerate a boxplot of departure delays across airlines. For this part, use the xlim() and ylim() functions to play around with your axis limits to focus on the “box” portion of the boxplot” Comment on whether, on average, airlines had flights that departed before or after their scheduled departure times, and also comment on differences in average (median) departure delays across airlines.\nNow, generate a doubly-grouped boxplot that displays delay times across airlines, but color based on whether the delay is a departure delay or an arrival delay. Comment on your plot.\nFor flights departing from SBA, is there an association between the scheduled departure time and the length of delay? Be sure to include a plot that effectively displays any potential changes to this relationship across destination airports (hint: is color really the best aesthetic to change here?)"
  },
  {
    "objectID": "Projects/MP01.html#section-3-branching-out",
    "href": "Projects/MP01.html#section-3-branching-out",
    "title": "Mini-Project 1",
    "section": "Section 3: Branching Out",
    "text": "Section 3: Branching Out\nAlright, let’s broaden our scope and stop focusing solely on flights routing through SBA.\n\nWhat does the distribution of departure times look like? Are there peaks and troughs throughout the day (i.e. are there period of times with very high and/or very low departure counts)?\nWhat does the distribution of arrival times look like? Are there peaks and troughs throughout the day (i.e. are there period of times with very high and/or very low arrival counts)? If there are peaks and troughs, do these correspond with the peaks and troughs in departure counts?\nAre there months that have higher/lower average (median) departure delays? What about arrival delays? (There are several justifications you could give, including either a plot or a table. Take your pick!)\n\nIt’s also important to think critically about the scope of inference2 of our dataset. For example, the graph below (which is analogous to one of the graphs you should have made somewhere above) marks the airports served by the Seattle-Tacoma International Airport:\n\nWe happen to know, from prior knowledge, that there exists a direct flight from Seattle to Newark Airport (near New York City). How come this flight isn’t included in this dataset? In other words, will filtering solely based on arrival or departure airport give us information about all flights (regardless of origin and destimation) routing through that airport?"
  },
  {
    "objectID": "Projects/MP01.html#footnotes",
    "href": "Projects/MP01.html#footnotes",
    "title": "Mini-Project 1",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nof or relating to maps↩︎\nthis is a term we’ll return to periodically throughout the course. For now, you can think of this question as analogous to asking “what are some limitations about our dataset?”↩︎"
  },
  {
    "objectID": "Pages/ICA_Prep.html",
    "href": "Pages/ICA_Prep.html",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Information Document (PLEASE READ): .pdf\nSome Practice Problems (the actual ICA will be longer, between 20 and 40 questions): .pdf\n\nAnswers: .pdf\n\n\n\n\nVersion A (Blank) Version B (Blank) Version C (Blank)\n\nVersion A Solutions"
  },
  {
    "objectID": "Pages/ICA_Prep.html#ica01",
    "href": "Pages/ICA_Prep.html#ica01",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Information Document (PLEASE READ): .pdf\nSome Practice Problems (the actual ICA will be longer, between 20 and 40 questions): .pdf\n\nAnswers: .pdf\n\n\n\n\nVersion A (Blank) Version B (Blank) Version C (Blank)\n\nVersion A Solutions"
  },
  {
    "objectID": "Pages/policies.html",
    "href": "Pages/policies.html",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Welcome to PSTAT 100: Data Science Concepts and Analysis! I am very excited to join you as your instructor this quarter. Our journey together will take us through the basics of Data Science, and aims to prepare you for your future endeavors in the field, whether they be in classes, industry, or academia. Here’s to a great quarter!     – Ethan"
  },
  {
    "objectID": "Pages/policies.html#course-staff-and-lecture-logistics",
    "href": "Pages/policies.html#course-staff-and-lecture-logistics",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Course Staff and Lecture Logistics",
    "text": "Course Staff and Lecture Logistics\nInstructor: Ethan P. Marzban (he/him)\n\n\n\n\n\n\nLecture Times and Location\n\n\n\nT, R from 9:30am - 10:45am, in BUCHN 1940.\n\n\nTeaching Assistants: TBD, TBD\nSections:\n\nM 2 - 2:50pm in PHELPS 1518 (TBD)\nM 3 - 3:50pm in PHELPS 1518 (TBD)\nM 4 - 4:50pm in PHELPS 1517 (TBD)\nM 5 - 5:50pm in PHELPS 1513 (TBD)"
  },
  {
    "objectID": "Pages/policies.html#course-description",
    "href": "Pages/policies.html#course-description",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Course Description",
    "text": "Course Description\nAs stated in the catalog description:\n\nOverview of data science key concepts and the use of tools for data retrieval, analysis, visualization, and reproducible research. Topics include an introduction to inference and prediction, principles of measurement, missing data, and notions of causality, statistical “traps”, and concepts in data ethics and privacy. Case studies will illustrate the importance of domain knowledge. Credit units: 4.\n\nIndeed, this course is designed to be a hands-on introduction to Data Science for intermediate-level students with some exposure to probability and basic computation skills, but with few or no upper-division courses in statistics."
  },
  {
    "objectID": "Pages/policies.html#prerequisites",
    "href": "Pages/policies.html#prerequisites",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Prerequisites:",
    "text": "Prerequisites:\n\nPSTAT 120A (Probability at a calculus-based level)\nMATH 4A (a first pass at Linear Algebra)\nPrior experience with a programming language (e.g. Python through CMPSC 9 or CMPSC 16).\n\nNote on Programming: the primary programming language of this course will be R, though you are not expected to necessarily have prior experience coding with R (so long as you have experience coding in another language, e.g. Python, Julia, etc.)"
  },
  {
    "objectID": "Pages/policies.html#textbooksreadings",
    "href": "Pages/policies.html#textbooksreadings",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Textbooks/Readings",
    "text": "Textbooks/Readings\nThere are two “required” textbooks this quarter (required in the sense that readings will be assigned from them), both of which are freely available at the links below courtesy of the authors:\n\nR for Data Science (2e), by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\nIntroduction to Modern Statistics, 2nd Ed., by Mine Çetinkaya-Rundel and Johanna Hardin\n\nAnother good resource for those of you very interested in Data Science (keep in mind this book is written primarily with the Python programming language in mind, which is why I will not be assigning reading from it):\n\nLearning Data Science, by Sam Lau, Joey Gonzalez, and Deb Nolan\n\nIf you are new to programming in R, you may also find this textbook useful:\n\nAn Introduction to R, by Alex Douglas, Deon Roos, Francesca Mancini, Ana Couto & David Lusseau\n\nThere will also be a handful of articles which will be assigned as reading. All required reading can be found in the Weekly tabs of the Materials page."
  },
  {
    "objectID": "Pages/policies.html#learning-outcomes",
    "href": "Pages/policies.html#learning-outcomes",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of this course, you should be able to:\n\ncritically assess data quality and sampling design\nretrieve, inspect, and clean raw data\nunderstand the basics of exploratory, descriptive, visual, and inferential techniques\ninterpret and communicate results in context"
  },
  {
    "objectID": "Pages/policies.html#assessments",
    "href": "Pages/policies.html#assessments",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Assessments",
    "text": "Assessments\n\nLabs: short, structured coding assignments designed to introduce programming concepts and skills. Labs will be assigned weekly, and are designed to be mostly completed during Section on Monday but won’t be due until 11:59pm on Wednesdays.\nHomeworks: slightly larger in scope than labs; will contain both programming and theoretical/conceptual concepts. We will have a total of 3 homework assignments released throughout the quarter; typically you will have 1-2 weeks to work on the homeworks and you are encouraged to start as early as possible!\nMini Projects: more open-ended than homeworks and labs, and are designed to more closely simulate real-world data science projects and endeavors. We will have a total of 3 mini projects (released in non-exam weeks where there are no homeworks due) throughout the quarter, and you are encouraged to work collaboratively.\nFinal Project: a final, comprehensive project that will be due during finals week. You will be required to work in teams on the Final Project.\n\n\n\n\n\n\n\nFinal Project\n\n\n\nThe final project will be due by 11:59pm on Tuesday, June 11.\n\n\n\n2 In-Class Assessments (ICAs) will be administered (see below for dates). I hesitate to call these “exams” because they are not intended to be as high-stakes as exams, however they are designed to test your retention of course material. More information will be released as we approach the date of the first ICA.\n\n\n\n\n\n\n\nAssessment Dates\n\n\n\n\nIn-Class Assessment 1: Thursday, April 25, 2024 in BUCHN 1940 (our Lecture classroom) starting at 9:30 (our regular class time)\nIn-Class Assessment 2: Thursday, May 23, 2024 in BUCHN 1940 (our Lecture classroom) starting at 9:30 (our regular class time)\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThere will be no ICAs offered at alternate times, for any reasons. So, please plan accordingly!\n\n\n\nFinal Course Grades\nYour final course grade will be computed according to the following weights:\n\n\n\nAssessment\nWeight\n\n\n\n\nLabs\n10%\n\n\nHW\n15%\n\n\nMini Projects\n20%\n\n\nFinal Project\n25%\n\n\nIn-Class Assessments\n30%\n\n\n\nYour final letter grade will be issued according to the following scheme (cutoffs between plusses and minuses will be calculated at the end of the quarter):\n\nA- – A+: 90 – 100%\nB– – B+: 80 – 89.99%\nC– – C+: 70 – 79.99%\nD– – D+ : 60 – 69.99%\nF: 0 – 59.99%\n\nI have elected to adopt an uncurved grading scheme to eliminate any sense of “competition” among students; I highly encourage you all to collaborate with and uplift each other. Having said that, I will certainly consider adjusting the cutoffs at the end of the quarter if necessary."
  },
  {
    "objectID": "Pages/policies.html#policies",
    "href": "Pages/policies.html#policies",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Policies",
    "text": "Policies\n\nLate Submissions\nYou are allowed two late submissions across homeworks and labs (so, 2 in total; not 2 each), that must be submitted within 48 hours of the original deadline. No work will be accepted beyond 48 hours after the original deadline. Additionally, because projects may/will be collaborative, late project submissions will not be accepted.\n\n\nCommunication\nThere are two primary means of communication outside of scheduled class meetings: office hours and an EdStem Discussion Forum (please see Canvas for a join link; for security purposes, we are only allowing currently-enrolled students join the discussion forum). If you are unsure of how to reach out to appropriate parties, please consult the following table:\n\n\n\nTopic\nRedirect to…\n\n\n\n\nTroubleshooting codes\nEdStem\n\n\nChecking answers\nOffice hours or EdStem\n\n\nClarifying assignment content\nOffice hours or EdStem\n\n\nAssignment submission\nGradescope\n\n\nRe-evaluation request\nGradescope\n\n\nQuestion about missing grades\nFill Out This Form\n\n\n\nSome additional comments:\n\nPlease note that we (the course staff) request you refrain from emailing us except in case of extreme emergency (it is up to you to decide what is an ‘emergency’). Please bring all of your questions to the course staff during either Office Hours or after Lecture/Section. Thank you!\nIf you have questions or concerns about missing grades, please use the form linked in the table above. You are allowed to submit the form multiple times, but we ask that you please wait at least 48 business hours before submitting follow-ups. Thank you!\n\n\n\nCollaboration and Academic Integrity\nData Science (as we will see) is an inherently collaborative field. As such, you are not only allowed but also encouraged to collaborate on assignments (be they lab, homework, or project). However, there are limitations to collaboration:\n\ncollaboration on the ICAs is strictly prohibited\ndo not copy other people’s work and try to pass it off as your own\nif/when you work in groups, include the names of all group members on the assignment\n\nAnyone found guilty of academic misconduct will be reported to the Academic Senate, and will receive at minimum a failing grade on the assignment in question; further actions may also include failing the course, and marks being made on permanent records. Depending on the severity of the infraction, expulsion is also a possibility.\nBasically, don’t cheat- please! If you’re ever struggling with course material, please come talk to me or the TA’s. We are truly here for you, and want only the best for you.\n\n\nSection Switching\nLab Sections take place in special “Collaborate Classrooms” which are equipped with laptops. There are only a fixed number of seats and laptops in these classrooms, meaning we cannot under any circumstance over-enroll sections. Therefore, if you want to switch section unofficially (we do not have the ability to switch your official enrollment through GOLD), please follow the steps at this link. Any requests to switch sections that do not adhere to the guidelines posted at that link will be ignored."
  },
  {
    "objectID": "Pages/policies.html#disabled-students-program-dsp",
    "href": "Pages/policies.html#disabled-students-program-dsp",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Disabled Students Program (DSP)",
    "text": "Disabled Students Program (DSP)\nIf you have a disability, or otherwise require accommodations for the exams and/or quizzes please reach out to the Disabled Students Program (DSP) ASAP to ensure your request(s) for accommodation can be processed. We ask that all requests be logged at least a week in advance, to ensure the system enough time to process. Please note that we cannot grant any requests for accommodations unless they come to us from DSP directly."
  },
  {
    "objectID": "Pages/policies.html#technology-needs",
    "href": "Pages/policies.html#technology-needs",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Technology Needs",
    "text": "Technology Needs\nAs a part of this course, you will be required to program in R. Though the Lab Sections take place in specially designed classrooms that come equipped with computers, your homework and quizzes may cover R-related questions, which means we expect you to have access to a laptop capable of connecting to the internet. If you do not currently possess such a laptop, please check out UCSB’s Basic Needs Resource page on Technology Resources to try and acquire one."
  },
  {
    "objectID": "Pages/policies.html#disclaimer",
    "href": "Pages/policies.html#disclaimer",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Disclaimer",
    "text": "Disclaimer\nThe instructor reserves the right to modify this syllabus if he deems such modifications academically advisable. Such modifications, should they occur, will be announced publicly."
  },
  {
    "objectID": "Pages/policies.html#faculty-mentor",
    "href": "Pages/policies.html#faculty-mentor",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Faculty Mentor",
    "text": "Faculty Mentor\nThe faculty mentor for this course is Dr. Drew Carter. They can be reached at carter@pstat.ucsb.edu. Please note that Dr. Carter will not be able to authorize regrades or accommodations/extensions for the course; for such inquiries, please utilize the communications channels listed above. Thank you!"
  },
  {
    "objectID": "Pages/staff.html",
    "href": "Pages/staff.html",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Please see the Calendar for a weekly schedule of Office Hours (including Week 1 office hours)\n\nInstructorTeaching AssistantsUndergraduate Learning Assistant\n\n\nINSTRUCTOR: Ethan P. Marzban (He/Him)\n\nHello! My name is Ethan P. Marzban (he/him), and I’m currently a PhD student in the Department of Statistics here at UCSB. My research interests span a variety of topics, including mathematical statistics, Bayesian statistics, and Stats/Data Science Education. In my free time, I enjoy playing the piano, drinking boba, and talking about cats. I’m super excited to be your instructor this quarter!\n\n\n\n\n\n\n\nOffice hours (Beginning Week 2)\nLocation\n\n\n\n\nTuesdays, 4:30pm - 5:30pm (PDT)\nZoom (Click for Link)\n\n\nFridays, 2 - 3:30pm (PDT)\nARTS 1349\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nSections\nOH (Beginning Week 1)\n\n\n\nQiqi Li\n2 - 2:50 pm (PHELPS 1518)  3 - 3:50 pm (PHELPS 1518)\nTuesdays, 1 - 3pm (SH 5421)\n\n\n\nYuting Ma\n4 - 4:50 pm (PHELPS 1517)  5 - 5:50 pm (PHELPS 1513)\nTuesdays, 11am - 12 pm (B434, 113)  Thursdays, 1 - 2 pm (B434, 113)\n\n\n\n\n\nTBD"
  }
]