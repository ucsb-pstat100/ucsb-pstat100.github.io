[
  {
    "objectID": "Pages/schedule.html",
    "href": "Pages/schedule.html",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Note\n\n\n\nThis page will be updated as we progress through the quarter; please check back regularly for updates!\n\n\n\n\n\n\n\n\nTextbook Abbreviations and Icon Meanings\n\n\n\n\nMDSR = Modern Data Science with R\nIMS = Introduction to Modern Statistics, 2nd Ed.\nR4DS = R for Data Science\nISL = An Introduction to Statistical Learning with Applications in R\nAMAW = All Models are Wrong\n = Lecture\n = Lab\n = Paper\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWEEK\nDATE\nREADING\nTOPIC\nMATERIALS\n\n\n\n\n1\nMon, Jun 23\n MSDR, Chapter 1: Prologue: Why Data Science?   IMS, 1.2.2: Types of Variable\nIntroduction to Data\n Lec01 Slides\n\n\n\n\nTue, Jun 24\n R4DS, Chapter 5: Data tidying   R4DS, Chapter 3: Data transformation   Hadley Wichkam Tidy Data, Journal of Statistical Software (2014)\nData Structures and Tidy Data\n Lec02 Slides    Lab01: Welcome to the tidyverse!\n\n\n\n\nWed, Jun 25\n MDSR, Chapter 3: A Grammar for Graphics   R4DS, Chapter 9: Layers   Hadley Wichkam A Layered Grammar of Graphics, Journal of Computational and Graphical Statistics (2010) \nVisualizations, Part I\n Lec03 Slides\n\n\n\n\nThu, Jun 26\n R4DS, Chapter 11: Communication   MDSR, Chapter 2: Data Visualization   IMS, Chapter 6: Applications: Explore\nVisualizations, Part II\n Lec04 Slides    Lab02: Bobabase (Databases and Joins)\n\n\n\n\nSun, Jun 29\n\n\n\n\nHOMEWORK 1 DUE\n\n\n2\nMon, Jun 30\n AMAW, Chapter 3: Geometric Duality   MDSR, Chapter 12.2: Dimension Reduction \nGeometry of Data\n Lec05 Slides\n\n\n\n\nTue, Jul 1\n Chapter 10 (Principal Components Analysis) of Introduction to Statistical Learning with Applications in R\nPCA\n Lec06 Slides    Lab03: Boots the House Down, Mama (PCA)    PCA Addendum\n\n\n\n\nWed, Jul 2\n\n\nReview/Catch-up\n Lec07 Slides\n\n\n\n\nThu, Jul 3\n\n\nIN-CLASS ASSESSMENT 01\nLAB CANCELLED\n\n\n3\nMon, Jul 7\n IMS, Chapter 2: Study Design   Bhaskaran and Smeeth What is the difference between missing completely at random and missing at random?, International Journal of Epidemiology (2014)\nStudy Design / Sampling Techniques\n Lec08 Slides  \n\n\n\n\nTue, Jul 8\n Selected Sections from IMS, “Foundations of Inference” and “Statistical Inference”\nSampling Distributions\n Lec09 Slides    Lab04: Care For a Sample? (Sampling Techniques and Distributions)\n\n\n\n\nWed, Jul 9\n MDSR, Chapter 9: Statistical Foundations   IMS, Chapter 12: Confidence Intervals with Bootstrapping\nEstimation / Confidence Intervals\n Lec10 Slides\n\n\n\n\nThu, Jul 10\n IMS, Chapter 13: Inference with Mathematical Models\nHypothesis Testing, I\n Lec11 Slides   Lab05\n\n\n\n\nSun, Jul 13\n\n\n\n\nMID-QUARTER PROJECT DUE\n\n\n4\nMon, Jul 14\n Selected Sections from IMS, “Foundations of Inference” and “Statistical Inference”\nHypothesis Testing, II\n Lec12 Slides\n\n\n\n\nTue, Jul 15\n Section 2.1 (What is Statistical Learning?) of Introduction to Statistical Learning with Applications in R\nIntroduction to Statistical Modeling\n Lec13 Slides   Lab06\n\n\n\n\nWed, Jul 16\n MDSR, Appendix E: Regression Modeling\nRegression, Part I\n Lec14 Slides\n\n\n\n\nThu, Jul 17\n MDSR, Appendix E: Regression Modeling\nRegression, Part II\n Lab07\n\n\n\n\nSun, Jul 20\n\n\n\n\nHOMEWORK 2 DUE\n\n\n5\nMon, Jul 21\n MDSR, Appendix E: Regression Modeling\nRegression, Part III\n Lec15 Slides\n\n\n\n\nTue, Jul 22\n MDSR, Chapter 10: Predictive Modeling   IMS, Chapter 9: Logistic Regression   MDSR, Chapter 11.1: Non-Regression Classifiers\nClassification\n Lec16 Slides   Lab08\n\n\n\n\nWed, Jul 23\n\n\nReview/Catch-Up\n Lec17 Slides\n\n\n\n\nThu, Jul 24\n\n\nIN-CLASS ASSESSMENT 02\n Lab09\n\n\n6\nMon, Jul 28\n Chapter 10 (Principal Components Analysis) of Introduction to Statistical Learning with Applications in R\nData Ethics\n Lec18 Slides\n\n\n\n\nTue, Jul 29\n TBD\nCausal Inference\n Lec19 Slides   Lab10\n\n\n\n\nWed, Jul 30\n TBD\nNeural Networks\n Lec20 Slides\n\n\n\n\nThu, Jul 31\n TBD\nClosing Remarks\n Lab11\n\n\n\n\nFri, Aug 1\n\n\nFINAL PROJECT DUE"
  },
  {
    "objectID": "Pages/schedule.html#course-schedule",
    "href": "Pages/schedule.html#course-schedule",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Note\n\n\n\nThis page will be updated as we progress through the quarter; please check back regularly for updates!\n\n\n\n\n\n\n\n\nTextbook Abbreviations and Icon Meanings\n\n\n\n\nMDSR = Modern Data Science with R\nIMS = Introduction to Modern Statistics, 2nd Ed.\nR4DS = R for Data Science\nISL = An Introduction to Statistical Learning with Applications in R\nAMAW = All Models are Wrong\n = Lecture\n = Lab\n = Paper\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWEEK\nDATE\nREADING\nTOPIC\nMATERIALS\n\n\n\n\n1\nMon, Jun 23\n MSDR, Chapter 1: Prologue: Why Data Science?   IMS, 1.2.2: Types of Variable\nIntroduction to Data\n Lec01 Slides\n\n\n\n\nTue, Jun 24\n R4DS, Chapter 5: Data tidying   R4DS, Chapter 3: Data transformation   Hadley Wichkam Tidy Data, Journal of Statistical Software (2014)\nData Structures and Tidy Data\n Lec02 Slides    Lab01: Welcome to the tidyverse!\n\n\n\n\nWed, Jun 25\n MDSR, Chapter 3: A Grammar for Graphics   R4DS, Chapter 9: Layers   Hadley Wichkam A Layered Grammar of Graphics, Journal of Computational and Graphical Statistics (2010) \nVisualizations, Part I\n Lec03 Slides\n\n\n\n\nThu, Jun 26\n R4DS, Chapter 11: Communication   MDSR, Chapter 2: Data Visualization   IMS, Chapter 6: Applications: Explore\nVisualizations, Part II\n Lec04 Slides    Lab02: Bobabase (Databases and Joins)\n\n\n\n\nSun, Jun 29\n\n\n\n\nHOMEWORK 1 DUE\n\n\n2\nMon, Jun 30\n AMAW, Chapter 3: Geometric Duality   MDSR, Chapter 12.2: Dimension Reduction \nGeometry of Data\n Lec05 Slides\n\n\n\n\nTue, Jul 1\n Chapter 10 (Principal Components Analysis) of Introduction to Statistical Learning with Applications in R\nPCA\n Lec06 Slides    Lab03: Boots the House Down, Mama (PCA)    PCA Addendum\n\n\n\n\nWed, Jul 2\n\n\nReview/Catch-up\n Lec07 Slides\n\n\n\n\nThu, Jul 3\n\n\nIN-CLASS ASSESSMENT 01\nLAB CANCELLED\n\n\n3\nMon, Jul 7\n IMS, Chapter 2: Study Design   Bhaskaran and Smeeth What is the difference between missing completely at random and missing at random?, International Journal of Epidemiology (2014)\nStudy Design / Sampling Techniques\n Lec08 Slides  \n\n\n\n\nTue, Jul 8\n Selected Sections from IMS, “Foundations of Inference” and “Statistical Inference”\nSampling Distributions\n Lec09 Slides    Lab04: Care For a Sample? (Sampling Techniques and Distributions)\n\n\n\n\nWed, Jul 9\n MDSR, Chapter 9: Statistical Foundations   IMS, Chapter 12: Confidence Intervals with Bootstrapping\nEstimation / Confidence Intervals\n Lec10 Slides\n\n\n\n\nThu, Jul 10\n IMS, Chapter 13: Inference with Mathematical Models\nHypothesis Testing, I\n Lec11 Slides   Lab05\n\n\n\n\nSun, Jul 13\n\n\n\n\nMID-QUARTER PROJECT DUE\n\n\n4\nMon, Jul 14\n Selected Sections from IMS, “Foundations of Inference” and “Statistical Inference”\nHypothesis Testing, II\n Lec12 Slides\n\n\n\n\nTue, Jul 15\n Section 2.1 (What is Statistical Learning?) of Introduction to Statistical Learning with Applications in R\nIntroduction to Statistical Modeling\n Lec13 Slides   Lab06\n\n\n\n\nWed, Jul 16\n MDSR, Appendix E: Regression Modeling\nRegression, Part I\n Lec14 Slides\n\n\n\n\nThu, Jul 17\n MDSR, Appendix E: Regression Modeling\nRegression, Part II\n Lab07\n\n\n\n\nSun, Jul 20\n\n\n\n\nHOMEWORK 2 DUE\n\n\n5\nMon, Jul 21\n MDSR, Appendix E: Regression Modeling\nRegression, Part III\n Lec15 Slides\n\n\n\n\nTue, Jul 22\n MDSR, Chapter 10: Predictive Modeling   IMS, Chapter 9: Logistic Regression   MDSR, Chapter 11.1: Non-Regression Classifiers\nClassification\n Lec16 Slides   Lab08\n\n\n\n\nWed, Jul 23\n\n\nReview/Catch-Up\n Lec17 Slides\n\n\n\n\nThu, Jul 24\n\n\nIN-CLASS ASSESSMENT 02\n Lab09\n\n\n6\nMon, Jul 28\n Chapter 10 (Principal Components Analysis) of Introduction to Statistical Learning with Applications in R\nData Ethics\n Lec18 Slides\n\n\n\n\nTue, Jul 29\n TBD\nCausal Inference\n Lec19 Slides   Lab10\n\n\n\n\nWed, Jul 30\n TBD\nNeural Networks\n Lec20 Slides\n\n\n\n\nThu, Jul 31\n TBD\nClosing Remarks\n Lab11\n\n\n\n\nFri, Aug 1\n\n\nFINAL PROJECT DUE"
  },
  {
    "objectID": "Pages/schedule.html#course-calendar",
    "href": "Pages/schedule.html#course-calendar",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Course Calendar",
    "text": "Course Calendar"
  },
  {
    "objectID": "Pages/Lab00/df_basics.html",
    "href": "Pages/Lab00/df_basics.html",
    "title": "Lab 00: Dataframe Basics",
    "section": "",
    "text": "Tip\n\n\n\nThis lab is long! Use the floating table of contents (at the top-right of the screen) to jump to sections as needed."
  },
  {
    "objectID": "Pages/Lab00/df_basics.html#lab-objectives",
    "href": "Pages/Lab00/df_basics.html#lab-objectives",
    "title": "Lab 00: Dataframe Basics",
    "section": "Lab Objectives",
    "text": "Lab Objectives\nThis lab covers the following topics:\n\nBasics of dataframes in R"
  },
  {
    "objectID": "Pages/Lab00/df_basics.html#relevant-textbook-chapterssections",
    "href": "Pages/Lab00/df_basics.html#relevant-textbook-chapterssections",
    "title": "Lab 00: Dataframe Basics",
    "section": "Relevant Textbook Chapters/Sections:",
    "text": "Relevant Textbook Chapters/Sections:\n\nPortions of Chapter 27 in R4DS"
  },
  {
    "objectID": "Pages/Lab00/df_basics.html#using-slicingindexing",
    "href": "Pages/Lab00/df_basics.html#using-slicingindexing",
    "title": "Lab 00: Dataframe Basics",
    "section": "Using Slicing/Indexing",
    "text": "Using Slicing/Indexing\nIf we have a dataframe called df, the command df[i, j] extracts the entry at the ith row and the jth column. For example:\n\nmy_df[1, 2]\n\n[1] \"hello\"\n\n\nWe can select multiple columns and/or rows by passing in a vector of values on either side of the comma:\n\nmy_df[c(1, 2), 2]\n\n[1] \"hello\" \"happy\"\n\n\nIf we want to extract all elements of row i, we can simply leave the column index blank:\n\nmy_df[1, ]\n\n  col1  col2\n1    2 hello\n\n\nIf we want to extract all elements of column j, we can simply leave the row index blank:\n\nmy_df[, 2]\n\n[1] \"hello\" \"happy\" \"world\"\n\n\n\n\n\n\n\n\nNote\n\n\n\nIt is important to note that rows and/or columns extracted from dataframes are stored as vectors:\n\nis.vector(my_df[,2])\n\n[1] TRUE\n\n\n\n\nA useful thing to note is that the synax a:b, where a and b are integers satisfying a &lt; b, generates the set of consecutive integers starting at a and ending at b:\n\n3:10\n\n[1]  3  4  5  6  7  8  9 10\n\n\nAnother way to generate sequences in R is to use the seq() function, which allows you to specify a start value, a stop value, and either the amount of space between successive values in the sequence or the number of elements to be included in the sequence:\n\nseq(0, 1, by = 0.1)\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\nseq(0, 1, length = 11)\n\n [1] 0.0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0\n\nseq(0, 1, length = 10)\n\n [1] 0.0000000 0.1111111 0.2222222 0.3333333 0.4444444 0.5555556 0.6666667\n [8] 0.7777778 0.8888889 1.0000000"
  },
  {
    "objectID": "Pages/Lab00/df_basics.html#using-column-names",
    "href": "Pages/Lab00/df_basics.html#using-column-names",
    "title": "Lab 00: Dataframe Basics",
    "section": "Using Column Names",
    "text": "Using Column Names\nWe can also access individual columns of a dataframe by using the $ operator, followed by the name of the column. For example:\n\nmy_df$col1\n\n[1] 2 4 6\n\n\nWe can further subset by indexing on the selected column (again, remember that columns extracted from a dataframe are stored as vectors):\n\nmy_df$col1[2:3]\n\n[1] 4 6\n\n\nIf we want to select multiple columns by name, we cannot use the $ operator but must instead use the select() function from the dplyr package (contained in the tidyverse):\n\nselect(my_df, c(col1, col2))\n\n  col1  col2\n1    2 hello\n2    4 happy\n3    6 world"
  },
  {
    "objectID": "Pages/Lab00/df_basics.html#updatingreplacing-values",
    "href": "Pages/Lab00/df_basics.html#updatingreplacing-values",
    "title": "Lab 00: Dataframe Basics",
    "section": "Updating/Replacing Values",
    "text": "Updating/Replacing Values\nTo replace an already-existing element in a dataframe with another value, we can access the value and the use the variable assignment operator (&lt;-) to overwrite the previous value. For example:\n\nmy_df[1, 2] &lt;- \"greetings\"\nmy_df\n\n  col1      col2\n1    2 greetings\n2    4     happy\n3    6     world"
  },
  {
    "objectID": "Pages/Lab00/df_basics.html#adding-columns",
    "href": "Pages/Lab00/df_basics.html#adding-columns",
    "title": "Lab 00: Dataframe Basics",
    "section": "Adding Columns",
    "text": "Adding Columns\nTo add a column, simply use the $ syntax to pretend you were accessing the column (even though it doesn’t exist yet), and then use the variable assignment operator to pass in a set of values:\n\nmy_df$col3 &lt;- c(\"red\", \"green\", \"blue\")\nmy_df\n\n  col1      col2  col3\n1    2 greetings   red\n2    4     happy green\n3    6     world  blue\n\n\nWhat happens if we try and add a column that has more values than rows in our dataframe? Well, let’s see:\n\nmy_df$col4 &lt;- c(TRUE, FALSE, TRUE, FALSE)\n\nError in `$&lt;-.data.frame`(`*tmp*`, col4, value = c(TRUE, FALSE, TRUE, : replacement has 4 rows, data has 3\n\n\nSo, this is something important to note: when adding a column to a dataframe, you must ensure that the number of values you are adding is the same as the number of rows in the dataframe.\nSay we really wanted to add a fourth colunmn to our my_df dataframe, with the values c(TRUE, FALSE, TRUE, FALSE). We could simply add a fourth row of missing values (NA) to the already-existing dataframe, and then append the column:\n\nmy_df[4,] &lt;- c(NA, NA, NA)\nmy_df$col4 &lt;- c(TRUE, FALSE, TRUE, FALSE)\nmy_df\n\n  col1      col2  col3  col4\n1    2 greetings   red  TRUE\n2    4     happy green FALSE\n3    6     world  blue  TRUE\n4   NA      &lt;NA&gt;  &lt;NA&gt; FALSE\n\n\n\n\n\n\n\n\nCaution\n\n\n\nThere are pros and cons to doing this. On the one hand, we’ve successfully added all the values we wanted to into our new column. However, we have done so at the cost of injecting missingness into our data. Depending on what we plan to do with the dataframe this may or may not be a big deal- so, just think critically before doing something like this."
  },
  {
    "objectID": "Pages/Lab00/df_basics.html#changing-column-names",
    "href": "Pages/Lab00/df_basics.html#changing-column-names",
    "title": "Lab 00: Dataframe Basics",
    "section": "Changing Column Names",
    "text": "Changing Column Names\nThe column names of our my_df dataframe are pretty uninformative. Let’s see if we can give the columns more interesting names!\nTo access the column names of a dataframe, we can use either names() or colnames():\n\ncolnames(my_df)\n\n[1] \"col1\" \"col2\" \"col3\" \"col4\"\n\n\nTo rename our columns, we can simply assign (using the variable assignment operator) a new list of names:\n\ncolnames(my_df) &lt;- c(\"numbers\", \"words\", \"colors\", \"booleans\")\nmy_df\n\n  numbers     words colors booleans\n1       2 greetings    red     TRUE\n2       4     happy  green    FALSE\n3       6     world   blue     TRUE\n4      NA      &lt;NA&gt;   &lt;NA&gt;    FALSE\n\n\nWe can, if we like, do something similar to assign names to the rows of our dataframe:\n\nrownames(my_df) &lt;- c(\"row1\", \"row2\", \"row3\", \"row4\")\nmy_df\n\n     numbers     words colors booleans\nrow1       2 greetings    red     TRUE\nrow2       4     happy  green    FALSE\nrow3       6     world   blue     TRUE\nrow4      NA      &lt;NA&gt;   &lt;NA&gt;    FALSE"
  },
  {
    "objectID": "Pages/Lab00/intro2r.html",
    "href": "Pages/Lab00/intro2r.html",
    "title": "Lab 00: Introduction to R",
    "section": "",
    "text": "Tip\n\n\n\nThis lab is long! Use the floating table of contents (at the top-right of the screen) to jump to sections as needed."
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#lab-objectives",
    "href": "Pages/Lab00/intro2r.html#lab-objectives",
    "title": "Lab 00: Introduction to R",
    "section": "Lab Objectives",
    "text": "Lab Objectives\nThis lab covers the following topics:\n\nBasics of coding in R"
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#relevant-textbook-chapterssections",
    "href": "Pages/Lab00/intro2r.html#relevant-textbook-chapterssections",
    "title": "Lab 00: Introduction to R",
    "section": "Relevant Textbook Chapters/Sections:",
    "text": "Relevant Textbook Chapters/Sections:\n\nVarious chapters of I2R\nPortions of Chapter 2 in R4DS\nPortions of Chapter 27 in R4DS"
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#r-basics",
    "href": "Pages/Lab00/intro2r.html#r-basics",
    "title": "Lab 00: Introduction to R",
    "section": "R Basics",
    "text": "R Basics\nA mentioned previously, the programming language we will be using this quarter is R. Developed in the 1990s at Bell Labs, it was built upon the S language, with the crucial benefit of being freely available to the public.\nR understand many of the basic mathematical operations we use on paper:\n\n\n\nOperation\nR Symbol\nExample\n\n\n\n\nAddition\n+\n2 + 3\n\n\nSubtraction\n-\n2 - 3\n\n\nMultiplication\n*\n2 * 3\n\n\nExponentiation\n^\n2 ^ 3\n\n\nDivision\n/\n2 / 3\n\n\n\nFor example:\n\n((2 + 3) / 4) ^ 5\n\n[1] 3.051758\n\n\nNote: like most programming languages, R obeys the order of operations:\n\nParentheses\nExponentiation\nMultiplication\nDivision\nAddition\nSubtraction\n\nThe variable assignment operator in R (i.e. the symbol we use to assign a value to a variable) is &lt;-:\n\nx &lt;- 2\nx\n\n[1] 2\n\n\n\n\n\n\n\n\nTip\n\n\n\nTechnically, using = will also work for variable assignment:\n\ny = 2\ny\n\n[1] 2\n\n\nHowever, when programming in R, it is customary to use the &lt;- operator instead.\n\n\nThere are a couple of restrictions on what we can name variables in R:\n\nVariable names cannot start with a number (but they can contain numbers). So 2var is not a valid variable name, whereas var2 is.\nVariable names cannot start with a period (but they can contain periods). So .my_var is not a valid variable name but my.var is.\nVariable names cannot include special characters (e.g. +, *, etc.) anywhere. For instance, *myvar is not a valid variable name.\n\n\n\n\n\n\n\nNote for Python Users\n\n\n\nIf you are a Python user, you might not be used to using periods in variable names (since, in Python, periods typically deliniate the start of a method). In R, periods do not have any correspondence with methods or functions, so feel free to use them in your variable names!"
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#data-types-and-data-structures",
    "href": "Pages/Lab00/intro2r.html#data-types-and-data-structures",
    "title": "Lab 00: Introduction to R",
    "section": "Data Types and Data Structures",
    "text": "Data Types and Data Structures\nWe can think of data types as the fundamental classes to which objects belong. There are 4 main data types in R:\n\ndouble (aka numeric; refers to real numbers)\ninteger\ncharacter (aka string)\nlogical (aka boolean)\n\nWe can extract the particular data type of an object using the typeof() function:\n\ntypeof(1)\n\n[1] \"double\"\n\ntypeof(1L)\n\n[1] \"integer\"\n\ntypeof(\"hello world\")\n\n[1] \"character\"\n\ntypeof(TRUE)\n\n[1] \"logical\"\n\n\nA note on booleans: in R, there are only two logical objects: TRUE (which is equivalent to T) and FALSE (which is equivalent to F). Pay close attention to the capitalization: True is NOT a valid logical type object in R (even though it is in Python)!\n\n\n\n\n\n\nNote\n\n\n\nThere are actually two more data types in R: \"complex\" and \"raw\". You may want to familiarize yourself with the \"complex\" type (which deals with complex numbers), but it is highly unlikely you will ever encounter the \"raw\" type in the wild.\n\n\nIndividual R objects can be collectively arranged into larger, more complex data structures. There are 6 main data structures in R:\n\nscalars: scalar values (i.e. single values)\nvectors: sequence of values, that must all be of the same type\nmatrices: rows and columns of values\narrays: rows, columns, and layers of values (you can think of these as essentially matrices stacked on top of each other, or, more mathematically, as akin to tensors), all of the same type\nlists: rows, columns, and layers of values, potentially of different types\nfactors: sequences of categorical values\ndataframes: rows and columns of values, potentially of different types\n\nAs you can see, there are some pairs of data structures that appear similar, but differ in the key aspect of whether or not they allow different data types. We will revisit this notion in a bit.\n\nVectors and Matrices\nFirst, let’s talk about how to create vectors in R. (In many ways, vectors form the fundamental unit in R.) The easiest way is to use the combine function, c():\n\nc(1, 2, \"hello\", \"world\")\n\n[1] \"1\"     \"2\"     \"hello\" \"world\"\n\n\n\n\n\n\n\n\nImportant\n\n\n\nDon’t forget the c when creating vectors! Simply listing the elements of a vector within a set of parentheses in R will result in an error:\n\n(1, 2, \"hello\", \"world\")\n\nError in parse(text = input): &lt;text&gt;:1:3: unexpected ','\n1: (1,\n      ^\n\n\n\n\nTo create a matrix, we use the matrix() function:\n\nmatrix(c(1, 2, 3, 4), \n       nrow = 2,\n       byrow = T)\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n\n\nNote the specification of byrow = T: this simply tells R to populate the elements of the matrix by rows. In contrast, we could have specified byrow = F:\n\nmatrix(c(1, 2, 3, 4), \n       nrow = 2,\n       byrow = F)\n\n     [,1] [,2]\n[1,]    1    3\n[2,]    2    4\n\n\nNow, let’s demonstrate what is meant by the fact that all objects in a matrix must be of the same type. Specifically, let’s try and create a matrix from the elements 1, 2, \"hello\", \"world\":\n\nmatrix(c(1, 2, \"hello\", \"world\"),\n       nrow = 2,\n       byrow = F)\n\n     [,1] [,2]   \n[1,] \"1\"  \"hello\"\n[2,] \"2\"  \"world\"\n\n\nNotice that R has automatically coerced all of the elements to be characters (even though the numbers 1 and 2 were originally specified using the double type)!\n\n\nDataframes\nIndeed, this is one of the motivating factors for using dataframes, instead of matrices. To create a dataframe from scratch, we use the data.frame() function, and specify the columns of the data frame:\n\ndata.frame(\n  c(1, 2),\n  c(\"hello\", \"world\")\n)\n\n  c.1..2. c..hello....world..\n1       1               hello\n2       2               world\n\n\nA couple of things to note:\n\nWe’ve managed to preserve the original data types of our objects.\nBy default, dataframes have column names (and the default names that R creates are pretty sucky…)\n\nLet’s explicitly specify our column names:\n\ndata.frame(\n  col1 = c(1, 2),\n  col2 = c(\"hello\", \"world\")\n)\n\n  col1  col2\n1    1 hello\n2    2 world\n\n\nIf we really wanted to, we could even specify row names:\n\ndata.frame(\n  col1 = c(1, 2),\n  col2 = c(\"hello\", \"world\"),\n  row.names = c(\"row1\", \"row2\")\n)\n\n     col1  col2\nrow1    1 hello\nrow2    2 world\n\n\nWe’ve posted a separate lab covering even more operations on dataframes, which can be accessed here.\n\n\nFactors\nAs mentioned above, factors are ideal when encoding categorical data. Recall (from Lecture 01) that categorical variables can be further subdivided into nominal and ordinal variables; analagously, R has factors and ordered factors.\nAs a simple example:\n\nfav_cols &lt;- factor(\n  c(\"red\", \"green\", \"blue\", \"green\", \"yellow\")\n)\nfav_cols\n\n[1] red    green  blue   green  yellow\nLevels: blue green red yellow\n\n\nTo extract the levels of a factor (i.e. the categories), we use the levels() function:\n\nlevels(fav_cols)\n\n[1] \"blue\"   \"green\"  \"red\"    \"yellow\"\n\n\nIf we wanted to create an ordered factor, we can still use the factor() function but now pass in an additional argument that states ordered = T:\n\nmy_grades &lt;- factor(\n  c(\"A+\", \"A-\", \"A\", \"A-\"),\n  ordered = T,\n  levels = c(\"A+\", \"A\", \"A-\")\n)\n\nmy_grades\n\n[1] A+ A- A  A-\nLevels: A+ &lt; A &lt; A-"
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#functions",
    "href": "Pages/Lab00/intro2r.html#functions",
    "title": "Lab 00: Introduction to R",
    "section": "Functions",
    "text": "Functions\nThe syntax of a function call in R is of the form:\n\nfunc_name(arg1, arg2, ...)\n\nFor example, to compute the sum of a vector we can use the sum() function:\n\nsum(c(1, 3, 5, 7))\n\n[1] 16\n\n\n\n\n\n\n\n\nTip\n\n\n\nTo access the help file for a function func_name, type ?func_name (replacing func_name with the actual name of the function) in an R console.\n\n\nTo define a function in R, we use the syntax\n\nfunc_name &lt;- function(arg1 = default1, arg2 = default2, ...) {\n  &lt;body of function&gt;\n}\n\nNote that we do not need to specify defaults for any of the arguments of a function. For example:\n\nnew_function &lt;- function(x, y = 1) {\n  return(x^2 + y^2)\n}\n\nnew_function(1, 2)  # should return 1^2 + 2^2; i.e. 5\n\n[1] 5\n\nnew_function(1)     # should return 1^2 + 1^2; i.e. 2\n\n[1] 2"
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#comparisons-and-control",
    "href": "Pages/Lab00/intro2r.html#comparisons-and-control",
    "title": "Lab 00: Introduction to R",
    "section": "Comparisons and Control",
    "text": "Comparisons and Control\nWe can use any of our standard mathematical comparisons in R.\n\n\n\nSymbol\nExample\nMeaning\n\n\n\n\n==\na == b\nIs a equal to b?\n\n\n&lt;=\na &lt;= b\nIs a less than or equal to b?\n\n\n&gt;=\na &lt;= b\nIs a greater than or equal to b?\n\n\n&lt;\na &lt; b\nIs a less than b?\n\n\n&gt;\na &gt; b\nIs a greater than b?\n\n\n!\n!p\nNegation of p\n\n\n|\np | q\nVectorized ‘or’: p or q\n\n\n&\np & q\nVectorized ‘and’: p and q\n\n\n\nNote that the result of a comparison is a vector of logicals, with TRUE in positions where the comparison holds and FALSE in positions where the comparison does not hold. For example:\n\nx &lt;- c(1, 2, 3)\ny &lt;- c(2, 1, 4)\n\nThe way we interpret this output is:\n\nThe first element of x was less than or equal to the first element of y\nThe second element of x was not less than or equal to the second element of y\nThe third element of x was less than or equal to the third element of y\n\nWe most often use the result of comparisons in conditional statements (aka control flow). Conditional statements in R are structured as follows:\n\nif(cond1) {\n  &lt;executes if cond1 is true&gt;\n} else if(cond2) {\n  &lt;executes if cond2 is true&gt;\n} ... else {\n  &lt;executes if none of the previous conditions are true&gt;\n}\n\nFor example:\n\nx &lt;- 15\n\nif(x &lt;= 10) {\n  print(\"x is small\")\n} else if (x &lt;= 20) {\n  print(\"x is moderate\")\n} else {\n  return(\"x is massive!\")\n}\n\n[1] \"x is moderate\"\n\n\nOne thing to note is that each of the conditions must be a scalar of length 1:\n\nx &lt;- c(15, 15)\n\nif(x &lt;= 10) {\n  print(\"x is small\")\n} else if (x &lt;= 20) {\n  print(\"x is moderate\")\n} else {\n  return(\"x is massive!\")\n}\n\nError in if (x &lt;= 10) {: the condition has length &gt; 1\n\n\nIf we want to control based on vector conditions, and we have only two cases to consider, we can use the ifelse() function. For example:\n\nx &lt;- c(2, 3, 4, 5, 6) \n\nifelse(x %% 2 == 0, \"even\", \"odd\")\n\n[1] \"even\" \"odd\"  \"even\" \"odd\"  \"even\""
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#loops",
    "href": "Pages/Lab00/intro2r.html#loops",
    "title": "Lab 00: Introduction to R",
    "section": "Loops",
    "text": "Loops\nIn R, there are three types of loops: for loops, while loops, and repeat loops. Since I hope you have already been exposed to loops I’ll bypass a detailed discussion of how they work, opting instead to simply highlight the R syntax of loops.\n\nfor-loops\nA for loops is ideal when you want to repeat a task a fixed number of times. For example:\n\nfor(k in 2:4) {\n  print(k)\n}\n\n[1] 2\n[1] 3\n[1] 4\n\n\nWe […]\n\nfor( k in 1:6) {\n  if(k %% 2 == 0) {\n    print(paste(k, \"is even\"))\n  } else {\n    print(paste(k, \"is odd\"))\n  }\n}\n\n[1] \"1 is odd\"\n[1] \"2 is even\"\n[1] \"3 is odd\"\n[1] \"4 is even\"\n[1] \"5 is odd\"\n[1] \"6 is even\"\n\n\n\n\nwhile- and repeat-loops\nThe remaining two types of loops in R (while and repeat loops) aren’t used as frequently as for loops, but I feel it prudent to at least mention their existence. Unlike for loops, while and repeat loops do not (necessarily) run for a fixed number of iterations - rather, they continue looping until a condition is met.\n\nFor example, to convert the first for loop above to a while loop, we could use\n\nk &lt;- 2\nwhile(k &lt;= 4) {\n  print(k)\n  k &lt;- k + 1\n}\n\n[1] 2\n[1] 3\n[1] 4\n\n\nWe could also convert the loop above to a repeat loop:\n\nk &lt;- 2\nrepeat {\n  if(k &gt; 4) {\n    break\n  } else {\n    print(k)\n    k &lt;- k + 1\n  }\n}\n\n[1] 2\n[1] 3\n[1] 4"
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#packages",
    "href": "Pages/Lab00/intro2r.html#packages",
    "title": "Lab 00: Introduction to R",
    "section": "Packages",
    "text": "Packages\nIn R, we use the term packages to refer to collections of functions and objects stored under a common name. (This is the equivalent of what is often referred to as a module, in Python).\nTo install a package in R, we use the syntax\n\ninstall.packages(\"&lt;package_name&gt;\")\n\nIf you try to install a package you have already installed, R will give you a warning message prompting you to either update the package or cancel your command.\nTo load a package into a document or working environment, use the library() function:\n\nlibrary(&lt;package_name&gt;) # note the LACK of quotation marks!\n\nAs an example, you’ll notice a code chunk at the start of this lab with the command library(ottr)- this command loads the ottr package into our environment (which in turn gives us access to various autograder-related functionality).\n\n\n\n\n\n\nTip\n\n\n\nFor more information about R packages, consult this resource."
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#the-vectorization-of-r",
    "href": "Pages/Lab00/intro2r.html#the-vectorization-of-r",
    "title": "Lab 00: Introduction to R",
    "section": "The Vectorization of R",
    "text": "The Vectorization of R\nIt is often stated that R is vectorized. Effectively, this means that the fundamental object in R is a vector, and most functions, when applied to vectors, are applied element-wise.\nFor instance:\n\nc(1, 2, 3) + c(1, 1, 1)\n\n[1] 2 3 4\n\n\nis equivalent to\n\nc(1, 2, 3) + 1\n\n[1] 2 3 4\n\n\nSince columns and rows of matrices are effectively stored as vectors, this makes adding a scalar to each element of a matrix fairly easy:\n\nM &lt;- matrix(1:6, nrow = 3, byrow = T)\nM\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\n\nM + 2\n\n     [,1] [,2]\n[1,]    3    4\n[2,]    5    6\n[3,]    7    8\n\n\nMost functions are also vectorized; i.e. allow for vector-valued inputs. If you want to make a user-defined function vectorized, you can wrap your function in a call to the Vectorize() function. For example, consider the following implementation of the sign function:\n\nsgn_non_vectorized &lt;- function(x) {\n  if(x &lt; 0) {\n    return(\"negative\")\n  } else if(x == 0) {\n    return(\"zero\")\n  } else {\n    return(\"positive\")\n  }\n}\n\nCalling sgn_non_vectorized(-1) is fine:\n\nsgn_non_vectorized(-1)\n\n[1] \"negative\"\n\n\nhowever calling sgn_non_vectorized(c(-1, 1)) causes problems:\n\nsgn_non_vectorized(c(-1, 1))\n\nError in if (x &lt; 0) {: the condition has length &gt; 1\n\n\nWe can fix this using the Vectorize() function:\n\nsgn_vectorized &lt;- Vectorize(\n  function(x){sgn_non_vectorized(x)}\n)\nsgn_vectorized(c(-1, 1))\n\n[1] \"negative\" \"positive\"\n\n\nBy the way, note that the above example also demonstrates the following: unlike in Python, you do not need to explicitly include a return statement in the body of an R function. By default, R will return whatever the final non-assignment step of your code is.\n\nLeveraging Vectorization to Bypass Loops\nAn interesting consequence of the vectorized nature of R is that we can actually bypass loops in certain contexts. Functions that help us do this include (but are not limited to):\n\napply(): applies a function to either rows or columns (or both) of an array or matrix\nlapply() and sapply(): applies a function across a list (differences between the functions largely boil down to the data type/structure of output)\n\nAs an example, consider the following matrix M (which we encountered above)\n\nM\n\n     [,1] [,2]\n[1,]    1    2\n[2,]    3    4\n[3,]    5    6\n\n\nTo compute row averages (i.e. averages across rows), we could use a for loop:\n\nrow_avgs &lt;- c()\nfor(k in 1:nrow(M)) {\n  row_avgs &lt;- c(row_avgs, mean(M[k,]))\n}\nrow_avgs\n\n[1] 1.5 3.5 5.5\n\n\nAlternatively, we could use the apply() function:\n\napply(M, MARGIN = 1, FUN = mean)\n\n[1] 1.5 3.5 5.5"
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#custom-error-messages-in-functions",
    "href": "Pages/Lab00/intro2r.html#custom-error-messages-in-functions",
    "title": "Lab 00: Introduction to R",
    "section": "Custom Error Messages in Functions",
    "text": "Custom Error Messages in Functions\nIf we like, we can build in descriptive errors into a function. For example, say we want to define a function called add_2() which takes in a single numerical input x and outputs the value of x + 2. Further suppose we’d like our function to return an error message stating \"Input must be of type 'double' or 'integer'\" if the input is not numerical (i.e. neither an integer nor a double). We can do so by using the stop() function:\n\nadd_2 &lt;- function(x) {\n  if(!(typeof(x) == \"double\") & !(typeof(x) == \"integer\")) {\n    stop(\"Input must be of type 'double' or 'integer'\")\n  } else {\n    return(x + 2)\n  }\n}\n\nadd_2(4.2)\n\n[1] 6.2\n\nadd_2(\"hello\")\n\nError in add_2(\"hello\"): Input must be of type 'double' or 'integer'"
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#recursion",
    "href": "Pages/Lab00/intro2r.html#recursion",
    "title": "Lab 00: Introduction to R",
    "section": "Recursion",
    "text": "Recursion\nYou have likely encountered the notion of recursion before, either in its mathematical or computing context. Loosely speaking, in computer science, we us the term recursion to describe a situation in which the current computational step depends on one or more computational steps that were completed in the past.\nA simple mathematical example of recursion is the Fibonacci Numbers, which is a sequence \\(\\{a_n\\}\\) of numbers defined through the recursive relationship \\[ a_0 = 0, \\quad a_1 = 1, \\quad a_{n} = a_{n - 1} + a_{n - 2} \\ (\\forall n \\geq 2) \\] For instance, the first 7 Fibonacci numbers are \\(\\{0, 1, 1, 2, 3, 5, 8\\}\\).\nLet’s say we want to create a function fib() that takes in a single integer input n and outputs the nth Fibonacci number. Firstly, this is not as simple as the examples we’ve seen before because there isn’t a closed-form formula for the nth Fibonacci number1.\n\nHowever, we can think of defining this function recursively. The key is to note that, if we have configured our fib() function correctly, we have that\n\nfib(n) = fib(n) + fib(n - 1)\n\nWe also know that\n\nfib(0) = 0\nfib(1) = 1\n\nThis motivates us to define our fib() function as follows:\n\nfib &lt;- Vectorize(function(n) {\n  if(n == 0) {\n    return(0)\n  } else if (n == 1) {\n    return(1)\n  } else {\n    return( fib(n - 1) + fib(n - 2))\n  }\n})\n\nAs an example:\n\nfib(1:7)\n\n[1]  1  1  2  3  5  8 13\n\n\nwhich matches what we computed “by hand”, above."
  },
  {
    "objectID": "Pages/Lab00/intro2r.html#footnotes",
    "href": "Pages/Lab00/intro2r.html#footnotes",
    "title": "Lab 00: Introduction to R",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nactually, this is a lie- there does exist a closed form expression for the nth Fibonacci number, but for the purposes of this exercise we are going to ignore that fact↩︎"
  },
  {
    "objectID": "Pages/Info/policies.html",
    "href": "Pages/Info/policies.html",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Welcome to PSTAT 100: Data Science Concepts and Analysis! I am very excited to join you as your instructor this quarter. Our journey together will take us through the basics of Data Science, and aims to prepare you for your future endeavors in the field, whether they be in classes, industry, or academia. Here’s to a great quarter!     – Ethan"
  },
  {
    "objectID": "Pages/Info/policies.html#course-staff-and-lecture-logistics",
    "href": "Pages/Info/policies.html#course-staff-and-lecture-logistics",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Course Staff and Lecture Logistics",
    "text": "Course Staff and Lecture Logistics\nInstructor: Ethan P. Marzban (he/him)\n\n\n\n\n\n\nLecture Times and Location\n\n\n\nM, T, W, R from 12:30 - 1:35pm in ILP 2207\n\n\nTeaching Assistant: Erika McPhillips\nSections:\n\nTuesdays and Thursdays, 2 - 2:50pm in PHELPS 1517\nTuesdays and Thursdays, 3 - 3:50pm in PHELPS 1517"
  },
  {
    "objectID": "Pages/Info/policies.html#course-description",
    "href": "Pages/Info/policies.html#course-description",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Course Description",
    "text": "Course Description\nAs stated in the UCSB Course Catalog:\n\nOverview of data science key concepts and the use of tools for data retrieval, analysis, visualization, and reproducible research. Topics include an introduction to inference and prediction, principles of measurement, missing data, and notions of causality, statistical traps, and concepts in data ethics and privacy. Case studies illustrate the importance of domain knowledge.\n\nIndeed, this course is designed to be a hands-on introduction to Data Science for intermediate-level students with some exposure to probability and basic computation skills, but with few or no upper-division courses in statistics."
  },
  {
    "objectID": "Pages/Info/policies.html#prerequisites",
    "href": "Pages/Info/policies.html#prerequisites",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Prerequisites:",
    "text": "Prerequisites:\n\nPSTAT 120A (Probability at a calculus-based level)\nMATH 4A (a first pass at Linear Algebra)\nPrior experience with a programming language (e.g. Python through CMPSC 9 or CMPSC 16).\n\nNote on Programming: the primary programming language of this course will be R, though you are not expected to necessarily have prior experience coding with R (so long as you have experience coding in another language, e.g. Python, Julia, etc.). With that said, if this is your first time coding in R, I encourage you to consult the Lab00 files on this course website (accessible by clicking the relevant link in the navbar)."
  },
  {
    "objectID": "Pages/Info/policies.html#textbooksreadings",
    "href": "Pages/Info/policies.html#textbooksreadings",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Textbooks/Readings",
    "text": "Textbooks/Readings\nThere are four main textbooks for this class (all of which are freely available online; links provided below); readings will be regularly assigned from them:\n\nModern Data Science with R (2e), by Benjamin S. Baumer, Daniel T. Kaplan, and Nicholas J. Horton.\nIntroduction to Modern Statistics, 2nd Ed., by Mine Çetinkaya-Rundel and Johanna Hardin\nR for Data Science (2e), by Hadley Wickham, Mine Çetinkaya-Rundel, and Garrett Grolemund\nAn Introduction to Statistical Learning with Applications in R, by Gareth James, Daniela Witten, Trevor Hastie, and Robert Tibshirani\n\nWe will also read through a handful of articles; these will all appear in the Course Schedule.\n\nAdditional (Optional) Texts\n\nLearning Data Science, by Sam Lau, Joey Gonzalez, and Deb Nolan  A great comprehensive resource, but written in Python (so be aware!)\nAn Introduction to R, by Alex Douglas, Deon Roos, Francesca Mancini, Ana Couto & David Lusseau  A good textbook for those of you new to programming in R"
  },
  {
    "objectID": "Pages/Info/policies.html#learning-outcomes",
    "href": "Pages/Info/policies.html#learning-outcomes",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Learning Outcomes",
    "text": "Learning Outcomes\nBy the end of this course, you should be able to:\n\ncritically assess data quality and sampling design\nretrieve, inspect, and clean raw data\nunderstand the basics of exploratory, descriptive, visual, and inferential techniques\ninterpret and communicate results in context"
  },
  {
    "objectID": "Pages/Info/policies.html#assessments",
    "href": "Pages/Info/policies.html#assessments",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Assessments",
    "text": "Assessments\n\nLabs: shorter, structured coding assignments designed to introduce programming concepts and skills. There will be a Lab assignment associated with every Discussion Section; labs will be due (TBD).\nHomeworks: slightly larger in scope than labs; will contain both programming and theoretical/conceptual concepts. We will have a total of 2 homework assignments released throughout the quarter. Homeworks are designed to probe your theoretical understanding of concepts that arise in the field of Data Science, as well as prepare you for the projects by asking you to address more open-ended questions.\nMid-Quarter Project: more open-ended than homeworks and labs, and is designed to more closely simulate real-world data science projects and endeavors. Details on the mid-quarter project will be released in the later part of Week 1.\nFinal Project: a final, comprehensive project that will be due on Friday August 1, 2025. You will be required to work in teams on the Final Project.\n\n\n\n\n\n\n\nFinal Project\n\n\n\nThe final project will be due by 11:59pm on Friday, August 1, 2025.\n\n\n\n2 In-Class Assessments (ICAs) will be administered (see below for dates). I hesitate to call these “exams” because they are not intended to be as high-stakes as exams, however they are designed to test your retention of course material. More information will be released as we approach the date of the first ICA.\n\n\n\n\n\n\n\nAssessment Dates\n\n\n\n\nIn-Class Assessment 1: Thursday, July 3, 2025 in Harold Frank Hall 1104, during our regularly-scheduled lecture time\nIn-Class Assessment 1: Thursday, July 24, 2025 in Harold Frank Hall 1104, during our regularly-scheduled lecture time\n\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThere will be no ICAs offered at alternate times, for any reasons. So, please plan accordingly!\n\n\n\nFinal Course Grades\nYour final course grade will be computed according to the following weights:\n\n\n\nAssessment\nWeight\n\n\n\n\nLabs\n10%\n\n\nHW\n20% (10% each)\n\n\nMid-Quarter Project\n20%\n\n\nFinal Project\n25%\n\n\nIn-Class Assessments\n25%\n\n\n\nYour final letter grade will be issued according to the following scheme (note that I am using interval notation: \\([a, b)\\) means all numbers greater than or equal to \\(a\\) but less than (and not equal to) \\(b\\)):\n\n\n\n\n\n\n\n\n\nGrade\nCourse Percentage\n\n\n\n\nA+\n100%\n\n\nA\n[95.0000, 100.0000)\n\n\nA-\n[90.0000, 95.0000)\n\n\nB+\n[86.3333, 90.0000)\n\n\nB\n[83.3333, 86.3333)\n\n\nB-\n[80.0000, 83.3333)\n\n\n\n\n\n\n\n\nGrade\nCourse Percentage\n\n\n\n\nC+\n[76.0000, 80.3333)\n\n\nC\n[73.3333, 76.3333)\n\n\nC-\n[70.0000, 73.3333)\n\n\nD+\n[66.0000, 70.3333)\n\n\nD\n[63.3333, 66.3333)\n\n\nD-\n[60.0000, 63.3333)\n\n\nF\n&lt; 60%\n\n\n\n\n\n\nI have elected to adopt an uncurved grading scheme to eliminate any sense of “competition” among students; I highly encourage you all to collaborate with and uplift each other. Having said that, I will certainly consider adjusting the cutoffs at the end of the quarter if necessary."
  },
  {
    "objectID": "Pages/Info/policies.html#policies",
    "href": "Pages/Info/policies.html#policies",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Policies",
    "text": "Policies\n\nLate Submissions\nI understand that life happens! To that effect, I am allowing:\n\nOne late homework, which must be submitted within 24 hours of the original deadline\nTwo late labs, which must be submitted within 24 hours of the original deadline\n\nGiven that the projects will be submitted in groups, no late submissions for the projects will be accepted for any reason. Additionally, as stated above, we will not be offering any make-ups for the ICAs; furthermore, failure to take both ICAs will result in a grade of “F” being administered.\n\n\nCommunication\nThere are two primary means of communication outside of scheduled class meetings: office hours and an EdStem Discussion Forum (please see Canvas for a join link; for security purposes, we are only allowing currently-enrolled students join the discussion forum). If you are unsure of how to reach out to appropriate parties, please consult the following table:\n\n\n\nTopic\nRedirect to…\n\n\n\n\nTroubleshooting codes\nEdStem\n\n\nChecking answers\nOffice hours or EdStem\n\n\nClarifying assignment content\nOffice hours or EdStem\n\n\nAssignment submission\nGradescope\n\n\nRe-evaluation request\nGradescope\n\n\nQuestion about missing grades\nFill Out This Form\n\n\n\nSome additional comments:\n\nPlease note that we (the course staff) request you refrain from emailing us except in case of extreme emergency (it is up to you to decide what is an ‘emergency’). Please bring all of your questions to the course staff during either Office Hours or after Lecture/Section. Thank you!\nIf you have questions or concerns about missing grades, please use the form linked in the table above. You are allowed to submit the form multiple times, but we ask that you please wait at least 48 business hours before submitting follow-ups. Thank you!\n\n\n\nCollaboration and Academic Integrity\nData Science (as we will see) is an inherently collaborative field. Indeed, collaboration is required for both projects; collaboration is also encouraged for homework and lab assignments. However, there are limitations to collaboration:\n\ncollaboration on the ICAs is strictly prohibited\ndo not copy other people’s work and try to pass it off as your own\nif/when you work in groups, include the names of all group members on the assignment\n\nFailure to abide by these principles will be treated as academic misconduct. Anyone found guilty of academic misconduct will be reported to the Academic Senate, and will receive at minimum a failing grade on the assignment in question; further actions may also include failing the course, and marks being made on permanent records. Depending on the severity of the infraction, expulsion is also a possibility.\nBasically, don’t cheat- please! If you’re ever struggling with course material, please come talk to me or the TA’s. We are truly here for you, and want only the best for you.\n\n\nSection Switching\nLab Sections take place in special “Collaborate Classrooms” which are equipped with laptops. There are only a fixed number of seats and laptops in these classrooms, meaning we cannot under any circumstance over-enroll sections. Therefore, if you want to switch section unofficially (we do not have the ability to switch your official enrollment through GOLD), please follow the steps at this link. Any requests to switch sections that do not adhere to the guidelines posted at that link will be ignored.\n\n\nAI Policy\nIt is undeniable that the recent advances in Generative AI (GenAI) and Large Language Models (LLMs) like ChatGPT have reshaped the educational landscape. Indeed, when utilized properly, they can be an incredibly useful power. With that said, I would like to establish some clear ground rules with regards to the use of GenAI in this class:\n\nThe use of AI on ICAs is strictly prohibited.\nThe use of AI on other assignments is discouraged, but not prohibited - I only ask that if you use AI (for a HW, Lab, or Project) that you please cite it.\n\nIf it is found that you used AI without citing its use, this will be treated as academic misconduct.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nPlease be careful when using Generative AI. It is still a relatively new innovation, and can not only occasionally produce inaccurate answers but can also produce unethical answers. Read all terms and conditions carefully, and ensure you understand (a) how the tool will give you an answer, and (b) what the tool will do with your data."
  },
  {
    "objectID": "Pages/Info/policies.html#disabled-students-program-dsp",
    "href": "Pages/Info/policies.html#disabled-students-program-dsp",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Disabled Students Program (DSP)",
    "text": "Disabled Students Program (DSP)\nIf you have a disability, or otherwise require accommodations for the ICAs please reach out to the Disabled Students Program (DSP) ASAP to ensure your request(s) for accommodation can be processed. We ask that all requests be logged at least a week in advance, to ensure the system enough time to process. Please note that we cannot grant any requests for accommodations unless they come to us from DSP directly."
  },
  {
    "objectID": "Pages/Info/policies.html#technology-needs",
    "href": "Pages/Info/policies.html#technology-needs",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Technology Needs",
    "text": "Technology Needs\nAs a part of this course, you will be required to program in R. Though the Lab Sections take place in specially designed classrooms that come equipped with computers, your homework and quizzes may cover R-related questions, which means we expect you to have access to a laptop capable of connecting to the internet. If you do not currently possess such a laptop, please check out UCSB’s Basic Needs Resource page on Technology Resources to try and acquire one."
  },
  {
    "objectID": "Pages/Info/policies.html#disclaimer",
    "href": "Pages/Info/policies.html#disclaimer",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Disclaimer",
    "text": "Disclaimer\nThe instructor reserves the right to modify this syllabus if he deems such modifications academically advisable. Such modifications, should they occur, will be announced publicly."
  },
  {
    "objectID": "Pages/Info/policies.html#faculty-mentor",
    "href": "Pages/Info/policies.html#faculty-mentor",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Faculty Mentor",
    "text": "Faculty Mentor\nThe faculty mentor for this course is Dr. Jack Miller. They can be reached at jbmiller@pstat.ucsb.edu. Please note that Dr. Miller will not be able to authorize regrades or accommodations/extensions for the course; for such inquiries, please utilize the communications channels listed above. Thank you!"
  },
  {
    "objectID": "Pages/Info/policies.html#some-general-tips-for-success",
    "href": "Pages/Info/policies.html#some-general-tips-for-success",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": " Some General Tips for Success",
    "text": "Some General Tips for Success\n\nForm study groups\nData Science is not meant to be a lonely field! There is much we can learn from one another, and it can be an incredibly enlightening experience to discuss problems and ideas with one another. (Just make sure you don’t violate any of the Academic Integrity points listed above)\n\n\nStart things early!\nMake sure you’re giving yourself enough time to complete the homework assignments, labs, projects, and make sure to leave plenty of time to study for the ICAs. I’d recommend creating a weekly schedule for yourself, and allocating time each day for PSTAT 100 material (whether that be working on an assignment, reading lecture slides, or coming to Office Hours.\n\n\nPractice Makes Progress\nThe best way to start learning Data Science is to start doing Data Science. The various textbooks and resources linked on the Course Website come equipped with additional practice problems and exercises which I highly recommend you work through.\n\n\nAttend Office Hours (TA and Instructor) regularly\nEven if you don’t have a specific question, you’re always more than welcome to sit in on Office Hours and listen to other people’s questions. (Sometimes, doing so will help you formulate your own questions!)\n\n\nAttend Lectures and Discussion Sections.\nIt’s true that we do not have an attendance policy, but please don’t let yourselves fall behind on attendance. Studies show that regular exposure is the best way to learn material, and there really is no substitute for going to Section and Lecture. Also, while you’re in Lecture, take your own notes! Even the act of writing things down and having to synthesize what you think is important information can help you process and learn the material in real time.\n\n\nDon’t Be Too Hard on Yourself!\nThough a little stress can be a good motivating factor for some, please don’t stress yourself out too much. Your performance in this course is not an evaluation of who you are as a person!"
  },
  {
    "objectID": "Pages/ICAs.html",
    "href": "Pages/ICAs.html",
    "title": "Information about ICAs",
    "section": "",
    "text": "Solutions to Version A: Link\nPost-ICA Info Document: Link\n\nPlease read this document FULLY before submitting a regrade request.\n\n\n\n\n\n\n\n\nReminder\n\n\n\nICA01 is taking place on Thursday July 3, 2025 from 12:30 - 1:35 pm in Harold Frank Hall 1104 (note that this is NOT our usual lecture classroom).\n\n\n\nInformation Document (PLEASE READ): Link\n\nNote: The “R Cheatsheets” that will be provided are exactly the files that appear on the Course Server, under the Cheatsheets/ subdirectory.  \n\nCover Page: Link\n\nThis is the cover page that will be attached to the ICA on Thursday - I encourage you to read through it now, so you don’t have to spend time reading through it during the actual ICA!  \n\nPractice Problems: Blank Solutions\n\nIf you feel there are typos, please leave a comment on the document.  \n\nSpring 2024 ICA01: Blank Solutions\n\nThis is the ICA01 I administered in Spring 2024, when I last taught this course.\nImportant: Certain problems are out-of-scope, because the order of topics has been changed slightly since Spring 2024. Additionally, the Spring 2024 ICA01 was entirely multiple choice whereas the Summer 2025 ICA will consist of a mix of multiple choice and free response questions (please see the Information Document linked above)."
  },
  {
    "objectID": "Pages/ICAs.html#ica-01",
    "href": "Pages/ICAs.html#ica-01",
    "title": "Information about ICAs",
    "section": "",
    "text": "Solutions to Version A: Link\nPost-ICA Info Document: Link\n\nPlease read this document FULLY before submitting a regrade request.\n\n\n\n\n\n\n\n\nReminder\n\n\n\nICA01 is taking place on Thursday July 3, 2025 from 12:30 - 1:35 pm in Harold Frank Hall 1104 (note that this is NOT our usual lecture classroom).\n\n\n\nInformation Document (PLEASE READ): Link\n\nNote: The “R Cheatsheets” that will be provided are exactly the files that appear on the Course Server, under the Cheatsheets/ subdirectory.  \n\nCover Page: Link\n\nThis is the cover page that will be attached to the ICA on Thursday - I encourage you to read through it now, so you don’t have to spend time reading through it during the actual ICA!  \n\nPractice Problems: Blank Solutions\n\nIf you feel there are typos, please leave a comment on the document.  \n\nSpring 2024 ICA01: Blank Solutions\n\nThis is the ICA01 I administered in Spring 2024, when I last taught this course.\nImportant: Certain problems are out-of-scope, because the order of topics has been changed slightly since Spring 2024. Additionally, the Spring 2024 ICA01 was entirely multiple choice whereas the Summer 2025 ICA will consist of a mix of multiple choice and free response questions (please see the Information Document linked above)."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#important-lab01-information",
    "href": "Lectures/Lec03/Lec03.html#important-lab01-information",
    "title": "PSTAT 100: Lecture 03",
    "section": " Important Lab01 Information",
    "text": "Important Lab01 Information\n\nMake sure you render your lab to a PDF, and submit the PDF to gradescope (I’ll quickly show you how to do this on the server now).\nFOLLOW THE INSTRUCTIONS ON THE LAB! (I already see some Gradescope submissions that haven’t followed all the instructions, especially when it comes to adding/removing names to your lab submission).\n\nPlease note: we’ll be lenient for the first couple of labs, but starting next week the grader reserves the right to deduct points for failing to follow instructions stated on the lab assignment.\n\nPlease also don’t forget to submit by 11:59pm tonight (Wednesday) on Gradescope!"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#leadup",
    "href": "Lectures/Lec03/Lec03.html#leadup",
    "title": "PSTAT 100: Lecture 03",
    "section": " Leadup",
    "text": "Leadup\nSummarizing Data\n\nData can be highly informative.\nThe information it provides, however, is oftentimes not immediately apparent.\n\nIndeed, it is the job of the data scientist to be able to extract the meaning from the data\nIt is also the job of the data scientist to be able to effectively communicate this meaning to an audience.\n\nOne of the most important ways we can accomplish this is by producing appropriate summaries of our data.\n\nThe branch of statistics known as descriptive statistics is essentially dedicated to the craft of effectively describing (i.e. summarising) data."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#leadup-1",
    "href": "Lectures/Lec03/Lec03.html#leadup-1",
    "title": "PSTAT 100: Lecture 03",
    "section": " Leadup",
    "text": "Leadup\nSummarizing Data\n\nBroadly speaking, there are two types of summaries we could produce: numerical and visual\n\nWe’ll spend most of our time today and tomorrow talking about visual summaries, and then take a crack at numerical summaries next week\n“Visual summaries” go by many different names - “graphs”, “plots”, “charts”, etc.\n\nToday, we’ll talk about a few different types of plots, and when they are appropriate to use\n\nTomorrow, we’ll dive deeper into the mechanisms behind creating plots, and some principles for effective visualization."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#review-variable-classification",
    "href": "Lectures/Lec03/Lec03.html#review-variable-classification",
    "title": "PSTAT 100: Lecture 03",
    "section": " Review: Variable Classification",
    "text": "Review: Variable Classification\nFull Scheme\n\n\n\n\n\n\n\ndata_classification\n\n\ncluster_main\n\n\n\ncluster_0\n\n\n\ncluster_1\n\n\n\ncluster_2\n\n\n\ncluster_3\n\n\n\n\nData\n\nVariable\n\n\n\nnumerical\n\nNumerical\n\n\n\nData-&gt;numerical\n\n\n\n\n\ncategorical\n\nCategorical\n\n\n\nData-&gt;categorical\n\n\n\n\n\ncontinuous\n\nContinuous\n\n\n\nnumerical-&gt;continuous\n\n\n\n\n\ndiscrete\n\nDiscrete\n\n\n\nnumerical-&gt;discrete\n\n\n\n\n\nnominal\n\nNominal\n\n\n\ncategorical-&gt;nominal\n\n\n\n\n\nordinal\n\nOrdinal\n\n\n\ncategorical-&gt;ordinal"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#mock-dataset",
    "href": "Lectures/Lec03/Lec03.html#mock-dataset",
    "title": "PSTAT 100: Lecture 03",
    "section": " Mock Dataset",
    "text": "Mock Dataset\nClass Standing\n\nLet’s consider another mock dataset, this one containing the standing (i.e. Freshman, Sophomore, Junior, or Senior) of a handful of (fictitious) students in a (fictitious) course:\n\n\n\nstandings &lt;- c( \"Freshman\",     \"Sophomore\",    \"Freshman\",     \"Junior\",       \"Sophomore\",    \"Freshman\",\n                \"Sophomore\",    \"Junior\",       \"Junior\",       \"Sophomore\",    \"Junior\",       \"Junior\",\n                \"Senior\",       \"Sophomore\",    \"Junior\",       \"Freshman\",     \"Freshman\",   \"Senior\" )\n\n\n\n\n\n\n\n\n\nCheck your Understanding\n\n\nWhat type of variable is standings (i.e. what is its classification)?\n\n\n\n\n\nEven though this is a relatively small dataset, it’s still difficult to make sense of the raw data."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nNumerical Summaries\n\nSo, we’d like to summarize this dataset in some way.\n\nEnter, descriptive statistics.\n\nTo start, it seems natural to tabulate the number of students in our dataset that belong to each class standing.\n\nSuch a table is called a frequency table.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFreshman\nSophomore\nJunior\nSenior\n\n\n\n\n5\n5\n6\n2\n\n\n\n\n\n\n\nThis is an example of a numerical summary.\n\nAgain, notice how much easier it was to extract information from the frequency table than it was to extract from the raw data!"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-1",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-1",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nNumerical Summaries\n\nHow can we convert this to a graphical summary?\nHere’s one idea: draw four rectangles (i.e. “bars”), one for each of the four possible standings.\nWe can make the height of each bar proportional to the corresponding frequency\n\nFor example, the height of the bar corresponding to Freshmen would be 5; the height of the bar corresponding to Sophomores would be 5; etc."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-2",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-2",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nstandings Dataset"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-3",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-3",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nBarplots/Bargraphs\n\nThis type of plot is called a barplot (or bargraph), and is the ideal visualization for a categorical variable.\nIn general, for a categorical variable with k categories C1 through Ck with corresponding frequencies f1 through fk, the resulting barplot will have k bars with the height of the ith bar given by fi."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#pie-charts-rip",
    "href": "Lectures/Lec03/Lec03.html#pie-charts-rip",
    "title": "PSTAT 100: Lecture 03",
    "section": " Pie Charts: RIP",
    "text": "Pie Charts: RIP\n\nPerhaps you’ve heard of (or seen) pie charts\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPie charts are practically never used within the statistical commmunity anymore.\n\nBasically, areas of circular sectors can be misleading.\n\n\n\n\n\n\nStick with a barplot!\nIf you really desire a desert-themed plot, consider a donut plot:"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-4",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-4",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nNumerical Variable\n\nSo, that takes care of what type of plot to make when we have a single categorical variable. What about when we have a single numerical value?\nAs another concrete example, consider the following mock dataset comprised of exam scores (reported as a percentage between 0 and 100):\n\n\n\nscores &lt;- c(89.1,   87.1,   90.1,   97.4,   99.1,   100.0,  84.1,   89.4,\n            92.3,   99.4,   95.2,   91.0,   90.0,   87.4,   89.0,   92.4)\n\n\n\nDoes it make sense to generate a barplot?\n\nNot really; we’d have 16 bars, each with height 1. This doesn’t summarize the data in any way- we might as well have just looked at the raw data!"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-5",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-5",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nNumerical Variable\n\nWe can, however, “inject” categories into our data.\n\nThat is; though we do not expect to have two or more students with exactly the same score, it is plausible to have a great many students with scores within some specified range\n\nTo start, let’s consider ranges of scores that are 5 points in width:"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-6",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-6",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nNumerical Variable\n\nThere are different conventions for edge cases, but the most common is to have left-inclusive intervals.\n\nFor example, given the categories we had on the previous slide, and observation equal to 85 would fall in the second category and not the first (I have tried to make this clear by using interval notation in the category titles).\n\nBy the way, we no longer call this table a frequency table; instead we call it a distribution table\nWe can, however, treat the distribution table in a similar manner to a frequency table: construct as many bars as we have cells, with heights proportional to the counts within each cell."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-7",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-7",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nNumerical Variable\n\n\nThe resulting plot is called a histogram."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-8",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-8",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nBinwidths"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-9",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-9",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nBinwidths"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-10",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-10",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nBinwidths\n\n\nNotice the effect that changing the binwidth has on the overall shape of the histogram!\n\nWhen creating your own histograms, pay attention to your binwidth.\nIn practice, there isn’t a single ideal binwidth that should be used; instead, play around with a few different binwidths before settling on one you feel results in a histogram that best captures the distribution of your data."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-11",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-11",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nBoxplots"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-12",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-12",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nBoxplots and Histograms\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote that both plots indicate a sort of “skew” to the data that is pulling the average of scores to the left.\n\nThe skew is, however, not strong enough to introduce outliers into the dataset (how do we know that?)"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#descriptive-statistics-13",
    "href": "Lectures/Lec03/Lec03.html#descriptive-statistics-13",
    "title": "PSTAT 100: Lecture 03",
    "section": " Descriptive Statistics",
    "text": "Descriptive Statistics\nExample: Boxplots\nExample: 100 people were asked to run one mile; their completion times (in minutes) were recorded, and the following boxplot was generated:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWhat were the slowest and fastest completion times?\nWhat was the median completion time?\n\n\n\n\n\nAnna ran a mile in around 8.5 minutes. Aproximately what percentage of runners were faster than her?"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#quick-summary",
    "href": "Lectures/Lec03/Lec03.html#quick-summary",
    "title": "PSTAT 100: Lecture 03",
    "section": " Quick Summary",
    "text": "Quick Summary\nUnivariate Plots\n\nSo, to quickly summarize:\n\nGiven a single categorical variable, use a barplot/bargraph.\nGiven a single numerical variable, you can use either a histogram or a boxplot.\n\nIf you have a discrete variable, you can consider generating a barplot as opposed to a histogram, but it’s a bit context-dependent."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#two-variable-plots-1",
    "href": "Lectures/Lec03/Lec03.html#two-variable-plots-1",
    "title": "PSTAT 100: Lecture 03",
    "section": " Two-Variable Plots",
    "text": "Two-Variable Plots\n\nMost datasets are comprised of more than just one variable. As such, a common question among Data Scientists is: how do the different variables in a given dataset relate to one another?\nWe’ll tackle the case of comparing two variables today, and save our multivariate considerations for later.\nEven in the two-variable case, there are three subcases to consider:\n\nComparing two numerical variables\nComparing a numerical variable and a categorical variable\nComparing two categorical variables"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#two-numerical-variables",
    "href": "Lectures/Lec03/Lec03.html#two-numerical-variables",
    "title": "PSTAT 100: Lecture 03",
    "section": " Two Numerical Variables",
    "text": "Two Numerical Variables\n\nLet’s consider (yet another) mock dataset; this one contains observations on five students’ commute times (in minutes) and their commute distances (in miles).\n\n\n\n\n\n\n\n\n\n\n\nCommute.Dist.\nCommute.Time\n\n\n\n\n0.5\n3\n\n\n1\n2\n\n\n1.5\n4\n\n\n2\n6\n\n\n2.5\n8\n\n\n\n\n\n\n\nNote that each row of this dataframe (which, since our data is tidy, is equivalent to each observation in the dataset) is a pair of numbers.\n\nFrom our mathematical training, isn’t it tempting to then plot these pairs of numbers on a Cartesian Coordinate system?"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#scatterplot",
    "href": "Lectures/Lec03/Lec03.html#scatterplot",
    "title": "PSTAT 100: Lecture 03",
    "section": " Scatterplot",
    "text": "Scatterplot\n\nSuch a plot is called a scatterplot."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#scatterplot-1",
    "href": "Lectures/Lec03/Lec03.html#scatterplot-1",
    "title": "PSTAT 100: Lecture 03",
    "section": " Scatterplot",
    "text": "Scatterplot\nTrends\n\nWhen considering scatterplots, certain patterns may become apparent.\n\nFor example, notice that, on average, as commute distance increases, so does commute time.\n\nSuch patterns are called trends.\nMost trends can be classified along two axes: positive/negative, and linear/nonlinear.\nA positive trend is observed when as x increases so does y; a negative trend is observed when as x increases y decreases.\nA trend whose rate of change is constant is said to be linear; a trend whose rate of change is nonconstant is said to be nonlinear"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#scatterplot-2",
    "href": "Lectures/Lec03/Lec03.html#scatterplot-2",
    "title": "PSTAT 100: Lecture 03",
    "section": " Scatterplot",
    "text": "Scatterplot\nTrends"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#scatterplot-3",
    "href": "Lectures/Lec03/Lec03.html#scatterplot-3",
    "title": "PSTAT 100: Lecture 03",
    "section": " Scatterplot",
    "text": "Scatterplot\nTrends\n\n\nAnother way to describe the findings of a scatterplot is in terms of the association between the variables being compared.\n\nFor instance, if the scatterplot of y vs. x displays a positive linear trend, we would say that x and y have a positive linear association, or that x and y are positively linearly associated."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#your-turn",
    "href": "Lectures/Lec03/Lec03.html#your-turn",
    "title": "PSTAT 100: Lecture 03",
    "section": " Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nYour Turn!\n\n\nTurn to your neighbor(s), and come up with an example of a pair of variables you believe would exhibit a positive association, a pair that you believe would exhibit a negative association, and a pair you believe would exhibit no association.\n\n\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#a-numerical-and-a-categorical-variable",
    "href": "Lectures/Lec03/Lec03.html#a-numerical-and-a-categorical-variable",
    "title": "PSTAT 100: Lecture 03",
    "section": " A Numerical and a Categorical Variable",
    "text": "A Numerical and a Categorical Variable\n\nSuppose that a particular drug claims to reduce the effects of hypertension. To test these claims, suppose 8 people with hypertension were selected; four of them were assigned the drug (treatment group) and the other four were not (control group). The systolic blood pressures of all subjects were recorded:\n\n\n\n\n\n\n\n\n\n\n\n\nID\nGroup\nSyst_BP\n\n\n\n\n1\nControl\n145\n\n\n2\nControl\n140\n\n\n3\nTreatment\n120\n\n\n4\nControl\n143\n\n\n5\nTreatment\n115\n\n\n6\nTreatment\n103\n\n\n7\nControl\n146\n\n\n8\nTreatment\n117"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#a-numerical-and-a-categorical-variable-1",
    "href": "Lectures/Lec03/Lec03.html#a-numerical-and-a-categorical-variable-1",
    "title": "PSTAT 100: Lecture 03",
    "section": " A Numerical and a Categorical Variable",
    "text": "A Numerical and a Categorical Variable\n\nIgnoring the ID variable, rows of our dataframe are once again pairs of objects.\nNow, however, these pairs are not pairs of numbers; hence, plotting them on a Cartesian Coordinate system doesn’t make a whole lot of sense.\nNevertheless, if we so desire, we can generate something resembling a scatterplot, called a dotplot:"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#a-numerical-and-a-categorical-variable-2",
    "href": "Lectures/Lec03/Lec03.html#a-numerical-and-a-categorical-variable-2",
    "title": "PSTAT 100: Lecture 03",
    "section": " A Numerical and a Categorical Variable",
    "text": "A Numerical and a Categorical Variable\nDotplot"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#a-numerical-and-a-categorical-variable-3",
    "href": "Lectures/Lec03/Lec03.html#a-numerical-and-a-categorical-variable-3",
    "title": "PSTAT 100: Lecture 03",
    "section": " A Numerical and a Categorical Variable",
    "text": "A Numerical and a Categorical Variable\nSide-by-Side Boxplot"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#a-numerical-and-a-categorical-variable-4",
    "href": "Lectures/Lec03/Lec03.html#a-numerical-and-a-categorical-variable-4",
    "title": "PSTAT 100: Lecture 03",
    "section": " A Numerical and a Categorical Variable",
    "text": "A Numerical and a Categorical Variable\nSide-by-Side Boxplot\n\nThis type of plot is called a side-by-side boxplot.\nIn general, a side-by-side boxplot has as many boxplots as categories, with the structure of each boxplot governed by the distribution of the numerical variable within each category.\nBy the way, notice that we can still consider the notion of trend, even in a side-by-side boxplot!\n\nFor example, given the data we observed, does the drug appear affective in lowering systolic blood pressure? How can you tell?"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#a-word-of-caution",
    "href": "Lectures/Lec03/Lec03.html#a-word-of-caution",
    "title": "PSTAT 100: Lecture 03",
    "section": " A Word of Caution",
    "text": "A Word of Caution\n\n\n\n\n\n\nCaution\n\n\nAssociation does not imply causation.\n\n\n\n\nIn other words, just becase blood pressures within the treatment group appear, on average, lower than those within the control group, doesn’t mean we can definitely concldue the drug caused this difference.\n\nFor instance, what if, by chance, people in the treatment group happened to lead more active lifestyles - in this case, how do we know it wasn’t the activeness of lifestyle that drove the drop in blood pressure and not the drug?\n\nWe’ll talk about causation toward the end of this course."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#your-turn-2",
    "href": "Lectures/Lec03/Lec03.html#your-turn-2",
    "title": "PSTAT 100: Lecture 03",
    "section": " Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nYour Turn!\n\n\nFor each of the following scenarios, identify the type of graph you think is best.\n\n\nAllison wants to know whether certain majors perform better on PSTAT 120A exams.\nTristan wants to know whether higher temperatures correspond to higher humidity levels.\nMorgan has collected information on how long it takes a sample of 100 athletes to complete an obstacle course, and would like to visualize the distribution of completion times.\n\n\n\n\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#two-categorical-variables",
    "href": "Lectures/Lec03/Lec03.html#two-categorical-variables",
    "title": "PSTAT 100: Lecture 03",
    "section": " Two Categorical Variables",
    "text": "Two Categorical Variables\n\nFinally, we tackle the case of two categorical variables.\nInstead of simulated data… let’s look at y’all’s data!\n\n\n\n\n\n\n\n\n\n\n\nAnimal\nNumber\n\n\n\n\nCats\nEven\n\n\nCats\nOdd\n\n\nDogs\nEven\n\n\nCats\nEven\n\n\nDogs\nOdd\n\n\nDogs\nOdd\n\n\nDogs\nOdd\n\n\nDogs\nEven"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#two-categorical-variables-1",
    "href": "Lectures/Lec03/Lec03.html#two-categorical-variables-1",
    "title": "PSTAT 100: Lecture 03",
    "section": " Two Categorical Variables",
    "text": "Two Categorical Variables\nAnimals and Numbers\n\nI asked you two questions: whether you prefer cats or dogs, and whether you prefer even or odd numbers.\n\nBoth of these variables (Animal and Number) are categorical.\n\nBut what does it mean to compare these variables?\nWe can’t even really make a dotplot.\n\nThere are only four possible combinations: (Cats, Even), (Cats, Odd), (Dogs, Even), (Dogs, Odd).\nSo our dotplot would just have four points, with a bunch of points stacked on top of each other."
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#two-categorical-variables-2",
    "href": "Lectures/Lec03/Lec03.html#two-categorical-variables-2",
    "title": "PSTAT 100: Lecture 03",
    "section": " Two Categorical Variables",
    "text": "Two Categorical Variables\nAnimals and Numbers"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#two-categorical-variables-3",
    "href": "Lectures/Lec03/Lec03.html#two-categorical-variables-3",
    "title": "PSTAT 100: Lecture 03",
    "section": " Two Categorical Variables",
    "text": "Two Categorical Variables\nAnimals and Numbers\n\nSure, if some combinations of Animal and Number preferences were completely absent from the data, that would be something we could tell from the dotplot.\nThat’s not the case here, though; among all 25 points of data, all four combinations have been covered.\nBut, remember: even though it looks like there are only 4 plots on our dotplot, there are actually 25; many of them are stacked on top of each other.\nSo, wouldn’t it be nice to incorporate information on how many points are stacked on top of each other?"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#two-categorical-variables-4",
    "href": "Lectures/Lec03/Lec03.html#two-categorical-variables-4",
    "title": "PSTAT 100: Lecture 03",
    "section": " Two Categorical Variables",
    "text": "Two Categorical Variables\nAnimals and Numbers"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#two-categorical-variables-5",
    "href": "Lectures/Lec03/Lec03.html#two-categorical-variables-5",
    "title": "PSTAT 100: Lecture 03",
    "section": " Two Categorical Variables",
    "text": "Two Categorical Variables\nAnimals and Numbers\n\nAmong cat people, there seems to be a clear preference for even numbers over odd numbers\n\nAmong dog people, there seems to be a roughly even split between even- and odd-preferences\n\nAmong those who prefer even numbers, there is a relatively even split among cat and dog people\n\nAmong those who prefer odd numbers, there seems to be a prevalence of dog people"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#two-categorical-variables-6",
    "href": "Lectures/Lec03/Lec03.html#two-categorical-variables-6",
    "title": "PSTAT 100: Lecture 03",
    "section": " Two Categorical Variables",
    "text": "Two Categorical Variables\nSome Comments\n\nNow, we “cheated” a bit.\nSpecifically, we introduced information about the number of observations corresponding to each (Animal, Number) combination.\nThat is, in essence, we’ve included information on our plot about a third variable!\nThis is one of the strange things about comparing two categorical variables: it is essentially impossible to make such a comparison without resorting to including cross-tabulated values.\n\nThis will segue us nicely into our discussion tomorrow on plots that incorporate information from three or more variables!"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#extensions",
    "href": "Lectures/Lec03/Lec03.html#extensions",
    "title": "PSTAT 100: Lecture 03",
    "section": " Extensions",
    "text": "Extensions\n\nThe plots we talked about today are just the basics!\n\n\n\n\nViolinplots\n\n\n\n\n\n\n\n\n\n\n\n\nHexagonal Heatmaps"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#extensions-1",
    "href": "Lectures/Lec03/Lec03.html#extensions-1",
    "title": "PSTAT 100: Lecture 03",
    "section": " Extensions",
    "text": "Extensions\nRidgeline Plot:"
  },
  {
    "objectID": "Lectures/Lec03/Lec03.html#next-time",
    "href": "Lectures/Lec03/Lec03.html#next-time",
    "title": "PSTAT 100: Lecture 03",
    "section": " Next Time",
    "text": "Next Time\n\nIn tomorrow’s lecture, we’ll introduce a framework for producing graphics using computer softwares.\nWe’ll also discuss some multivariate plots (i.e. plots that incorporate information from more than 2 variables).\nFinally, we’ll talk a little bit about color theory, and some principles of good visualizations.\nFriendly Reminder: keep working on Homework 1!\nAnother Friendly Reminder: don’t forget to submit Lab 01 by 11:59pm tonight!\nFinal Friendly Reminder: please submit all required DSP paperwork ASAP (no later than tomorrow to ensure they get processed in time for the first ICA next week)"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#big-data",
    "href": "Lectures/Lec05/Lec05.html#big-data",
    "title": "PSTAT 100: Lecture 05",
    "section": " Big Data",
    "text": "Big Data\n\nHow many of you have heard the term big data?\nAt the most basic level, big data is data that is big. But what do we really mean by “big,” especially seeing as datasets are comprised by both the number of observations and the number of variables?\nEssentially there are three situations to consider:\n\nA large number of both observations and variables\nA much larger number of observations than variables\nA much larger number of variables than observations"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#big-data-1",
    "href": "Lectures/Lec05/Lec05.html#big-data-1",
    "title": "PSTAT 100: Lecture 05",
    "section": " Big Data",
    "text": "Big Data\n\nWith the continued improvement of computers and computing, the first two cases on the previous slide are not of as great concern as they were, say, 10 years ago.\nHowever, the third case is still an active area of research.\n\nWhen we have more variables than observations (or even just an absurdly large number of variables), things start to break down quickly, as we will shortly see.\n\nSo, a natural question arises: given a dataset, are all dimensions (variables?) really necessary to convey all of the necessary information?\nThe answer, in some cases, turns out to be “no.”"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#big-data-2",
    "href": "Lectures/Lec05/Lec05.html#big-data-2",
    "title": "PSTAT 100: Lecture 05",
    "section": " Big Data",
    "text": "Big Data\n\nWe’ll spend the better part of two lectures addressing the details behind this answer.\nThere are a few things we’ll need to discuss first.\n\nFor example, what do we really mean by the “dimension” of a dataset?\nWhat does it mean to “convey necessary information?”\n\nThe very first thing we’ll do today is to establish a more mathematical framework for discussing data.\n\nThis is somewhat in contrast to the “data science” view we took last week, breaking data into its semantics and structure.\n\nFirst, let’s take a brief interlude to talk about some numerical summaries of data."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#summary-statistics",
    "href": "Lectures/Lec05/Lec05.html#summary-statistics",
    "title": "PSTAT 100: Lecture 05",
    "section": " Summary Statistics",
    "text": "Summary Statistics\nCentral Tendency\n\nGiven a list x = (x1, …, xn) of n numbers, there are a series of numerical summaries we can provide.\n\nI suspect you will all have seen these concepts before, so I’ll go through them relatively quickly.\n\nFirst question: what is the “center” (or “most typical value”) of x? (Relates to measures of central tendencey)\nTwo main answers: median and mean.\nTo find the median, line up the data in ascending order and then tick off the first and last elements; repeat this process until you are either left with one value (the median), or two values (in which case you add these two values and divide by 2 to obtain the median)."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#summary-statistics-1",
    "href": "Lectures/Lec05/Lec05.html#summary-statistics-1",
    "title": "PSTAT 100: Lecture 05",
    "section": " Summary Statistics",
    "text": "Summary Statistics\nCentral Tendency\n\nFor example, the median of the set \\(\\{-1, 4, 5, 6, 10\\}\\) is 5 and the median of the set \\(\\{-1, 4, 5, 6, 10, 12\\}\\) is 5.5 (I encourage you to do this computation on your own, as practice).\nThe definition of the sample mean is \\[ \\overline{x}_n := \\frac{1}{n} \\sum_{i=1}^{n} x_i \\]\nSo, for example, the mean of \\(\\{-1, 4, 5, 6, 10\\}\\) is 4.8, which we calculated by summing up all five elements and then dividing by 5."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#summary-statistics-2",
    "href": "Lectures/Lec05/Lec05.html#summary-statistics-2",
    "title": "PSTAT 100: Lecture 05",
    "section": " Summary Statistics",
    "text": "Summary Statistics\nCentral Tendency\n\n\nOne way to interpret the mean is as follows: imagine placing a weight of unit 1 at each point xi. Then, imagine finding the point such that a fulcrum placed at this point would result in a perfectly balanced system. The location of this point is the sample mean \\(\\overline{x}_n\\).\n\n\n\n\n\n\nIn R, we use mean() and median() to compute the mean and median (respectively) of a set of numbers, as we saw in Lab01."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#summary-statistics-3",
    "href": "Lectures/Lec05/Lec05.html#summary-statistics-3",
    "title": "PSTAT 100: Lecture 05",
    "section": " Summary Statistics",
    "text": "Summary Statistics\nVariability\n\nTo express how “spread out,” or “variable,” \\(\\vect{x}\\) is, there are three common measures:\n\nRange: \\(\\max\\{\\vect{x}\\} - \\min\\{\\vect{x}\\}\\)\nSample Variance: \\(\\frac{1}{n - 1} \\sum_{i=1}^{n} (x_i - \\overline{x}_n)^2\\)\n\nThe sample standard deviation is just the square root of the sample variance.\n\nInter-Quartile Range (IQR): \\(Q_3 - Q_1\\)\n\nThe variance is perhaps most commonly used, as it has a simple interpretation as the “average distance from the center.”\n\nIn R, these are computed using diff(range()), var(), and IQR(), respectively."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#your-turn",
    "href": "Lectures/Lec05/Lec05.html#your-turn",
    "title": "PSTAT 100: Lecture 05",
    "section": " Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nYour Turn!\n\n\nConsider the list of numbers x = \\((1.1, \\ 2.4, \\ 5.6, \\ 7.8, \\ 100.1)\\).\n\n\nCalculate both the mean and median of x. Which do you think is a “better” description of the central value of x?\nCalculate the range, standard deviation (square root of variance), and IQR of x. Which do you think is a “better” description of the spread of x?\n\n\n\n\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#data-matrix",
    "href": "Lectures/Lec05/Lec05.html#data-matrix",
    "title": "PSTAT 100: Lecture 05",
    "section": " Data Matrix",
    "text": "Data Matrix\n\nLet’s now consider a dataset comprised of n observations across p numerical variables.\n\n\n\n\n\n\n\nName\nHeight (in)\nWeight (lbs)\n\n\n\n\nAlex\n61.5\n130.3\n\n\nBiyonka\n72.4\n180.6\n\n\nCatherine\n58.4\n86.7\n\n\n\n\n\n\nAs an example, consider the dataset to the left with three observations on two numerical variables (height and weight).\n\n\n\nStripping away the Name column and any extraneous formatting information (cell borders, column titles, etc.), what mathematical object are we left with?\n\nThat is, what mathematical object is a grid of numbers?"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#data-matrix-1",
    "href": "Lectures/Lec05/Lec05.html#data-matrix-1",
    "title": "PSTAT 100: Lecture 05",
    "section": " Data Matrix",
    "text": "Data Matrix"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#data-matrix-2",
    "href": "Lectures/Lec05/Lec05.html#data-matrix-2",
    "title": "PSTAT 100: Lecture 05",
    "section": " Data Matrix",
    "text": "Data Matrix"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#data-matrix-3",
    "href": "Lectures/Lec05/Lec05.html#data-matrix-3",
    "title": "PSTAT 100: Lecture 05",
    "section": " Data Matrix",
    "text": "Data Matrix\n\nMore generally, consider a dataset with n observations and p variables.\nThe data matrix is the (n × p) matrix \\(\\mat{X} = \\{x_{ij}\\}\\) such that xij is the ith observation on the jth variable.\nAs indicated in the diagram on the previous slide, there are two ways to think of a matrix: we can call these “row-wise” and “column-wise” viewpoints\n\nIn the “column-wise” viewpoint, we think of \\(\\mat{X}\\) as being comprised of p vectors of length n\nIn the “row-wise” viewpoint, we think of \\(\\mat{X}\\) as being comprised of n transposed vectors of length p\nEssentially, these two viewpoints relate the question: is our data a collection of observations, or a collection of variables?"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#data-matrix-4",
    "href": "Lectures/Lec05/Lec05.html#data-matrix-4",
    "title": "PSTAT 100: Lecture 05",
    "section": " Data Matrix",
    "text": "Data Matrix\nTwo Viewpoints\n\nFor illustrative purposes, consider again our mock height-weight dataset from before: \\[ \\mat{X} = \\begin{pmatrix} 61.5 & 130.3 \\\\ 72.4 & 180.6 \\\\ 58.4 & 86.7 \\\\ \\end{pmatrix} \\]\nThe row-wise viewpoint says: our dataset is comprised of three transposed vectors in \\(\\R^2\\): \\[ \\left\\{ \\begin{pmatrix} 61.5 \\\\ 130.3 \\\\ \\end{pmatrix}, \\  \\begin{pmatrix} 72.5 \\\\ 180.6 \\\\ \\end{pmatrix} , \\  \\begin{pmatrix} 58.4 \\\\ 86.7 \\\\ \\end{pmatrix}  \\right\\} \\]\n\nEach element represents an individual."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#data-matrix-5",
    "href": "Lectures/Lec05/Lec05.html#data-matrix-5",
    "title": "PSTAT 100: Lecture 05",
    "section": " Data Matrix",
    "text": "Data Matrix\nTwo Viewpoints\n\nThe column-wise viewpoint says: our dataset is comprised of two vectors in \\(\\R^3\\): \\[ \\left\\{ \\begin{pmatrix} 61.5 \\\\ 72.4 \\\\ 58.4 \\\\ \\end{pmatrix}, \\ \\begin{pmatrix} 130.3 \\\\ 180.6 \\\\ 86.7 \\\\ \\end{pmatrix} \\right\\} \\]\n\nEach element now represents a variable.\n\nLet’s see what happens if we “plot” our data under these two viewpoints."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#geometry-of-data",
    "href": "Lectures/Lec05/Lec05.html#geometry-of-data",
    "title": "PSTAT 100: Lecture 05",
    "section": " Geometry of Data",
    "text": "Geometry of Data\nAn Example\n\n\n\n\n\n\n\nCloud of Individuals: each point represents an individual in the dataset."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#geometry-of-data-1",
    "href": "Lectures/Lec05/Lec05.html#geometry-of-data-1",
    "title": "PSTAT 100: Lecture 05",
    "section": " Geometry of Data",
    "text": "Geometry of Data\nAn Example\n\n\n\n\n\n\n\nCloud of Variables: each point represents the direction of a variable in the dataset (“how can the variable be described based on the individuals?”)."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#data-matrix-6",
    "href": "Lectures/Lec05/Lec05.html#data-matrix-6",
    "title": "PSTAT 100: Lecture 05",
    "section": " Data Matrix",
    "text": "Data Matrix\nTwo Perspectives\n\nThere isn’t necessarily one viewpoint (row-wise or column-wise) that is always “better” than the other.\n\nIndeed, it’s often useful to be able to switch between the two viewpoints.\n\nWhen dealing with numerical considerations, however, the column-wise viewpoint is often preferred.\nFirstly, all values in a column of a data matrix will be of the same units; this is not the case of the values across a row of the data matrix.\nSecondly, the column-wise viewpoint allows us to compare variables as opposed to comparing units.\nSo, let’s stick with the column-wise viewpoint for now."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#geometry-of-data-2",
    "href": "Lectures/Lec05/Lec05.html#geometry-of-data-2",
    "title": "PSTAT 100: Lecture 05",
    "section": " Geometry of Data",
    "text": "Geometry of Data\n\nIt turns out that many of the summary statistics we talked about earlier today have very nice correspondences with quantities from linear algebra.\nAs an example, consider a vector \\(\\vect{x} = (x_1, \\cdots, x_n)^{\\mathsf{T}}\\) that represents a column from a particular data matrix (i.e. a variable in the cloud of variables). Further suppose that \\(\\overline{x}_n = 0\\) (i.e. that the data is mean-centered)\nWe then have that \\[ \\| \\vect{x} \\| := \\sum_{i=1}^{n} x_{i}^2 \\  \\stackrel{(\\overline{x}_n = 0)}{=} \\  \\sum_{i=1}^{n} (x_i - \\overline{x}_n)^2 \\]\n\nWhich summary statistic does this look like?"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#geometry-of-data-3",
    "href": "Lectures/Lec05/Lec05.html#geometry-of-data-3",
    "title": "PSTAT 100: Lecture 05",
    "section": " Geometry of Data",
    "text": "Geometry of Data\n\nFor two vectors \\(\\vect{x} = (x_1, \\cdots, x_k)^{\\mathsf{T}}\\) and \\(\\vect{y} = (y_1, \\cdots, y_k)^{\\mathsf{T}}\\), their dot product \\[ \\langle \\vect{x}, \\vect{y} \\rangle := \\vect{x} \\cdot \\vect{y} = \\sum_{i=1}^{n} x_i y_i \\] can be interpreted in terms of the sample covariance between two sets of observations.\nThe mean is related to the inner product between \\(\\vect{x}\\) and the unity vector: \\[ \\langle \\vect{x} , \\vect{1} \\rangle = \\begin{pmatrix} x_1 & \\cdots & x_n \\\\ \\end{pmatrix} \\begin{pmatrix} 1 \\\\ \\vdots \\\\ 1 \\\\ \\end{pmatrix} = \\sum_{i=1}^{n} x_i\\]"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#geometry-of-data-4",
    "href": "Lectures/Lec05/Lec05.html#geometry-of-data-4",
    "title": "PSTAT 100: Lecture 05",
    "section": " Geometry of Data",
    "text": "Geometry of Data\n\nSo, again, we see that many of our familiar “statistical” quantities have direct correspondences with Linear Algebra quantities - this is one of the reasons Linear Algebra is so important in Statistics!\nFurthermore, this connection allows us to (in the column-wise viewpoint) obtain summaries of our variables by performing familiar geometric operations.\n\nWant to know how correlated two variables in a dataset are? Take the inner product of their observations!\nWant to know the variability of a particular variable? Find the norm of the vector of observations!\n\nSpeaking of Linear Algebra (and slowly turning our attention back to the initial question from the start of today’s lecture), let’s discuss the “dimensionality” of a dataset."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#dimensionality",
    "href": "Lectures/Lec05/Lec05.html#dimensionality",
    "title": "PSTAT 100: Lecture 05",
    "section": " Dimensionality",
    "text": "Dimensionality\nDifferent Perspectives\n\n\n\n\n\n\n\n\nHeight (in)\nWeight (lbs)\n\n\n\n\n61.5\n130.3\n\n\n72.4\n180.6\n\n\n58.4\n86.7\n\n\n\n\n\nThis dataset seems to have 2 dimensions\n\n\n\n\n\n\nHeight (in)\nHeight (cm)\n\n\n\n\n61.5\n156.21\n\n\n72.4\n183.90\n\n\n58.4\n148.34\n\n\n\n\n\nHow many dimensions does this data have?\n\n\n(How many variables contribute new information?)"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#dimensionality-1",
    "href": "Lectures/Lec05/Lec05.html#dimensionality-1",
    "title": "PSTAT 100: Lecture 05",
    "section": " Dimensionality",
    "text": "Dimensionality\nDifferent Perspectives\n\nFrom a “data science” perspective, we can think of “dimensionality” (in the column-wise viewpoint) as the number of variables that provide new information.\n\nFor instance, in the dataset on the right of the previous slide, we really only have one variable (height) - just because we’ve written it down twice doesn’t mean we’ve gained any new information.\n\nThis is essentially in line with the “Linear Algebra viewpoint” of dimensionality - the dimension of a matrix is just its rank.\n\nIn the column-wise viewpoint, we can think of dimension as just the column rank - i.e. the number of linearly independent columns.\n\nBut, there are a few differences:"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#dimensionality-2",
    "href": "Lectures/Lec05/Lec05.html#dimensionality-2",
    "title": "PSTAT 100: Lecture 05",
    "section": " Dimensionality",
    "text": "Dimensionality\nDifferent Perspectives\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow many dimensions does this data have?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow many dimensions does this data have?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow many dimensions does this data have?"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#dimensionality-3",
    "href": "Lectures/Lec05/Lec05.html#dimensionality-3",
    "title": "PSTAT 100: Lecture 05",
    "section": " Dimensionality",
    "text": "Dimensionality\nDifferent Perspectives\n\n\n\n\n\n\n\n\n\n\n\n\nOnly 1!\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Algebra: 2  Data Science: 1\n\n\n\n\n\n\n\n\n\n\n\n\nLinear Algebra: 2  Data Science: 1"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#dimensionality-4",
    "href": "Lectures/Lec05/Lec05.html#dimensionality-4",
    "title": "PSTAT 100: Lecture 05",
    "section": " Dimensionality",
    "text": "Dimensionality\nDifferent Perspectives\n\nEven though the column rank of the data matrix corresponding to the middle plot would be 2, the resulting matrix would be very nearly singular (noninvertible) and hence we are more likely to say it is of dimension 1.\n\nAdditionally, as we saw in the final panel, if two variables are perfectly related (albeit in a nonlinear fashion), we’d be tempted to say they contain the same information and are, in essence, the same variable repeated twice.\n\nFor example, writing down height and then height squared doesn’t really give two new variables!"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#big-data-again",
    "href": "Lectures/Lec05/Lec05.html#big-data-again",
    "title": "PSTAT 100: Lecture 05",
    "section": " Big Data (Again)",
    "text": "Big Data (Again)\n\nAlright, so let’s return to our “big data problem” from the start of today’s lecture.\nAlready we can perhaps see some justification for why I said, in certain cases, not all variables are needed to convey the full story of a dataset.\n\n\n\n\n\n\n\nHeight (in)\nHeight (cm)\n\n\n\n\n61.5\n156.21\n\n\n72.4\n183.90\n\n\n58.4\n148.34\n\n\n\n\n\n\nThe second column is providing redunant information.\n\nAgain, this is really a one-dimensional dataset!\n\n\n\n\nNow, admittedly, this is a bit of an “extreme” situation - most datasets don’t just have copies of one variable.\n\nSo, how can we figure out which variables (if any) provide redundant information?"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#the-goal",
    "href": "Lectures/Lec05/Lec05.html#the-goal",
    "title": "PSTAT 100: Lecture 05",
    "section": " The Goal",
    "text": "The Goal\n\n\n\n\n\n\n\nGoal: Dimension Reduction\n\n\nReduce the dimension of a dataset with as little loss of information as possible.\n\n\n\n\n\nTwo questions arise:\n\nHow do we “reduce dimensions”?\nWhat do we mean by “little loss of information?”\n\nIndeed, one (admittedly crude) form of dimension reduction is to simply remove one or more columns from a dataset!\nBut, a slightly more creative approach involves leveraging projections.\n\nRecall that we can (geometrically) think of projections as “shadows” cast by a set of points (vectors) onto a subspace."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions",
    "href": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions",
    "title": "PSTAT 100: Lecture 05",
    "section": " Projecting into Smaller Dimensions",
    "text": "Projecting into Smaller Dimensions"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-1",
    "href": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-1",
    "title": "PSTAT 100: Lecture 05",
    "section": " Projecting into Smaller Dimensions",
    "text": "Projecting into Smaller Dimensions"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-2",
    "href": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-2",
    "title": "PSTAT 100: Lecture 05",
    "section": " Projecting into Smaller Dimensions",
    "text": "Projecting into Smaller Dimensions"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-3",
    "href": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-3",
    "title": "PSTAT 100: Lecture 05",
    "section": " Projecting into Smaller Dimensions",
    "text": "Projecting into Smaller Dimensions"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-4",
    "href": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-4",
    "title": "PSTAT 100: Lecture 05",
    "section": " Projecting into Smaller Dimensions",
    "text": "Projecting into Smaller Dimensions"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-5",
    "href": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-5",
    "title": "PSTAT 100: Lecture 05",
    "section": " Projecting into Smaller Dimensions",
    "text": "Projecting into Smaller Dimensions"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-6",
    "href": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-6",
    "title": "PSTAT 100: Lecture 05",
    "section": " Projecting into Smaller Dimensions",
    "text": "Projecting into Smaller Dimensions"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-7",
    "href": "Lectures/Lec05/Lec05.html#projecting-into-smaller-dimensions-7",
    "title": "PSTAT 100: Lecture 05",
    "section": " Projecting into Smaller Dimensions",
    "text": "Projecting into Smaller Dimensions\n\n\nSeems like we might want to preserve as much variance as possible!"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#the-goal-revisited",
    "href": "Lectures/Lec05/Lec05.html#the-goal-revisited",
    "title": "PSTAT 100: Lecture 05",
    "section": " The Goal, Revisited",
    "text": "The Goal, Revisited\n\n\n\n\n\n\nGoal\n\n\nIdentify the directions (in the cloud of variables) along which there is maximal variance. Then, project onto a subspace spanned by these directions to obtain a low-dimensional representation of the data.\n\n\n\n\nWe’ll set up some of the math today, and continue our discussion tomorrow.\nFirst, let’s work toward a more specific goal:\n\n\n\n\n\n\n\n\nGoal\n\n\nIdentify the vector \\(\\vect{v}\\) such that \\(\\mat{X} \\vect{v}\\) (the column mean-centered data projected onto \\(\\vect{v}\\)) has maximum variance (when compared to all other such vectors)."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#pca-a-first-pass",
    "href": "Lectures/Lec05/Lec05.html#pca-a-first-pass",
    "title": "PSTAT 100: Lecture 05",
    "section": " PCA: A First Pass",
    "text": "PCA: A First Pass\nDirection of Maximal Variance\n\nCrucially, we’ll assume the columns of \\(\\vect{X}\\) have mean zero.\n\nIn R, we can accomplish this using the scale() function.\n\nRemember how to express the variance of \\(\\mat{X} \\vect{v}\\) in terms of standard linear algebra operations?\n\nSquared-norm!\n\nThe variance of \\(\\mat{X} \\vect{v}\\) is proportional to \\[ \\| \\mat{X} \\vect{v} \\|^2 =  (\\mat{X} \\vect{v})^{\\mathsf{T}}(\\mat{X} \\vect{v}) = \\tvect{v} \\tmat{X} \\mat{X} \\vect{v} \\]\n\nSo, the direction \\(\\vect{v}\\) of maximal variance is the one for which \\(\\tvect{v} \\tmat{X} \\mat{X} \\vect{v}\\) is maximized."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#pca-a-first-pass-1",
    "href": "Lectures/Lec05/Lec05.html#pca-a-first-pass-1",
    "title": "PSTAT 100: Lecture 05",
    "section": " PCA: A First Pass",
    "text": "PCA: A First Pass\nDirection of Maximal Variance\n\nThis maximization problem, however, is ill-posed without further constraints.\n\nSpecifically, if \\(\\vect{v}\\) is a direction of maximal variance, so too will \\(c \\vect{v}\\) be for any constant \\(c\\).\n\nSo, let’s add the following constraint: \\(\\vect{v}\\) must be of unit-length.\n\n\n\n\n\n\n\n\nGoal\n\n\nIdentify the unit vector \\(\\vect{v}\\) such that \\(\\mat{X} \\vect{v}\\) (the column mean-centered data projected onto \\(\\vect{v}\\)) has maximum variance.\n\n\n\n\n\n\\[ \\argmax_{\\vect{v}} \\left\\{ \\tvect{v} \\tmat{X} \\mat{X} \\vect{v} \\right\\} \\quad \\text{s.t.} \\quad \\tvect{v} \\vect{v} = 1 \\]"
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#pca-a-first-pass-2",
    "href": "Lectures/Lec05/Lec05.html#pca-a-first-pass-2",
    "title": "PSTAT 100: Lecture 05",
    "section": " PCA: A First Pass",
    "text": "PCA: A First Pass\nDirection of Maximal Variance\n\nConstrained optimization problems like this are most often solved using Lagrange Multipliers, which we will discuss further in a future lab.\n\nIf you’d like a primer, I encourage you to check out this video.\nAgain, I don’t expect you to follow every step of the following computation yet!\n\nWe first construct the lagrangian \\(\\mathcal{L}(\\vect{v}, \\lambda) := \\tvect{v} \\tmat{X} \\mat{X} \\vect{v} - \\lambda \\tvect{v} \\vect{v}\\).\nThen we differentiate wrt. \\(\\vect{v}\\) and set equal to zero: \\[ \\tmat{X} \\mat{X} \\vect{v} - \\lambda \\vect{v} = 0 \\] or, in other words, \\((\\tmat{X} \\mat{X}) \\vect{v} = \\lambda \\vect{v}\\)."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#pca-a-first-pass-3",
    "href": "Lectures/Lec05/Lec05.html#pca-a-first-pass-3",
    "title": "PSTAT 100: Lecture 05",
    "section": " PCA: A First Pass",
    "text": "PCA: A First Pass\nDirection of Maximal Variance\n\n\n\n\n\n\nGoal\n\n\nIdentify the vector \\(\\vect{v}\\) such that \\(\\mat{X} \\vect{v}\\) (the column mean-centered data projected onto \\(\\vect{v}\\)) has maximum variance.\n\n\n\n\n\n\n\n\n\n\nResult\n\n\nThe vector \\(\\vect{v}\\) is given by an eigenvector of \\(\\tmat{X} \\mat{X}\\) with eigenvalue \\(\\lambda\\).\n\n\n\n\n\nThe variance of the projected data along \\(\\vect{v}\\) is proportional to \\(\\tvect{v} \\tmat{X} \\mat{X} \\vect{v}\\).\n\nSince \\(\\vect{v}\\) is an eigenvalue of \\(\\tmat{X} \\mat{X}\\), this simplifies to \\(\\vect{v}(\\lambda \\vect{v}) = \\lambda \\tvect{v} \\vect{v}\\)\nWe assumed \\(\\vect{v}\\) is of unit length, meaning the variance is proportional to the associated eigenvalue \\(\\lambda\\)."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#pca-a-first-pass-4",
    "href": "Lectures/Lec05/Lec05.html#pca-a-first-pass-4",
    "title": "PSTAT 100: Lecture 05",
    "section": " PCA: A First Pass",
    "text": "PCA: A First Pass\nDirections of Maximal Variance\n\nIn other words, the eigenvectors \\(\\vect{v}\\) give the directions of maximal variance, and the eigenvalues \\(\\lambda\\) give the amount of variance the projected data will have (all up to proportionality constants).\nSo, the eigenvector \\(\\vect{v}_1\\) associated with the largest eigenvalue is the direction with the largest variance; the eigenvector \\(\\vect{v}_2\\) associated with the second-largest eigenvalue is the direction with the second-largest variance; etc.\nPretty neat, huh?\n\nSeems like as good a place as any to leave off for today."
  },
  {
    "objectID": "Lectures/Lec05/Lec05.html#next-time",
    "href": "Lectures/Lec05/Lec05.html#next-time",
    "title": "PSTAT 100: Lecture 05",
    "section": " Next Time",
    "text": "Next Time\n\nWe will continue discussing the details of PCA.\n\nFor example, now that we have the directions of maximal variance - what do we do?\nHow many dimensions are enough to capture a “good” lower-dimensional approximation of our data?\nHow do we do this in R?\n\nReminder: ICA01 is coming up this Thursday (July 3, 2025).\n\nAn information document has been posted to the course website; please read it fully!\n\nSecond Reminder: group formation for the Mid-Quarter Project is due tomorrow (Tuesday, July 1) by 11:59pm."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#congrats-on-finishing-ica01",
    "href": "Lectures/Lec08/Lec08.html#congrats-on-finishing-ica01",
    "title": "PSTAT 100: Lecture 08",
    "section": " Congrats On Finishing ICA01!",
    "text": "Congrats On Finishing ICA01!\n\nCongratulations on finishing ICA01!\nGrades have been released; allow me to say a few words about the ICA before we proceed with today’s lecture material.\nFirst of all, I’ve posted both solutions to the ICA along with an additional document outlining some of the problems that seemed to trip people up the most.\n\nPlease read through BOTH OF THESE before submitting a regrade request.\n\nRegrade requests must be submitted before 11:59pm on Wednesday July 9, 2025 through Gradescope.\n\nKindly note: we reserve the right to regrade your entire ICA, not just the question/s you request a regrade for."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#recap-the-dsl",
    "href": "Lectures/Lec08/Lec08.html#recap-the-dsl",
    "title": "PSTAT 100: Lecture 08",
    "section": " Recap: The DSL",
    "text": "Recap: The DSL"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#recap-the-dsl-1",
    "href": "Lectures/Lec08/Lec08.html#recap-the-dsl-1",
    "title": "PSTAT 100: Lecture 08",
    "section": " Recap: The DSL",
    "text": "Recap: The DSL\n\n\n\n\n\nToday, we’ll explore the collecting step of the DSL.\nSpecifically, we’ll consider questions like:\n\nHow should we collect our data? (Study Design; Sampling Techniques)\nGiven knowledge about how our data was collected, how far are we allowed to generalize our findings? (Scope of Inference)"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#diabetes",
    "href": "Lectures/Lec08/Lec08.html#diabetes",
    "title": "PSTAT 100: Lecture 08",
    "section": " Diabetes",
    "text": "Diabetes\nAn Example\n\nType II diabetes is a condition characterized by unusually high levels of sugar in the bloodstream, and is estimated to affect somewhere around 11% of all US citizens.\n\nTypically, diabetes is diagnosed by examining an individual’s A1C Hemoglobin levels, which is used as a measure of average blood sugar level over the past two-to-three months.\nExactly what cutoff is used to officially diagnose diabetes varies somewhat from doctor to doctor; generally, A1C levels of 6.5% or higher are considered to be in the diabetic range."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#diabetes-1",
    "href": "Lectures/Lec08/Lec08.html#diabetes-1",
    "title": "PSTAT 100: Lecture 08",
    "section": " Diabetes",
    "text": "Diabetes\nAn Example\n\nMetformin is one of a few popular prescription drugs used to treat diabetes by lowering an individual’s A1C levels.\nSuppose we are hired as statistical consultants to determine whether or not we believe Metformin is effective in combating type II diabetes.\nHow might we go about formulating our conclusions?\nSpecifically, how might we design some sort of experiment to answer this question?"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#two-scenarios",
    "href": "Lectures/Lec08/Lec08.html#two-scenarios",
    "title": "PSTAT 100: Lecture 08",
    "section": " Two Scenarios",
    "text": "Two Scenarios\n\n\n\nScenario 1:\nWe sample 100 people at random, 50 of whom currently on metformin and 50 of whom are not. We then collect the A1C levels of all 100 participants, to obtain 100 different data points.\n\n\n\n\n\nScenario 2:\nWe sample 100 people at random, none of whom are currently on metformin. We then assign 50 of them to take metformin, and assign the other 50 to take a placebo. Finally, after a few months, we collect the A1C levels of all 100 participants."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#two-scenarios-1",
    "href": "Lectures/Lec08/Lec08.html#two-scenarios-1",
    "title": "PSTAT 100: Lecture 08",
    "section": " Two Scenarios",
    "text": "Two Scenarios\n\nIn both scenarios, the data we get out looks the same: 100 observations of A1C levels, 50 of which are from patients on metformin and 50 of which are from patients are not on metformin.\nThe two scenarios, however, do differ in one crucial aspect: whether we (as the experimenters) administer/withhold treatment or not.\nThis is the key distinction between an observational study and an experiment.\n\nIn an observational study, treatment is neither administered nor withheld. In an experiment, treatment is either explicitly administered or withheld.\n\n\n\n\n\n\n\n\n\nCheck Your Understanding\n\n\nWhich Scenario (1 or 2), corresponds to an observational study, and which corresponds to an experiment?"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#observational-studies",
    "href": "Lectures/Lec08/Lec08.html#observational-studies",
    "title": "PSTAT 100: Lecture 08",
    "section": " Observational Studies",
    "text": "Observational Studies\n\nThe distinction between an observational study and an experiment is important not just for general purposes, but also for the purposes of causal inference.\nBroadly speaking, causal inference is the branch of statistics dedicated to trying to take associations between variables a step further, and determine whether or not one variable is causing a change in the other. Such relationships (in which one variable is causing or inducing a change in another) is called a causal relationship (or a causal effect).\nWe’ll talk about causal inference more later in this course."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#observational-studies-vs.-experiments",
    "href": "Lectures/Lec08/Lec08.html#observational-studies-vs.-experiments",
    "title": "PSTAT 100: Lecture 08",
    "section": " Observational Studies vs. Experiments",
    "text": "Observational Studies vs. Experiments\n\nThe reason I bring up causal inference is that we cannot (or, at least, it is highly cautioned against) make causal claims in an observational study.\n\nEssentially, the argument goes: in an observational study, we are not allowed to control variables. As such, we cannot effectively control against confounding variables (variables that affect our data, but that are uncontrolled).\n\nNow, that is not to say that associations in an experiment automatically imply causation. The only way to determine causality is to utilize tools from causal inference.\nIn an experiment, the group/s that are assigned treatment are called treatment group(s), and the group/s that have treatment withheld (or are administered a placebo) are called control group(s)"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#another-distinction",
    "href": "Lectures/Lec08/Lec08.html#another-distinction",
    "title": "PSTAT 100: Lecture 08",
    "section": " Another Distinction",
    "text": "Another Distinction\n\n\n\nScenario 1:\nWe sample 50 people at random, none of whom are currently on metformin. We take their A1C levels at the start of the study, prescribe then metformin (which they take regularly), and then measure their A1C levels a few months later.\n\n\n\n\n\nScenario 2:\nWe sample 100 people at random, none of whom are currently on metformin. We then assign 50 of them to take metformin, and assign the other 50 to take a placebo. Finally, after a few months, we collect the A1C levels of all 100 participants.\n\n\n\nAgain, the end-product data are the same between the scenarios. Now, the key distinction is whether or not subjects were tracked over time."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#longitudinal-vs.-cross-sectional-studies",
    "href": "Lectures/Lec08/Lec08.html#longitudinal-vs.-cross-sectional-studies",
    "title": "PSTAT 100: Lecture 08",
    "section": " Longitudinal vs. Cross-Sectional Studies",
    "text": "Longitudinal vs. Cross-Sectional Studies\n\nThis is the difference between longitudinal studies (in which subjects are tracked over time) and cross-sectional studies (in which there is no tracking over time).\nLongitudinal studies lead to paired or grouped, in which there is serial correlation among observations.\n\nFor instance, a pre-metformin A1C measurement from Bob will most certainly be correlated with a post-metformin A1C measurement from Bob\n\nBy the way, both observational studies and experiments could be longitudinal or cross-sectional.\n\nAs an example, classify the two scenarios on the previous page as either longitudinal or cross-sectional, and whether they come from an observational study or an experiment."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#your-turn",
    "href": "Lectures/Lec08/Lec08.html#your-turn",
    "title": "PSTAT 100: Lecture 08",
    "section": " Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nYour Turn!\n\n\nSetup: A new pilot program is purported to help high school students perform better on the AP (Advanced Placement) AB Calculus exam. To test this claim, an experimenter selects 40 high school students at random, and assigns 20 of them to a class testing out the new program and 20 of them to a “standard” calculus class (that does not offer the new program). Before beginning the study, all 40 students are given an entrance exam (to use as a baseline score), and all 40 students take an exit survey at the end of the study.\n\n\nIs this an observational study or an experiment?\nIs this a longitudinal study or a cross-sectional study?\nSuppose it is found that students who underwent the new program performed significantly better on the AP Calculus AB exam than students in the “traditional” classroom. Can we claim that the new program caused the increase in performance? If not, what are some potential confounding variables?\n\n\n\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#sampling-terminology",
    "href": "Lectures/Lec08/Lec08.html#sampling-terminology",
    "title": "PSTAT 100: Lecture 08",
    "section": " Sampling Terminology",
    "text": "Sampling Terminology\n\nThere are three main terms we’ll start with: target population, access frame, and sample.\n\nPlease note that these terms go by many names: sometimes the access frame is called the sampling frame; sometimes the target population is just called the “population”.\nWe also assume that everything exists within a so-called universe, which we don’t always make explicit reference to.\n\nTarget Population: the set of observational units that we would like to investigate/make claims about.\nAccess Frame: set of elements that we can actually reach/observe.\nSample: the subset of elements taken from the access frame that we actually end up observing."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#example-voter-turnout",
    "href": "Lectures/Lec08/Lec08.html#example-voter-turnout",
    "title": "PSTAT 100: Lecture 08",
    "section": " Example: Voter Turnout",
    "text": "Example: Voter Turnout\n\nSuppose we would like to determine which US voters are most likely to vote for a particular candidate in a local election, and suppose we do so by way of a text survey (i.e. a survey sent to people’s smartphones).\nSome people don’t have a smartphone; these people will be a part of the target population (since they are a part of the set of people we’re interested in), but not part of the access frame (because they’re not accessible via our survey method).\nSome people are ineligible to vote, but still have a smartphone; these people will be a part of the access frame (since they are accessible via our survey method), but not a part of the target population (since we’re only interested in voter turnout among those eligible to vote)."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#example-voter-turnout-1",
    "href": "Lectures/Lec08/Lec08.html#example-voter-turnout-1",
    "title": "PSTAT 100: Lecture 08",
    "section": " Example: Voter Turnout",
    "text": "Example: Voter Turnout"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#example-voter-turnout-2",
    "href": "Lectures/Lec08/Lec08.html#example-voter-turnout-2",
    "title": "PSTAT 100: Lecture 08",
    "section": " Example: Voter Turnout",
    "text": "Example: Voter Turnout"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#more-formally",
    "href": "Lectures/Lec08/Lec08.html#more-formally",
    "title": "PSTAT 100: Lecture 08",
    "section": " More Formally",
    "text": "More Formally\n\nLet \\(U_i\\) denote the ith observational unit, and let \\(I\\) denote the set of allowable indices for i.\nUniverse: \\(\\mathcal{U} := \\{U_i\\}_{i \\in I}\\)\nTarget Population: \\(T_P := \\{U_1, \\cdots, U_n\\} \\subseteq \\mathcal{U}\\)\n\nA subset (potentially an improper subset) of the universe containing the units of interest to the study\n\nAccess Frame: \\(F = \\{U_j \\mid j \\in J \\subset I \\}\\)\n\nA subset (potentially an improper subset) of the universe containing the units of accessible to the study\n\nSampled Population: \\(S_P := T_P \\cap F\\)\nSample: \\(S \\subseteq S_P\\)"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#more-formally-1",
    "href": "Lectures/Lec08/Lec08.html#more-formally-1",
    "title": "PSTAT 100: Lecture 08",
    "section": " More Formally",
    "text": "More Formally\n\n\nThere is still the question of which units from the sampled population actually get included in our sample."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#census",
    "href": "Lectures/Lec08/Lec08.html#census",
    "title": "PSTAT 100: Lecture 08",
    "section": " Census",
    "text": "Census\n\n\nIn some ways, a census may seem “ideal”. So why don’t we hear more about censuses?\nFirstly, censuses are often prohibitively expensive (both in terms of money and in terms of personpower required).\nCensuses can also produce imbalanced samples, something we’ll talk more about later today."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#other-sampling-structures",
    "href": "Lectures/Lec08/Lec08.html#other-sampling-structures",
    "title": "PSTAT 100: Lecture 08",
    "section": " Other Sampling Structures",
    "text": "Other Sampling Structures\n\n\nThis is perhaps a slightly more common situation.\nThe natural follow-up question is: what mechanism should we implement to select units from the sampled population?\n\nThis mechanism is often random, leading to probabilistic samples (sometimes called random samples).\n\nOver the next few slides, we’ll discuss some of these probabilistic sampling techniques."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#simple-random-sampling",
    "href": "Lectures/Lec08/Lec08.html#simple-random-sampling",
    "title": "PSTAT 100: Lecture 08",
    "section": " Simple Random Sampling",
    "text": "Simple Random Sampling\n\nSuppose every unit in the sampled population has an equal chance of being included in our sample.\n\nThat is, let πi denote the probability that unit i is included in the sample (we call this the inclusion probability); then suppose πi = πj for every i ≠ j\n\nSuch a sample is called a simple random sample (SRS).\n\nAgain, the hallmark of an SRS is that each unit in the frame has an equal chance of being included in our sample.\n\nQuestion for you: in a census, what is the inclusion probability πi?\nBy the way: it is possible to take SRSes with or without replacement. In real-world settings, sampling without replacement is far more common however sampling with replacement tends to make inference (the topic of tomorrow’s lecture) a bit easier."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#moving-beyond-simple-random-sampling",
    "href": "Lectures/Lec08/Lec08.html#moving-beyond-simple-random-sampling",
    "title": "PSTAT 100: Lecture 08",
    "section": " Moving Beyond Simple Random Sampling",
    "text": "Moving Beyond Simple Random Sampling\n\nSimple random sampling is sometimes touted as a “gold standard” for sampling.\n\nAdmittedly, it is true that inference for SRSes is a lot simpler than inference for samples taken according to other schemes (some of which we’ll discuss in a bit).\n\nBasically, samples that are taken as an SRS (with replacement) can be treated as i.i.d. (independently and identically distributed) random variables, meaning we can use our PSTAT 120A and 120B knowledge to easily model, perform inference, predict, etc.\n\n\nHowever, simple random samples are not immune to the effects of bias."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#moving-beyond-simple-random-sampling-1",
    "href": "Lectures/Lec08/Lec08.html#moving-beyond-simple-random-sampling-1",
    "title": "PSTAT 100: Lecture 08",
    "section": " Moving Beyond Simple Random Sampling",
    "text": "Moving Beyond Simple Random Sampling\n\nLet’s say we have been hired as an external consultant for some company, which wants to conduct a climate survey on its employees.\n\nIf we take an SRS of employees, it seems like we should get a pretty unbiased sample.\nWell, what if I told you 80% of employees at this company identified as white. Still think our sample will be free of bias?\n\nIndeed, an SRS will very nicely preserve (or, at the very least, imitate) the structure of the sampled population.\nSo, if the sampled population has sources of systematic bias, so too may our SRS.\n\nEmphasis on may - it is certainly possible that we just so happen to obtain a sample that is balanced in terms of race. But, is it probable?"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#stratified-random-sampling",
    "href": "Lectures/Lec08/Lec08.html#stratified-random-sampling",
    "title": "PSTAT 100: Lecture 08",
    "section": " Stratified Random Sampling",
    "text": "Stratified Random Sampling\n\nTo obtain a more balanced sample, consider the following scheme: divide the employees by the race they most identify with, and then take an SRS of employees from each race.\nThis is an example of a stratified random sample.\nIn a stratified random sample, the sampled population is divided into a series of groups, called strata (singular, stratum), and an SRS is taken from each stratum."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#leadup",
    "href": "Lectures/Lec08/Lec08.html#leadup",
    "title": "PSTAT 100: Lecture 08",
    "section": " Leadup",
    "text": "Leadup\n\nLet’s say we’re working with the superintendent for a certain school district, and we want to assess the education level of students across schools in this district.\nLet’s also suppose the schools themselves are relatively similar to one another.\nWe might be tempted to take a stratified sample, using each school as a stratum.\n\nThis would work! But, it’s a bit overkill, mainly because the schools are all relatively similar to each other.\n\nAs such, a more efficient scheme might be to randomly select some schools, and then take an SRS from each of the sampled schools."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#cluster-sampling",
    "href": "Lectures/Lec08/Lec08.html#cluster-sampling",
    "title": "PSTAT 100: Lecture 08",
    "section": " Cluster Sampling",
    "text": "Cluster Sampling\n\nAs such, a more efficient scheme might be to randomly select some schools, and then take an SRS from each of the sampled schools.\nThis is an example of a cluster sampling scheme: the sampled population is (again) divided into a series of groups (now called clusters); an SRS of clusters is taken, and then an SRS from the sampled clusters is taken.\n\nCAUTION: IMS calls this “multistage sampling” (and calls something else cluster sampling). This is a bit nonstandard - the definitions above are more standard, which is why we’re adopting them for this course."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#cluster-sampling-1",
    "href": "Lectures/Lec08/Lec08.html#cluster-sampling-1",
    "title": "PSTAT 100: Lecture 08",
    "section": " Cluster Sampling",
    "text": "Cluster Sampling"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#comparisons",
    "href": "Lectures/Lec08/Lec08.html#comparisons",
    "title": "PSTAT 100: Lecture 08",
    "section": " Comparisons",
    "text": "Comparisons\n\nAs a concrete example, consider drawing a sample of size 20 from the set of integers {1, 2, …, 100}.\nOn the next slide are three such samples, each sampled according to a different strategy.\n\nTo generate the SRS, I simply used the sample() function from R.\n\nAs an aside, if you want to sample rows from a dataframe, consider using the dplyr::slice_sample() function\n\nTo generate the stratified random sample, I divided the population into 10 strata: {1, …, 10}, {11, …., 20}, …., {91, …, 100}, and took an SRS of size 2 from each stratum.\nTo generate the cluster random sample, I divided the population into 20 clusters: {1, …, 5}, {6, …, 10}, …., {96, …, 100}. I then took an SRS of 10 of these clusters, and took an SRS of size 2 from each cluster."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#comparisons-1",
    "href": "Lectures/Lec08/Lec08.html#comparisons-1",
    "title": "PSTAT 100: Lecture 08",
    "section": " Comparisons",
    "text": "Comparisons"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#your-turn-2",
    "href": "Lectures/Lec08/Lec08.html#your-turn-2",
    "title": "PSTAT 100: Lecture 08",
    "section": " Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nYour Turn!\n\n\nDacMonalds wants to compare sales across its different regional locations. With over 40,000 locations, company executives cannot examine sales reports from each and every location. Propose a sampling scheme that we could use to collect data; be as specific as possible.\n\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#scope-of-inference",
    "href": "Lectures/Lec08/Lec08.html#scope-of-inference",
    "title": "PSTAT 100: Lecture 08",
    "section": " Scope of Inference",
    "text": "Scope of Inference\n\nSo, why should we care how our sample was taken?\nFor one thing, knowledge about this is crucial in handling missing values (which we will talk about in a few minutes).\nBut, our goal with data is (often) to use it to make broader claims about the world.\n\nMore specifically, we often wish to use our data to make claims about the population.\n\nThe scope of inference, loosely speaking, refers to extent to which conclusions based on the sample are generalizable to the population and/or universe.\n\nIndeed, identifying the scope of inference for a particular dataset requires knowledge about how the data was collected!"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#scope-of-inference-1",
    "href": "Lectures/Lec08/Lec08.html#scope-of-inference-1",
    "title": "PSTAT 100: Lecture 08",
    "section": " Scope of Inference",
    "text": "Scope of Inference\n\nAs a simple (but somewhat extreme) example, opinions on gun control collected from US citizens cannot be used to make conclusions or claims about the views on gun control held by citizens of, say, Canada.\nEven data based on an SRS of individuals taken from the pool of US citizens may have limited scope of inference; for instance, if our sample ends up including a disproportionate amount of male-identifying respondants then our conclusions may not generalize to female-identifying respondants.\nMore or less, whether or not we can generalize the results of a sample to the population boils down to whether or not the sample is representative of the population.\nNaturally, this question of representativeness is tied with the relationship between the population, frame, and sample, which is why we started off by talking about these notions."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#your-turn-4",
    "href": "Lectures/Lec08/Lec08.html#your-turn-4",
    "title": "PSTAT 100: Lecture 08",
    "section": " Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nYour Turn!\n\n\nSETUP: A new pilot program is purported to help high school students perform better on the AP (Advanced Placement) AB Calculus exam. To test this claim, an experimenter takes a simple random sample of 40 high school students from Santa Barbara, and assigns 20 of them to a class testing out the new program and 20 of them to a “standard” calculus class (that does not offer the new program). Before beginning the study, all 40 students are given an entrance exam (to use as a baseline score), and all 40 students take an exit survey at the end of the study. It is found that students in the pilot program performed significantly better on the AP Calculus AB exam than students in the “traditional” classroom.\n\n\nAre we justified in concluding that the pilot program will work, on average, for residents of Santa Barbara?\nAre we justified in concluding that the pilot program will work, on average, for residents of California?\nAre we justified in concluding that the pilot program will work, on average, for US residents?\n\n\n\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#bias",
    "href": "Lectures/Lec08/Lec08.html#bias",
    "title": "PSTAT 100: Lecture 08",
    "section": " Bias",
    "text": "Bias\n\nLet’s talk a bit about bias.\nThere’s a formal statistical definition of bias, which we’ll discuss in a few lectures. Today, let’s discuss bias at a high level: broadly speaking, we can think of bias as discrepancies between some aspect of the sample and the corresponding aspect of the population.\nSelection bias occurs when some part of the population is not in the sampled population\n\nFor example, an experimenter interested in collecting household income data who neglects to survey transient (aka unhoused) persons will most definitely obtain a biased sample.\n\nNon-response bias occurs when a subset of the sampled population is included in the sample, but choose not to contribute data (e.g. didn’t fill out a survey, didn’t pick up the phone, dropped out of a study for personal reasons, etc.)"
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#bias-1",
    "href": "Lectures/Lec08/Lec08.html#bias-1",
    "title": "PSTAT 100: Lecture 08",
    "section": " Bias",
    "text": "Bias\n\nNote the distinction between selection and non-response bias. In both cases, we may end up with a group of missing values from our dataset.\n\nThe mechanisms behind why they are missing, however, are very different across the two types of bias.\nIn selection bias, values are missing because we, as experimenters, chose to exclude them (for whatever reason).\nIn non-response bias, values are missing for reasons outside our control.\n\nThis distinction will become important later in the course, when we talk about how to handle missing data."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#convenience-sampling",
    "href": "Lectures/Lec08/Lec08.html#convenience-sampling",
    "title": "PSTAT 100: Lecture 08",
    "section": " Convenience Sampling",
    "text": "Convenience Sampling\n\nSuppose we’re interested in conducting a survey on UCSB students’ attitudes toward police on campus.\nOne way we might administer this survey is to stand outside the PSTAT main office and pick the first 100 students we see to participate in a survey.\nIndeed, assuming we don’t have any non-response bias, we’ll get 100 people in our “sample!”\n\nBut, is this really a quality sample?\nIn fact, is this even really a random sample?\nI think most of us would say, “no.”\n\nMore generally, as the name suggests, a convenience sample is obtained by drawing whichever units from the population are most convenient."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#convenience-sampling-1",
    "href": "Lectures/Lec08/Lec08.html#convenience-sampling-1",
    "title": "PSTAT 100: Lecture 08",
    "section": " Convenience Sampling",
    "text": "Convenience Sampling\n\nConvenience samples often have zero scope of inference.\nUnfortunately, there are still some published studies that are based on convenience samples.\n\nOften, these are motivated by the idea that some data is better than no data.\n\nHowever, we also have to contend with what is often called the garbage-in garbage-out philosophy.\n\nLoosely speaking, even the most sophisticated data science techniques will produce meaningless (and sometimes dangerous) results if they are applied to poorly-sampled data."
  },
  {
    "objectID": "Lectures/Lec08/Lec08.html#next-time",
    "href": "Lectures/Lec08/Lec08.html#next-time",
    "title": "PSTAT 100: Lecture 08",
    "section": " Next Time",
    "text": "Next Time\n\nTomorrow, we’ll begin our transition into inferential statistics.\n\nPlease brush up on your PSTAT 120A material!\n\nIn lab tomorrow, you’ll get some practice with sampling, along with some topics from tomorrow’s lecture.\nREMINDER: Keep working on the Mid-Quarter Project!\n\nYour reports are due this Sunday (July 13) by 11:59pm.\nKindly recall that no late submissions will be accepted for any reason.\nOnly one member needs to submit to Gradescope; they will be prompted to match all group member names."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#introduction",
    "href": "Lectures/Lec01/Lec01.html#introduction",
    "title": "PSTAT 100: Lecture 01",
    "section": " Introduction",
    "text": "Introduction\nWelcome to the Course!\n\nWelcome to PSTAT 100! I am so glad to be here on this journey with you.\nAbout me: Ethan P. Marzban (he/him); rising 6th-Year PhD Student in the PSTAT Department\nI am incredibly thankful to have Erika McPhillips (she/her) as a TA for this course!\n\n\nOffice Hours (subject to change):\n\n\n\n\nWho?\n\n\nWhen?\n\n\nWhere?\n\n\n\n\n\n\nEthan\n\n\nWednesdays, 3:30 - 4:30 pm\n\n\nGIRV 2123\n\n\n\n\nFridays, 9:00 - 10:30 am\n\n\nZoom\n\n\n\n\nErika\n\n\nTuesdays, 4:15 - 5:15 pm\n\n\nSH 5421\n\n\n\n\nThursdays, 4:15 - 5:15 pm\n\n\nSH 5421"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#course-logistics",
    "href": "Lectures/Lec01/Lec01.html#course-logistics",
    "title": "PSTAT 100: Lecture 01",
    "section": " Course Logistics",
    "text": "Course Logistics\nImportant Course Sites\n\nThere are three important sites related to the course:\n\nMain Course Website: https://ucsb-pstat100.github.io  This is where lecture slides will be posted, along with the course policies and the course schedule\nCourse Computing Server: Please See Canvas  This is where all labs, homeworks, and project files will be posted. Please make sure to use the bit.ly link every time you need to access the course computing server.\nGradescope: https://www.gradescope.com/courses/995844  This is where you will submit the majority of the assignments this quarter, and is also where you will be able to view your completed ICAs"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#course-logistics-1",
    "href": "Lectures/Lec01/Lec01.html#course-logistics-1",
    "title": "PSTAT 100: Lecture 01",
    "section": " Course Logistics",
    "text": "Course Logistics\nCourse Policies\n\nIf you haven’t already, please read through the Course Policies fully.\n\nThey lay out policies surrounding late work, how your final grades will be computed, what constitutes allowable use of AI, and much more.\n\nOne highlight: you will be graded on labs, homeworks, projects, and in-class assessments.\n\nThe Course Policies provide further details on how these assignments differ, as well as how they factor in to your final course grade."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#some-tips-for-success",
    "href": "Lectures/Lec01/Lec01.html#some-tips-for-success",
    "title": "PSTAT 100: Lecture 01",
    "section": " Some Tips for Success",
    "text": "Some Tips for Success\n\nCreate a weekly schedule for yourself, and allocate a bit of time for PSTAT 100 each day.\n\nE.g. for working on homework/projects, working through practice problems, reviewing notes, etc.\n\nTake notes!\n\nCourse slides are somewhat comprehensive, but not the full story - I’ll often say things in class that are very important (and potentially testable on ICAs…)\n\nForm Study Groups\n\nData Science is a highly collaborative field - get some practice forming these connections by connecting with your fellow classmates!"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-science",
    "href": "Lectures/Lec01/Lec01.html#data-science",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Science",
    "text": "Data Science\nYour Thoughts, from the Google Form!"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-science-1",
    "href": "Lectures/Lec01/Lec01.html#data-science-1",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Science",
    "text": "Data Science\nThe First “Expert”\n\n\n\n\n\nInterdisciplinary; emphasis on domain knowledge\n\nDraws from expertise and innovations from many fields\n\nData-Driven; collects, interprets, and uses data to say things about the world."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-science-2",
    "href": "Lectures/Lec01/Lec01.html#data-science-2",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Science",
    "text": "Data Science\nThe Second “Expert”"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-science-3",
    "href": "Lectures/Lec01/Lec01.html#data-science-3",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Science",
    "text": "Data Science\nStats, Maths, and Computing\n\nNotice that these three fields (loosely) correspond to the three prerequisites for this course!\n\n\n\n\nStats (PSTAT 120A)\n\nData has error and randomness; we need probability to be able to draw conclusions in the face of this randomness\n\n\n\n\nMaths (MATH 4A)\n\nData is naturally expressible as matrices and vectors (more on this next week)\n\n\n\n\nComputing (CMPSC 9/16)\n\nData is large, and often too complicated to handle by hand (without the aid of computing software)"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-science-4",
    "href": "Lectures/Lec01/Lec01.html#data-science-4",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Science",
    "text": "Data Science\nStill Very New!"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-science-lifecycle",
    "href": "Lectures/Lec01/Lec01.html#data-science-lifecycle",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Science Lifecycle",
    "text": "Data Science Lifecycle\nFirst Version\n\n\n\n\n\nThe Data Science Lifecycle (DSL) seeks to describe the general lifecycle of a typical data science project.\nFour main stages: questioning, collecting, analyzing, and interpreting.\nLots of variations of the DSL, some with more steps than others.\nMain idea: data science projects are highly iterative."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-science-lifecycle-1",
    "href": "Lectures/Lec01/Lec01.html#data-science-lifecycle-1",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Science Lifecycle",
    "text": "Data Science Lifecycle\nSecond Version\n\n\n\n\n\nIn my opinion, this is a much better representation of the DSL! (Though the graphic is certainly too complex.)\nAgain, data science is a highly iterative field; we rarely proceed in a linear fashion from start to finish.\n\nRather, we start, analyze out data, realize we need more data, collect more data, analyze our new data, realize we need to revise our original question, etc."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-science-lifecycle-2",
    "href": "Lectures/Lec01/Lec01.html#data-science-lifecycle-2",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Science Lifecycle",
    "text": "Data Science Lifecycle\nStarting the Cycle\n\n\n\n\n\nSometimes we’ll begin with a question we want to answer.\nE.g. “Has air quality in the US improved over time?”\nE.g. “How has the distribution of wealth and income changed since the economic recession of 2008?”"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-science-lifecycle-3",
    "href": "Lectures/Lec01/Lec01.html#data-science-lifecycle-3",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Science Lifecycle",
    "text": "Data Science Lifecycle\nStarting the Cycle\n\n\n\n\n\nIn this case, our question will dictate what kind of data to collect\n\nE.g. AQI data\nE.g. Income Data; Federal Bank Data; etc.\n\nIn other cases, we’ll start with a dataset, which will then inform what question we want to ask.\n\nLimitations in our dataset may also necessitate changes in our question; we’ll return to this point in a few lectures."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-science-lifecycle-4",
    "href": "Lectures/Lec01/Lec01.html#data-science-lifecycle-4",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Science Lifecycle",
    "text": "Data Science Lifecycle\nTraveling Through the Cycle\n\n\n\n\n\nOnce we have our data, we need to analyze it.\nThis might involve data cleaning or data tidying; this could also involve producing appropriate visualizations.\n\nAt this stage, we may perform Exploratory Data Analysis (EDA).\nIn certain cases, we may find it useful to apply techniques from maching learning to better understand our dataset."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-science-lifecycle-5",
    "href": "Lectures/Lec01/Lec01.html#data-science-lifecycle-5",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Science Lifecycle",
    "text": "Data Science Lifecycle\nTraveling Through the Cycle\n\n\n\n\n\nFinally, we need to understand what our data is saying.\nThis will typically involve answering our question(s); oftentimes we’ll take things a step further and see if we can use our data to make sense of the world.\nA key component of this stage of the DSL is producing some sort of a report or presentation."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#pstat-100",
    "href": "Lectures/Lec01/Lec01.html#pstat-100",
    "title": "PSTAT 100: Lecture 01",
    "section": " PSTAT 100",
    "text": "PSTAT 100\n\nWe’ll be returning to the different stages of the DSL throughout this course (though not necessarily in order).\n\nConsequently, I don’t expect you to understand all of the jargon on the previous few slides!\n\nToday, we’ll start by addressing a question that is not explicitly part of the DSL, but implicitly forms the backbone of it: What is Data?"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#what-is-data-1",
    "href": "Lectures/Lec01/Lec01.html#what-is-data-1",
    "title": "PSTAT 100: Lecture 01",
    "section": " What is Data?",
    "text": "What is Data?"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#what-is-data-2",
    "href": "Lectures/Lec01/Lec01.html#what-is-data-2",
    "title": "PSTAT 100: Lecture 01",
    "section": " What is Data?",
    "text": "What is Data?\n\nAccording to Merriam-Webster (source), there are three definitions for data:\n\n\nfactual information (such as measurements or statistics) used as a basis for reasoning, discussion, or calculation\ninformation in digital form that can be transmitted or processed\ninformation output by a sensing device or organ that includes both useful and irrelevant or redundant information and must be processed to be meaningful\n\n\nI like the first definition, particularly the phrase “used as a basis for reasoning, discussion, or calculation.”"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#what-is-data-3",
    "href": "Lectures/Lec01/Lec01.html#what-is-data-3",
    "title": "PSTAT 100: Lecture 01",
    "section": " What is Data?",
    "text": "What is Data?\n\nRaw data is often uninterpretable (and, in some cases, useless)\nIt’s the job of a Data Scientist to interpret the data, and use it to assess beliefs.\n\n\n\n\n\n\n\n\nDefinition\n\n\nData Literacy: “the ability to explore, understand, and communicate with data in a meaningful way.” (Tableau; source)\n\n\n\n\n\nOne of the goals of PSTAT 100 is to increase your data literacy.\nWe’ll develop a series of tools (that you will expound upon in your future PSTAT courses) in service of this goal."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#a-dataset",
    "href": "Lectures/Lec01/Lec01.html#a-dataset",
    "title": "PSTAT 100: Lecture 01",
    "section": " A Dataset",
    "text": "A Dataset\nCats!\n\nLet’s take a look at a concrete dataset.\nThis particular dataset was collected in 2013 by a collection veterinarians at The Royal Veterinary College in the United Kingdom.\n\nThe primary goal of the study was to investigate the prevalence of epilepsy in cats; for today, we’ll only be considering the characteristics of the cats included in the study.\n\nSpend a few seconds taking in the dataset, and I’d like to know your initial reactions."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#a-dataset-1",
    "href": "Lectures/Lec01/Lec01.html#a-dataset-1",
    "title": "PSTAT 100: Lecture 01",
    "section": " A Dataset",
    "text": "A Dataset\nCats!\n\n\n Cat.ID                   Breed        Age     Sex Neutered\n      1     Domestic Short hair 14.7515400    Male Neutered\n      2     Domestic Short hair 13.3305955    Male  Unknown\n      3     Domestic Short hair 14.5270363  Female Neutered\n      4     Domestic Short hair 14.8364134    Male Neutered\n      5     Domestic Short hair 13.4154689  Female Neutered\n      6     Domestic Short hair 12.5338809    Male  Unknown\n      7     Domestic Short hair 12.3641342  Female Neutered\n      8     Domestic Short hair  7.6522930    Male  Unknown\n      9     Domestic Short hair 18.7515400    Male Neutered\n     10     Domestic Short hair 11.2005476  Female Neutered\n     11     Domestic Short hair 12.4298426  Female Neutered\n     12     Domestic Short hair  7.5865845  Female Neutered\n     13     Domestic Short hair  7.5865845  Female Neutered\n     14     Domestic Short hair 17.3935661    Male  Unknown\n     15     Domestic Short hair  7.7125257    Male Neutered\n     16     Domestic Short hair 10.2313484    Male  Unknown\n     17     Domestic Short hair  6.3709788  Female Neutered\n     18     Domestic Short hair  6.4175222    Male Neutered\n     19     Domestic Short hair  6.3463381  Female  Unknown\n     20     Domestic Short hair  8.5968515  Female  Unknown\n     21     Domestic Short hair  9.0704997  Female  Unknown\n     22     Domestic Short hair  8.0657084  Female  Unknown\n     23     Domestic Short hair  9.3305955    Male Neutered\n     24     Domestic Short hair 10.6146475  Female Neutered\n     25     Domestic Short hair 10.6146475    Male Neutered\n     26     Domestic Short hair 10.9212868    Male Neutered\n     27     Domestic Short hair 10.4421629  Female  Unknown\n     28     Domestic Short hair 12.2491444    Male Neutered\n     29     Domestic Short hair 10.2642026    Male Neutered\n     30     Domestic Short hair 17.9301848  Female  Unknown\n     31     Domestic Short hair 10.1656400  Female  Unknown\n     32     Domestic Short hair 12.4845996    Male  Unknown\n     33     Domestic Short hair 12.0876112    Male Neutered\n     34     Domestic Short hair 12.6926762  Female Neutered\n     35     Domestic Short hair 11.8110883  Female  Unknown\n     36     Domestic Short hair 11.6988364    Male  Unknown\n     37     Domestic Short hair 11.5838467    Male Neutered\n     38     Domestic Short hair 11.6112252  Female  Unknown\n     39     Domestic Short hair 10.7515400  Female Neutered\n     40     Domestic Short hair 10.6694045    Male  Unknown\n     41     Domestic Short hair 10.7351129    Male Neutered\n     42     Domestic Short hair  7.6577687    Male  Unknown\n     43     Domestic Short hair 13.4154689    Male  Unknown\n     44     Domestic Short hair 22.7515400  Female Neutered\n     45     Domestic Short hair 13.8343600  Female  Unknown\n     46     Domestic Short hair 18.5845311  Female  Unknown\n     47     Domestic Short hair 14.3874059    Male Neutered\n     48     Domestic Short hair 17.4401095    Male  Unknown\n     49     Domestic Short hair  9.4099932  Female  Unknown\n     50     Domestic Short hair  8.3778234  Female  Unknown\n     51     Domestic Short hair 15.1238877  Female Neutered\n     52     Domestic Short hair  8.7008898  Female  Unknown\n     53     Domestic Short hair 10.4175222  Female Neutered\n     54     Domestic Short hair 10.4175222    Male Neutered\n     55     Domestic Short hair 19.9370294  Female Neutered\n     56     Domestic Short hair  9.8261465    Male Neutered\n     57     Domestic Short hair 15.9972621    Male Neutered\n     58     Domestic Short hair 19.4360027  Female Neutered\n     59     Domestic Short hair 13.6673511  Female Neutered\n     60     Domestic Short hair  9.0458590  Female  Unknown\n     61     Domestic Short hair  6.9212868    Male  Unknown\n     62     Domestic Short hair 15.9972621    Male  Unknown\n     63     Domestic Short hair 19.7015743  Female Neutered\n     64     Domestic Short hair 11.3319644  Female Neutered\n     65     Domestic Short hair 19.8275154    Male Neutered\n     66     Domestic Short hair 17.8015058    Male  Unknown\n     67     Domestic Short hair  6.1464750  Female  Unknown\n     68     Domestic Short hair 10.8062971  Female  Unknown\n     69     Domestic Short hair 17.9986311  Female Neutered\n     70      Domestic Long Hair 17.7631759    Male  Unknown\n     71    Domestic Medium Hair  8.2710472  Female  Unknown\n     72     Domestic Short hair  8.5886379  Female  Unknown\n     73     Domestic Short hair  8.5886379    Male  Unknown\n     74     Domestic Short hair  8.5886379  Female  Unknown\n     75     Domestic Short hair  8.5886379  Female Neutered\n     76     Domestic Short hair 13.9986311  Female  Unknown\n     77     Domestic Short hair 18.9979466    Male  Unknown\n     78     Domestic Short hair  7.4195756    Male Neutered\n     79     Domestic Short hair  6.9158111    Male  Unknown\n     80     Domestic Short hair  6.4175222  Female  Unknown\n     81     Domestic Short hair 22.8583162    Male  Unknown\n     82      Domestic Long Hair  6.6584531  Female  Unknown\n     83      Domestic Long Hair  8.8815880    Male  Unknown\n     84      Domestic Long Hair  8.8706366    Male  Unknown\n     85    Domestic Medium Hair  6.7707050  Female  Unknown\n     86 Domestic Semi Long Hair  5.8863792  Female  Unknown\n     87 Domestic Semi Long Hair  5.8863792    Male Neutered\n     88      Domestic Long Hair 15.3921971    Male  Unknown\n     89      Domestic Long Hair 15.6796715  Female Neutered\n     90    Domestic Medium Hair  9.8863792    Male  Unknown\n     91      Domestic Long Hair  9.5222450  Female  Unknown\n     92    Domestic Medium Hair 13.4565366    Male Neutered\n     93 Domestic Semi Long Hair  7.5017112    Male  Unknown\n     94      Domestic Long Hair  7.3921971  Female  Unknown\n     95      Domestic Long Hair 14.2039699  Female  Unknown\n     96      Domestic Long Hair  5.6208077    Male Neutered\n     97 Domestic Semi Long Hair  5.8179329  Female Neutered\n     98    Domestic Medium Hair  5.1718001    Male  Unknown\n     99    Domestic Medium Hair  5.7549624  Female Neutered\n    100      Domestic Long Hair  4.3559206    Male Neutered\n    101     Domestic Short hair 11.7891855    Male Neutered\n    102     Domestic Short hair  7.2662560  Female  Unknown\n    103     Domestic Short hair 11.7262149  Female   Entire\n    104     Domestic Short hair  5.6427105    Male Neutered\n    105     Domestic Short hair 15.0828200  Female  Unknown\n    106     Domestic Short hair 18.0835044  Female  Unknown\n    107     Domestic Short hair 21.5003422  Female  Unknown\n    108     Domestic Short hair 12.8186174  Female  Unknown\n    109     Domestic Short hair 12.4982888  Female  Unknown\n    110     Domestic Short hair 16.2628337  Female Neutered\n    111     Domestic Short hair 13.5824778    Male Neutered\n    112     Domestic Short hair 13.5824778    Male Neutered\n    113     Domestic Short hair 16.6680356  Female Neutered\n    114     Domestic Short hair 10.3490760  Female  Unknown\n    115     Domestic Short hair  7.5592060    Male  Unknown\n    116     Domestic Short hair  6.5325120  Female  Unknown\n    117     Domestic Short hair  6.4175222    Male Neutered\n    118     Domestic Short hair 13.1909651  Female Neutered\n    119     Domestic Short hair  9.7440110    Male  Unknown\n    120     Domestic Short hair 17.1882272  Female  Unknown\n    121     Domestic Short hair 16.1642710    Male  Unknown\n    122     Domestic Short hair  8.4845996    Male  Unknown\n    123     Domestic Short hair 10.3134839  Female  Unknown\n    124     Domestic Short hair 12.3011636  Female Neutered\n    125     Domestic Short hair 14.8911704    Male  Unknown\n    126     Domestic Short hair 13.6673511    Male  Unknown\n    127     Domestic Short hair 12.2765229    Male  Unknown\n    128     Domestic Short hair 17.4154689  Female  Unknown\n    129     Domestic Short hair  6.8610541    Male  Unknown\n    130     Domestic Short hair 13.9986311    Male Neutered\n    131     Domestic Short hair 10.5434634  Female  Unknown\n    132     Domestic Short hair 12.0821355  Female Neutered\n    133     Domestic Short hair  7.5236140    Male  Unknown\n    134     Domestic Short hair  7.5263518  Female Neutered\n    135     Domestic Short hair  8.3668720  Female Neutered\n    136     Domestic Short hair  7.4496920    Male  Unknown\n    137     Domestic Short hair 20.4161533  Female  Unknown\n    138     Domestic Short hair  6.4175222    Male Neutered\n    139     Domestic Short hair 17.0102669    Male Neutered\n    140     Domestic Short hair  9.3333333  Female Neutered\n    141     Domestic Short hair  9.3333333  Female  Unknown\n    142     Domestic Short hair  4.5475702    Male Neutered\n    143     Domestic Short hair 10.7323751    Male  Unknown\n    144     Domestic Short hair  9.4537988    Male  Unknown\n    145    Domestic Medium Hair  9.7878166    Male  Unknown\n    146      Domestic Long Hair 11.1375770    Male Neutered\n    147    Domestic Medium Hair 13.8097194  Female  Unknown\n    148                  Bengal  8.2299795    Male  Unknown\n    149 Domestic Semi Long Hair  5.2375086    Male  Unknown\n    150      Domestic Long Hair  4.3559206  Female Neutered\n    151 Domestic Semi Long Hair  4.3285421    Male  Unknown\n    152     Domestic Short hair 10.7460643    Male  Unknown\n    153     Domestic Short hair  5.5989049    Male  Unknown\n    154     Domestic Short hair  5.4893908    Male  Unknown\n    155     Domestic Short hair  5.5906913  Female  Unknown\n    156     Domestic Short hair  4.7255305    Male Neutered\n    157     Domestic Short hair  4.7255305  Female  Unknown\n    158     Domestic Short hair 12.2600958    Male  Unknown\n    159     Domestic Short hair 10.3436003    Male Neutered\n    160     Domestic Short hair  9.2484600  Female  Unknown\n    161     Domestic Short hair  4.6105407    Male  Unknown\n    162     Domestic Short hair  4.6680356    Male Neutered\n    163     Domestic Short hair  4.6543463    Male Neutered\n    164     Domestic Short hair  5.4291581  Female  Unknown\n    165     Domestic Short hair  6.6447639  Female Neutered\n    166     Domestic Short hair 17.8206708    Male  Unknown\n    167     Domestic Short hair  8.4134155  Female  Unknown\n    168     Domestic Short hair 10.0314853  Female Neutered\n    169     Domestic Short hair 13.4647502    Male Neutered\n    170     Domestic Short hair 10.9459274    Male Neutered\n    171     Domestic Short hair  9.5879535  Female  Unknown\n    172     Domestic Short hair  9.5879535    Male Neutered\n    173     Domestic Short hair  8.7802875  Female  Unknown\n    174     Domestic Short hair  8.5530459    Male Neutered\n    175     Domestic Short hair  4.7665982  Female  Unknown\n    176     Domestic Short hair  4.6160164    Male Neutered\n    177     Domestic Short hair 11.4442163    Male Neutered\n    178     Domestic Short hair  5.1362081  Female Neutered\n    179     Domestic Short hair  7.3839836  Female  Unknown\n    180     Domestic Short hair  4.4900753    Male Neutered\n    181     Domestic Short hair 13.2292950  Female Neutered\n    182     Domestic Short hair         NA    Male  Unknown\n    183     Domestic Short hair  4.7173169  Female Neutered\n    184     Domestic Short hair  4.3915127    Male Neutered\n    185     Domestic Short hair 14.5023956    Male  Unknown\n    186     Domestic Short hair 12.4982888  Female  Unknown\n    187     Domestic Short hair 15.9972621  Female  Unknown\n    188     Domestic Short hair 13.9986311    Male Neutered\n    189     Domestic Short hair 15.7618070  Female  Unknown\n    190     Domestic Short hair  6.4640657  Female Neutered\n    191     Domestic Short hair  6.4175222    Male Neutered\n    192     Domestic Short hair 10.4065708    Male  Unknown\n    193     Domestic Short hair 12.7118412  Female  Unknown\n    194     Domestic Short hair 11.9780972  Female Neutered\n    195     Domestic Short hair  9.7522245    Male Neutered\n    196     Domestic Short hair 13.6563997    Male  Unknown\n    197     Domestic Short hair 17.5058179  Female Neutered\n    198     Domestic Short hair 16.3778234    Male  Unknown\n    199     Domestic Short hair 22.3408624    Male  Unknown\n    200     Domestic Short hair  6.2039699  Female  Unknown\n    201     Domestic Short hair  5.8015058    Male  Unknown\n    202     Domestic Short hair  5.7385352    Male Neutered\n    203     Domestic Short hair  4.7583847    Male Neutered\n    204     Domestic Short hair  4.7227926    Male Neutered\n    205     Domestic Short hair 16.9719370    Male  Unknown\n    206     Domestic Short hair 16.3997262    Male  Unknown\n    207     Domestic Short hair 16.3915127    Male  Unknown\n    208     Domestic Short hair  4.3915127    Male Neutered\n    209     Domestic Short hair  6.2067077    Male Neutered\n    210     Domestic Short hair  8.2491444    Male  Unknown\n    211     Domestic Short hair  4.6214921  Female Neutered\n    212     Domestic Short hair  5.9466119    Male  Unknown\n    213     Domestic Short hair 11.3949350    Male Neutered\n    214     Domestic Short hair  5.5112936  Female  Unknown\n    215     Domestic Short hair  4.7501711    Male  Unknown\n    216     Domestic Short hair  4.4763860    Male  Unknown\n    217     Domestic Short hair  8.5420945    Male Neutered\n    218     Domestic Short hair  4.6872005    Male   Entire\n    219     Domestic Short hair  4.7364819  Female Neutered\n    220     Domestic Short hair  4.5995893    Male Neutered\n    221     Domestic Short hair  6.9979466  Female Neutered\n    222     Domestic Short hair  5.2867899  Female Neutered\n    223     Domestic Short hair 14.8856947    Male Neutered\n    224     Domestic Short hair  6.8939083    Male Neutered\n    225     Domestic Short hair  4.6132786    Male Neutered\n    226     Domestic Short hair  4.3750856    Male Neutered\n    227     Domestic Short hair  4.3750856    Male  Unknown\n    228     Domestic Short hair  4.4928131  Female Neutered\n    229     Domestic Short hair  4.4572211  Female Neutered\n    230     Domestic Short hair  4.5010267  Female  Unknown\n    231     Domestic Short hair  4.5338809    Male  Unknown\n    232     Domestic Short hair  4.5338809  Female Neutered\n    233     Domestic Short hair 15.6687201  Female  Unknown\n    234     Domestic Short hair 19.7508556    Male  Unknown\n    235     Domestic Short hair 14.7515400    Male  Unknown\n    236     Domestic Short hair 12.9117043    Male  Unknown\n    237     Domestic Short hair 13.5824778    Male  Unknown\n    238     Domestic Short hair 19.3100616    Male  Unknown\n    239     Domestic Short hair  4.4763860  Female  Unknown\n    240     Domestic Short hair  4.4599589    Male  Unknown\n    241     Domestic Short hair  4.4763860    Male  Unknown\n    242     Domestic Short hair  4.3312799    Male Neutered\n    243     Domestic Short hair  6.7624914    Male  Unknown\n    244     Domestic Short hair  4.3312799  Female Neutered\n    245     Domestic Short hair 19.6687201    Male Neutered\n    246     Domestic Short hair 13.9986311  Female  Unknown\n    247     Domestic Short hair 15.1238877    Male Neutered\n    248     Domestic Short hair 14.8062971    Male Neutered\n    249     Domestic Short hair  9.7494867  Female  Unknown\n    250     Domestic Short hair 13.7494867  Female  Unknown\n    251     Domestic Short hair 15.7809719  Female  Unknown\n    252     Domestic Short hair 15.7809719  Female  Unknown\n    253     Domestic Short hair 15.9123888    Male Neutered\n    254     Domestic Short hair 15.0663929    Male Neutered\n    255     Domestic Short hair 13.5934292    Male Neutered\n    256     Domestic Short hair 20.1642710    Male  Unknown\n    257     Domestic Short hair 17.4154689  Female Neutered\n    258     Domestic Short hair  6.6283368    Male Neutered\n    259     Domestic Short hair  5.7166324  Female  Unknown\n    260     Domestic Short hair  7.0527036  Female  Unknown\n    261     Domestic Short hair  7.9972621    Male Neutered\n    262     Domestic Short hair  6.1218344  Female  Unknown\n    263     Domestic Short hair  9.0732375  Female  Unknown\n    264     Domestic Short hair 13.3305955  Female Neutered\n    265     Domestic Short hair 14.6694045    Male  Unknown\n    266     Domestic Short hair 16.3312799    Male  Unknown\n    267     Domestic Short hair 19.8357290    Male Neutered\n    268     Domestic Short hair 13.7138946    Male  Unknown\n    269     Domestic Short hair  7.6522930    Male  Unknown\n    270     Domestic Short hair  9.8042437    Male  Unknown\n    271     Domestic Short hair 11.2443532    Male  Unknown\n    272     Domestic Short hair  8.3477070  Female Neutered\n    273     Domestic Short hair 10.7515400    Male Neutered\n    274     Domestic Short hair 10.4010951    Male Neutered\n    275     Domestic Short hair 11.5017112    Male  Unknown\n    276     Domestic Short hair 17.5058179    Male  Unknown\n    277     Domestic Short hair  6.7597536    Male   Entire\n    278     Domestic Short hair  7.4442163  Female  Unknown\n    279     Domestic Short hair 14.2943190    Male Neutered\n    280     Domestic Short hair  9.7741273    Male  Unknown\n    281     Domestic Short hair  6.2833676    Male  Unknown\n    282     Domestic Short hair  6.4010951  Female Neutered\n    283     Domestic Short hair  4.7392197    Male Neutered\n    284     Domestic Short hair  5.2648871  Female Neutered\n    285     Domestic Short hair 15.6687201  Female  Unknown\n    286     Domestic Short hair 15.6687201  Female  Unknown\n    287      Domestic Long Hair 13.0568104    Male Neutered\n    288      Domestic Long Hair 16.7337440    Male Neutered\n    289 Domestic Semi Long Hair  9.1115674    Male Neutered\n    290     Domestic Short hair  4.5037645  Female  Unknown\n    291     Domestic Short hair  4.5037645    Male  Unknown\n    292     Domestic Short hair  4.7036277  Female Neutered\n    293     Domestic Short hair  4.5420945  Female  Unknown\n    294     Domestic Short hair  4.4763860    Male  Unknown\n    295     Domestic Short hair 14.7515400  Female Neutered\n    296     Domestic Short hair 17.3305955    Male  Unknown\n    297     Domestic Short hair 15.2498289    Male Neutered\n    298     Domestic Short hair 14.5023956  Female  Unknown\n    299     Domestic Short hair 17.5003422    Male Neutered\n    300     Domestic Short hair 20.3312799    Male Neutered\n    301     Domestic Short hair 21.9438741    Male  Unknown\n    302     Domestic Short hair 11.3292266  Female  Unknown\n    303     Domestic Short hair  9.4565366    Male Neutered\n    304     Domestic Short hair 10.7214237  Female  Unknown\n    305     Domestic Short hair  9.4264203    Male   Entire\n    306     Domestic Short hair  9.4264203  Female   Entire\n    307     Domestic Short hair  9.2922656  Female Neutered\n    308     Domestic Short hair  9.9493498  Female Neutered\n    309     Domestic Short hair 18.5462012  Female  Unknown\n    310     Domestic Short hair 11.4989733  Female  Unknown\n    311     Domestic Short hair 18.9130732  Female  Unknown\n    312     Domestic Short hair 16.5831622    Male Neutered\n    313     Domestic Short hair 11.7645448    Male Neutered\n    314     Domestic Short hair 14.9979466  Female  Unknown\n    315     Domestic Short hair  7.8576318    Male Neutered\n    316 Domestic Semi Long Hair  5.1225188    Male  Unknown\n    317      Domestic Long Hair 17.9137577    Male Neutered\n    318     Domestic Short hair 16.8350445    Male Neutered\n    319     Domestic Short hair  9.4893908  Female Neutered\n    320     Domestic Short hair  7.5482546  Female Neutered\n    321     Domestic Short hair  8.5886379  Female  Unknown\n    322     Domestic Short hair  9.0622861    Male Neutered\n    323     Domestic Short hair  6.5763176  Female  Unknown\n    324     Domestic Short hair  6.5270363  Female Neutered\n    325     Domestic Short hair  6.4421629    Male  Unknown\n    326     Domestic Short hair  5.3141684  Female Neutered\n    327    Domestic Medium Hair  5.9274470    Male Neutered\n    328      Domestic Long Hair 17.8343600  Female Neutered\n    329    Domestic Medium Hair  7.5701574    Male  Unknown\n    330 Domestic Semi Long Hair  6.2258727  Female Neutered\n    331    Domestic Medium Hair  6.3326489    Male Neutered\n    332    Domestic Medium Hair  6.3326489    Male Neutered\n    333      Domestic Long Hair  5.3141684    Male Neutered\n    334    Domestic Medium Hair  9.7084189    Male Neutered\n    335    Domestic Medium Hair  7.7837098    Male Neutered\n    336      Domestic Long Hair 13.5824778  Female  Unknown\n    337    Domestic Medium Hair 11.5920602    Male Neutered\n    338    Domestic Medium Hair 11.4880219    Male Neutered\n    339      Domestic Long Hair  9.3196441  Female  Unknown\n    340      Domestic Long Hair  7.4332649    Male Neutered\n    341     Domestic Short hair  4.1779603    Male  Unknown\n    342     Domestic Short hair  7.7070500    Male  Unknown\n    343     Domestic Short hair 18.5845311  Female  Unknown\n    344     Domestic Short hair 18.2505133  Female Neutered\n    345     Domestic Short hair 16.4490075  Female  Unknown\n    346     Domestic Short hair 12.4079398    Male Neutered\n    347     Domestic Short hair 11.4168378  Female Neutered\n    348     Domestic Short hair 18.3956194  Female  Unknown\n    349     Domestic Short hair  6.3874059  Female Neutered\n    350     Domestic Short hair  6.1984942  Female  Unknown\n    351     Domestic Short hair  8.4709103  Female  Unknown\n    352     Domestic Short hair  9.3305955  Female  Unknown\n    353     Domestic Short hair 13.7577002  Female  Unknown\n    354     Domestic Short hair 14.2176591  Female  Unknown\n    355     Domestic Short hair 11.5975359  Female  Unknown\n    356     Domestic Short hair 17.9986311  Female  Unknown\n    357     Domestic Short hair  6.8364134  Female Neutered\n    358     Domestic Short hair 10.7652293  Female  Unknown\n    359     Domestic Short hair 12.8459959  Female  Unknown\n    360     Domestic Short hair  5.7686516  Female  Unknown\n    361     Domestic Short hair 14.5023956  Female Neutered\n    362     Domestic Short hair 14.5023956  Female Neutered\n    363     Domestic Short hair  8.8213552  Female Neutered\n    364     Domestic Short hair  6.3901437  Female Neutered\n    365      Domestic Long Hair  7.1238877  Female  Unknown\n    366 Domestic Semi Long Hair  6.6803559  Female  Unknown\n    367      Domestic Long Hair 10.6995209  Female  Unknown\n    368      Domestic Long Hair 13.1088296  Female  Unknown\n    369    Domestic Medium Hair  5.4318960  Female Neutered\n    370      Domestic Long Hair  9.6563997    Male  Unknown\n    371      Domestic Long Hair  5.0896646  Female  Unknown\n    372      Domestic Long Hair 15.4168378  Female  Unknown\n    373      Domestic Long Hair 12.9965777  Female Neutered\n    374    Domestic Medium Hair 15.9123888  Female  Unknown\n    375     Domestic Short hair  9.4537988  Female Neutered\n    376     Domestic Short hair  8.6954141    Male  Unknown\n    377     Domestic Short hair 16.8350445    Male  Unknown\n    378     Domestic Short hair 14.5023956    Male  Unknown\n    379     Domestic Short hair 15.9123888  Female Neutered\n    380     Domestic Short hair 15.8357290  Female Neutered\n    381     Domestic Short hair 16.8350445  Female  Unknown\n    382     Domestic Short hair 16.7501711  Female Neutered\n    383     Domestic Short hair  7.0444901  Female Neutered\n    384     Domestic Short hair  4.5037645  Female  Unknown\n    385     Domestic Short hair  4.1314168    Male Neutered\n    386     Domestic Short hair  6.4120465  Female  Unknown\n    387     Domestic Short hair 13.4072553    Male Neutered\n    388     Domestic Short hair  9.0732375  Female  Unknown\n    389     Domestic Short hair 13.5003422    Male Neutered\n    390     Domestic Short hair  9.7850787    Male  Unknown\n    391     Domestic Short hair  9.3607118    Male Neutered\n    392     Domestic Short hair 10.5845311    Male Neutered\n    393     Domestic Short hair 12.5503080  Female Neutered\n    394     Domestic Short hair 19.5756331  Female  Unknown\n    395     Domestic Short hair 13.1115674    Male  Unknown\n    396     Domestic Short hair  6.7679671    Male  Unknown\n    397     Domestic Short hair 15.9972621    Male  Unknown\n    398      Domestic Long Hair  7.1622177  Female   Entire\n    399      Domestic Long Hair 16.9582478  Female Neutered\n    400      Domestic Long Hair  6.2231348    Male  Unknown\n    401    Domestic Medium Hair  6.4175222    Male  Unknown\n    402    Domestic Medium Hair 11.5592060    Male Neutered\n    403    Domestic Medium Hair 14.2121834    Male  Unknown\n    404     Domestic Short hair  4.4024641  Female  Unknown\n    405     Domestic Short hair 16.4161533  Female Neutered\n    406     Domestic Short hair 14.5023956    Male  Unknown\n    407     Domestic Short hair 16.3312799    Male  Unknown\n    408     Domestic Short hair 14.3326489  Female  Unknown\n    409     Domestic Short hair 12.3312799  Female  Unknown\n    410     Domestic Short hair 12.3312799    Male Neutered\n    411     Domestic Short hair  4.9582478  Female Neutered\n    412     Domestic Short hair 10.5845311    Male Neutered\n    413     Domestic Short hair 10.6639288    Male  Unknown\n    414      Domestic Long Hair 12.8761123    Male Neutered\n    415    Domestic Medium Hair  6.5106092  Female  Unknown\n    416    Domestic Medium Hair  6.5023956    Male  Unknown\n    417 Domestic Semi Long Hair  6.0944559    Male  Unknown\n    418    Domestic Medium Hair  8.5639973  Female  Unknown\n    419    Domestic Medium Hair 10.2422998    Male Neutered\n    420 Domestic Semi Long Hair  5.5359343  Female  Unknown\n    421 Domestic Semi Long Hair  5.5112936  Female  Unknown\n    422      Domestic Long Hair 18.3080082    Male Neutered\n    423      Domestic Long Hair 16.6680356    Male Neutered\n    424      Domestic Long Hair 16.5256674    Male  Unknown\n    425      Domestic Long Hair  6.4312115    Male  Unknown\n    426    Domestic Medium Hair  8.3312799  Female  Unknown\n    427 Domestic Semi Long Hair 17.7029432    Male  Unknown\n    428 Domestic Semi Long Hair  4.0520192    Male Neutered\n    429      Domestic Long Hair  1.5003422    Male Neutered\n    430     Domestic Short hair 12.8651608  Female Neutered\n    431     Domestic Short hair 17.5003422  Female Neutered\n    432     Domestic Short hair 15.5017112    Male  Unknown\n    433     Domestic Short hair 14.5023956    Male Neutered\n    434     Domestic Short hair 19.2498289    Male Neutered\n    435     Domestic Short hair 19.4168378    Male Neutered\n    436     Domestic Short hair 21.0157426  Female  Unknown\n    437     Domestic Short hair  7.6522930    Male  Unknown\n    438     Domestic Short hair 18.8939083  Female  Unknown\n    439     Domestic Short hair  8.6269678    Male  Unknown\n    440     Domestic Short hair  5.2867899  Female Neutered\n    441     Domestic Short hair  8.3422313    Male Neutered\n    442     Domestic Short hair  8.3422313  Female Neutered\n    443     Domestic Short hair 10.8145106    Male  Unknown\n    444     Domestic Short hair 19.6878850  Female  Unknown\n    445     Domestic Short hair 21.3305955    Male  Unknown\n    446     Domestic Short hair  3.6468172  Female Neutered\n    447     Domestic Short hair 18.8829569  Female  Unknown\n    448     Domestic Short hair 12.5475702    Male Neutered\n    449     Domestic Short hair 13.0814511    Male  Unknown\n    450     Domestic Short hair 11.4907598    Male  Unknown\n    451     Domestic Short hair 18.2258727  Female  Unknown\n    452     Domestic Short hair 20.2491444  Female  Unknown\n    453     Domestic Short hair  4.0602327  Female  Unknown\n    454     Domestic Short hair 19.9041752    Male Neutered\n    455     Domestic Short hair  5.5989049    Male  Unknown\n    456     Domestic Short hair 14.7515400  Female  Unknown\n    457     Domestic Short hair 14.7515400    Male Neutered\n    458     Domestic Short hair 11.9452430    Male Neutered\n    459     Domestic Short hair  9.7494867  Female Neutered\n    460 Domestic Semi Long Hair  5.5359343  Female  Unknown\n    461    Domestic Medium Hair 10.9979466    Male Neutered\n    462     Domestic Short hair 18.9979466  Female Neutered\n    463     Domestic Short hair 11.2361396  Female  Unknown\n    464     Domestic Short hair 10.6201232  Female  Unknown\n    465     Domestic Short hair 10.4175222  Female Neutered\n    466     Domestic Short hair  8.6433949    Male Neutered\n    467     Domestic Short hair 17.5961670  Female  Unknown\n    468     Domestic Short hair  7.5783710  Female  Unknown\n    469     Domestic Short hair  5.5222450    Male Neutered\n    470     Domestic Short hair  5.3032170    Male Neutered\n    471     Domestic Short hair 16.8350445    Male Neutered\n    472     Domestic Short hair  6.7241615    Male  Unknown\n    473     Domestic Short hair  5.3305955  Female Neutered\n    474     Domestic Short hair  6.9459274    Male  Unknown\n    475     Domestic Short hair 17.2813142    Male Neutered\n    476     Domestic Short hair  6.3901437    Male Neutered\n    477     Domestic Short hair 12.8350445  Female Neutered\n    478    Domestic Medium Hair 10.7077344    Male Neutered\n    479 Domestic Semi Long Hair  3.4031485    Male Neutered\n    480      Domestic Long Hair  3.4004107    Male Neutered\n    481      Domestic Long Hair 12.9965777  Female  Unknown\n    482     Domestic Short hair  5.7494867    Male Neutered\n    483     Domestic Short hair 13.1635866    Male  Unknown\n    484     Domestic Short hair  4.4900753  Female Neutered\n    485     Domestic Short hair 15.0280630  Female  Unknown\n    486     Domestic Short hair  4.1834360    Male  Unknown\n    487     Domestic Short hair  4.2491444    Male Neutered\n    488     Domestic Short hair 15.6687201    Male Neutered\n    489     Domestic Short hair 14.4421629  Female Neutered\n    490     Domestic Short hair 17.3744011    Male Neutered\n    491     Domestic Short hair  9.8453114  Female Neutered\n    492     Domestic Short hair  7.5482546    Male Neutered\n    493     Domestic Short hair 18.7268994  Female Neutered\n    494     Domestic Short hair  7.1348392    Male   Entire\n    495     Domestic Short hair 13.8261465  Female  Unknown\n    496     Domestic Short hair  6.6803559    Male  Unknown\n    497     Domestic Short hair  6.2724162    Male Neutered\n    498     Domestic Short hair  9.7248460  Female  Unknown\n    499     Domestic Short hair  8.7255305    Male Neutered\n    500     Domestic Short hair  8.7255305    Male  Unknown\n    501     Domestic Short hair 19.9123888    Male  Unknown\n    502     Domestic Short hair 13.4154689    Male  Unknown\n    503     Domestic Short hair  6.2286105    Male  Unknown\n    504     Domestic Short hair 10.5598905  Female  Unknown\n    505     Domestic Short hair  4.7501711  Female Neutered\n    506     Domestic Short hair  4.3203285  Female  Unknown\n    507     Domestic Short hair 14.7515400  Female Neutered\n    508     Domestic Short hair 10.0616016  Female  Unknown\n    509     Domestic Short hair  9.6509240    Male Neutered\n    510     Domestic Short hair 11.5373032    Male Neutered\n    511     Domestic Short hair 11.5811088  Female  Unknown\n    512                  Bengal  8.3942505  Female  Unknown\n    513      Domestic Long Hair 11.5975359  Female  Unknown\n    514      Domestic Long Hair 15.3182752  Female  Unknown\n    515 Domestic Semi Long Hair  5.5879535  Female  Unknown\n    516      Domestic Long Hair  5.4647502  Female Neutered\n    517                  Bengal  4.9911020    Male Neutered\n    518    Domestic Medium Hair  9.6563997  Female  Unknown\n    519                  Bengal  4.6160164    Male Neutered\n    520     Domestic Short hair 15.4168378  Female Neutered\n    521     Domestic Short hair 16.1861739  Female  Unknown\n    522     Domestic Short hair  8.2381930  Female Neutered\n    523     Domestic Short hair 10.1054073    Male  Unknown\n    524     Domestic Short hair  5.6290212  Female Neutered\n    525     Domestic Short hair  6.0451745  Female Neutered\n    526     Domestic Short hair 16.5831622  Female  Unknown\n    527      Domestic Long Hair 16.1642710    Male Neutered\n    528      Domestic Long Hair 21.4647502  Female Neutered\n    529      Domestic Long Hair  5.6728268  Female  Unknown\n    530    Domestic Medium Hair  5.1827515  Female  Unknown\n    531    Domestic Medium Hair  5.1827515    Male Neutered\n    532    Domestic Medium Hair 15.7563313    Male Neutered\n    533    Domestic Medium Hair 15.7508556  Female  Unknown\n    534      Domestic Long Hair 11.2361396  Female Neutered\n    535                  Bengal  5.8124572    Male Neutered\n    536      Domestic Long Hair  5.3223819    Male Neutered\n    537      Domestic Long Hair 13.1635866    Male  Unknown\n    538    Domestic Medium Hair  7.0444901  Female Neutered\n    539      Domestic Long Hair 10.9979466  Female   Entire\n    540    Domestic Medium Hair  5.9986311    Male Neutered\n    541      Domestic Long Hair 16.4161533  Female Neutered\n    542      Domestic Long Hair 11.5017112    Male Neutered\n    543      Domestic Long Hair 13.5003422    Male  Unknown\n    544      Domestic Long Hair 10.8555784    Male  Unknown\n    545 Domestic Semi Long Hair  3.2498289  Female  Unknown\n    546      Domestic Long Hair  5.7303217    Male  Unknown\n    547     Domestic Short hair 17.7823409  Female  Unknown\n    548     Domestic Short hair  5.2101300    Male Neutered\n    549     Domestic Short hair 14.7515400  Female Neutered\n    550     Domestic Short hair  7.8083504    Male  Unknown\n    551     Domestic Short hair  8.7337440    Male  Unknown\n    552     Domestic Short hair 12.5366188    Male  Unknown\n    553     Domestic Short hair  4.9171800  Female Neutered\n    554     Domestic Short hair  9.7494867  Female  Unknown\n    555     Domestic Short hair 11.5208761  Female Neutered\n    556     Domestic Short hair 11.4086242    Male Neutered\n    557     Domestic Short hair 10.8555784  Female  Unknown\n    558     Domestic Short hair 10.8555784  Female Neutered\n    559     Domestic Short hair 14.5626283  Female Neutered\n    560     Domestic Short hair 12.8706366  Female  Unknown\n    561      Domestic Long Hair 19.3347023    Male Neutered\n    562      Domestic Long Hair 14.9623546  Female  Unknown\n    563    Domestic Medium Hair 11.1047228    Male Neutered\n    564    Domestic Medium Hair 11.6933607    Male Neutered\n    565    Domestic Medium Hair  3.4798084  Female  Unknown\n    566    Domestic Medium Hair  8.6160164    Male  Unknown\n    567      Domestic Long Hair  8.7282683  Female  Unknown\n    568     Domestic Short hair  7.7262149    Male Neutered\n    569     Domestic Short hair 23.2224504    Male Neutered\n    570     Domestic Short hair 19.1622177    Male  Unknown\n    571     Domestic Short hair  8.1587953  Female  Unknown\n    572     Domestic Short hair 17.2484600  Female  Unknown\n    573     Domestic Short hair 14.1930185    Male Neutered\n    574     Domestic Short hair  2.3572895  Female  Unknown\n    575     Domestic Short hair  2.3791923  Female Neutered\n    576     Domestic Short hair  7.5728953    Male  Unknown\n    577     Domestic Short hair  4.3039014  Female Neutered\n    578     Domestic Short hair  4.1834360    Male  Unknown\n    579     Domestic Short hair  9.0266940    Male  Unknown\n    580     Domestic Short hair  8.5886379  Female Neutered\n    581     Domestic Short hair  9.1635866    Male  Unknown\n    582     Domestic Short hair 17.5961670    Male  Unknown\n    583     Domestic Short hair  5.6728268  Female Neutered\n    584     Domestic Short hair  5.4236824    Male Neutered\n    585     Domestic Short hair 17.3305955    Male  Unknown\n    586     Domestic Short hair 10.5845311    Male Neutered\n    587     Domestic Short hair 14.7077344    Male Neutered\n    588     Domestic Short hair  5.1362081  Female  Unknown\n    589     Domestic Short hair 17.4154689    Male Neutered\n    590     Domestic Short hair 13.9986311  Female  Unknown\n    591     Domestic Short hair  2.3928816  Female Neutered\n    592     Domestic Short hair 16.5694730  Female  Unknown\n    593     Domestic Short hair 16.7501711    Male Neutered\n    594     Domestic Short hair  9.4510609    Male Neutered\n    595     Domestic Short hair 12.7501711    Male Neutered\n    596     Domestic Short hair  1.5550992    Male  Unknown\n    597     Domestic Short hair  2.9678303    Male  Unknown\n    598     Domestic Short hair  3.6522930    Male Neutered\n    599     Domestic Short hair  3.1649555  Female Neutered\n    600     Domestic Short hair  3.2416153  Female  Unknown\n    601     Domestic Short hair 16.3696099    Male   Entire\n    602      Domestic Long Hair  8.6406571  Female Neutered\n    603      Domestic Long Hair 17.2019165  Female  Unknown\n    604      Domestic Long Hair  2.4394251  Female  Unknown\n    605     Domestic Short hair 13.7494867  Female  Unknown\n    606     Domestic Short hair 10.7652293  Female  Unknown\n    607     Domestic Short hair 14.1382615  Female  Unknown\n    608     Domestic Short hair 13.3771389  Female Neutered\n    609     Domestic Short hair 20.0821355  Female  Unknown\n    610     Domestic Short hair  9.4318960  Female Neutered\n    611     Domestic Short hair 15.5154004  Female Neutered\n    612     Domestic Short hair 16.3312799  Female Neutered\n    613     Domestic Short hair 19.9780972  Female Neutered\n    614     Domestic Short hair  6.1984942  Female Neutered\n    615     Domestic Short hair  4.3778234  Female Neutered\n    616     Domestic Short hair  5.3634497  Female Neutered\n    617     Domestic Short hair 11.2553046  Female  Unknown\n    618     Domestic Short hair 10.7652293  Female  Unknown\n    619     Domestic Short hair  7.9972621  Female  Unknown\n    620     Domestic Short hair  9.2156057  Female  Unknown\n    621      Domestic Long Hair 10.6995209    Male Neutered\n    622                   Other         NA Unknown   Entire\n    623    Domestic Medium Hair  9.5112936    Male Neutered\n    624      Domestic Long Hair 11.1594798  Female  Unknown\n    625                   Other         NA Unknown   Entire\n    626      Domestic Long Hair  7.4414784    Male Neutered\n    627    Domestic Medium Hair  4.3696099    Male Neutered\n    628      Domestic Long Hair 12.8021903  Female Neutered\n    629                   Other         NA Unknown   Entire\n    630      Domestic Long Hair 13.7494867  Female Neutered\n    631      Domestic Long Hair  8.9965777  Female   Entire\n    632      Domestic Long Hair  1.5030801    Male   Entire\n    633     Domestic Short hair 16.4818617    Male Neutered\n    634     Domestic Short hair         NA Unknown  Unknown\n    635     Domestic Short hair  8.9363450    Male  Unknown\n    636     Domestic Short hair  4.7693361  Female  Unknown\n    637     Domestic Short hair  5.3579740  Female Neutered\n    638     Domestic Short hair 16.5010267    Male Neutered\n    639     Domestic Short hair 16.8350445  Female Neutered\n    640     Domestic Short hair 14.8364134    Male  Unknown\n    641     Domestic Short hair 20.4161533  Female  Unknown\n    642     Domestic Short hair 16.5831622    Male  Unknown\n    643     Domestic Short hair  6.9815195  Female  Unknown\n    644     Domestic Short hair  9.5058179    Male Neutered\n    645     Domestic Short hair 15.6331280    Male Neutered\n    646     Domestic Short hair 10.6721424  Female  Unknown\n    647     Domestic Short hair  8.6105407  Female  Unknown\n    648     Domestic Short hair  1.5304586    Male Neutered\n    649     Domestic Short hair  2.5598905    Male Neutered\n    650     Domestic Short hair  3.5017112  Female  Unknown\n    651     Domestic Short hair  8.7967146    Male Neutered\n    652     Domestic Short hair  8.2929500    Male  Unknown\n    653     Domestic Short hair  5.8863792    Male Neutered\n    654     Domestic Short hair  1.2867899    Male Neutered\n    655     Domestic Short hair  1.3552361    Male  Unknown\n    656     Domestic Short hair 14.9979466    Male   Entire\n    657     Domestic Short hair  4.8240931    Male  Unknown\n    658     Domestic Short hair 15.5017112  Female Neutered\n    659     Domestic Short hair 12.7392197    Male Neutered\n    660     Domestic Short hair 12.7036277  Female Neutered\n    661     Domestic Short hair  9.7111567    Male  Unknown\n    662     Domestic Short hair  4.3066393    Male  Unknown\n    663     Domestic Short hair  4.8405202    Male  Unknown\n    664     Domestic Short hair  1.4428474    Male Neutered\n    665     Domestic Short hair  1.3059548    Male  Unknown\n    666     Domestic Short hair  8.0465435    Male   Entire\n    667     Domestic Short hair  1.2867899    Male Neutered\n    668     Domestic Short hair  1.3524983  Female  Unknown\n    669     Domestic Short hair  1.3716632    Male  Unknown\n    670    Domestic Medium Hair 17.5578371  Female  Unknown\n    671      Domestic Long Hair         NA  Female   Entire\n    672                   Other         NA Unknown  Unknown\n    673     Domestic Short hair 13.6673511    Male Neutered\n    674     Domestic Short hair  7.6030116  Female  Unknown\n    675     Domestic Short hair 10.0999316  Female Neutered\n    676     Domestic Short hair 12.9418207  Female  Unknown\n    677     Domestic Short hair  9.8398357  Female  Unknown\n    678     Domestic Short hair 10.6694045    Male  Unknown\n    679     Domestic Short hair 19.4168378  Female Neutered\n    680     Domestic Short hair 14.9130732  Female  Unknown\n    681     Domestic Short hair  4.6269678  Female  Unknown\n    682     Domestic Short hair  5.2484600  Female   Entire\n    683     Domestic Short hair 15.8357290    Male  Unknown\n    684     Domestic Short hair 14.4175222  Female Neutered\n    685     Domestic Short hair  5.6700890    Male Neutered\n    686     Domestic Short hair  4.5366188  Female Neutered\n    687     Domestic Short hair 12.0219028    Male  Unknown\n    688     Domestic Short hair  6.1218344    Male  Unknown\n    689     Domestic Short hair  5.4154689  Female  Unknown\n    690     Domestic Short hair 21.6673511  Female Neutered\n    691     Domestic Short hair  8.6023272    Male  Unknown\n    692     Domestic Short hair  4.8678987  Female Neutered\n    693     Domestic Short hair 14.3846680    Male  Unknown\n    694     Domestic Short hair 13.1006160  Female Neutered\n    695     Domestic Short hair 15.3730322  Female Neutered\n    696     Domestic Short hair  9.6043806    Male  Unknown\n    697     Domestic Short hair  8.6023272  Female Neutered\n    698     Domestic Short hair 12.8761123  Female Neutered\n    699     Domestic Short hair  1.3497604  Female Neutered\n    700     Domestic Short hair  4.7036277  Female  Unknown\n    701     Domestic Short hair  1.0157426  Female Neutered\n    702                  Bengal 14.5845311    Male  Unknown\n    703                   Other  5.3661875  Female  Unknown\n    704    Domestic Medium Hair 14.7159480    Male Neutered\n    705     Domestic Short hair 21.6372348  Female  Unknown\n    706     Domestic Short hair  3.3921971  Female Neutered\n    707     Domestic Short hair  7.3237509    Male Neutered\n    708     Domestic Short hair  9.9986311    Male Neutered\n    709     Domestic Short hair  7.8384668    Male  Unknown\n    710     Domestic Short hair  3.3648186    Male  Unknown\n    711     Domestic Short hair  3.7234771    Male Neutered\n    712     Domestic Short hair  4.2135524  Female Neutered\n    713     Domestic Short hair  5.1800137    Male Neutered\n    714     Domestic Short hair 15.6550308    Male  Unknown\n    715     Domestic Short hair 12.3641342  Female Neutered\n    716     Domestic Short hair  1.6071184    Male Neutered\n    717     Domestic Short hair  6.8364134    Male  Unknown\n    718     Domestic Short hair  2.5106092    Male Neutered\n    719     Domestic Short hair  2.4996578    Male  Unknown\n    720      Domestic Long Hair  9.6700890  Female  Unknown\n    721    Domestic Medium Hair  2.4585900    Male Neutered\n    722    Domestic Medium Hair 10.1081451    Male Neutered\n    723 Domestic Semi Long Hair  8.4517454  Female Neutered\n    724    Domestic Medium Hair 16.4380561    Male Neutered\n    725      Domestic Long Hair 10.5023956    Male Neutered\n    726 Domestic Semi Long Hair  4.2436687  Female Neutered\n    727      Domestic Long Hair  3.3155373  Female   Entire\n    728      Domestic Long Hair 18.1464750  Female  Unknown\n    729    Domestic Medium Hair  3.2251882    Male  Unknown\n    730      Domestic Long Hair 15.5619439    Male Neutered\n    731    Domestic Medium Hair  1.5687885    Male Neutered\n    732    Domestic Medium Hair  1.3114305    Male  Unknown\n    733      Domestic Long Hair 14.7871321  Female  Unknown\n    734    Domestic Medium Hair  0.8993694    Male   Entire\n    735    Domestic Medium Hair  0.8268309    Male   Entire\n    736 Domestic Semi Long Hair  1.2621492  Female Neutered\n    737     Domestic Short hair 16.7830253  Female  Unknown\n    738     Domestic Short hair  8.7693361  Female  Unknown\n    739     Domestic Short hair  7.7344285  Female  Unknown\n    740     Domestic Short hair  1.1800137    Male  Unknown\n    741     Domestic Short hair  5.9110198 Unknown  Unknown\n    742     Domestic Short hair  3.4086242  Female  Unknown\n    743     Domestic Short hair  1.4483231    Male  Unknown\n    744     Domestic Short hair  1.3196441    Male Neutered\n    745     Domestic Short hair  5.9000684    Male   Entire\n    746     Domestic Short hair  1.6536619    Male  Unknown\n    747     Domestic Short hair  1.2621492    Male  Unknown\n    748     Domestic Short hair  1.3880903  Female Neutered\n    749     Domestic Short hair  1.3004791    Male  Unknown\n    750     Domestic Short hair  1.4291581    Male   Entire\n    751     Domestic Short hair  5.8809035    Male  Unknown\n    752     Domestic Short hair  1.2813142    Male  Unknown\n    753     Domestic Short hair 11.8494182  Female Neutered\n    754     Domestic Short hair 11.7727584  Female Neutered\n    755     Domestic Short hair  5.9739904    Male  Unknown\n    756     Domestic Short hair  4.4490075  Female Neutered\n    757     Domestic Short hair  4.1095140  Female Neutered\n    758     Domestic Short hair 12.6954141    Male  Unknown\n    759     Domestic Short hair  6.2669405  Female Neutered\n    760     Domestic Short hair 14.4175222  Female Neutered\n    761     Domestic Short hair  0.9719370    Male   Entire\n    762     Domestic Short hair  1.1827515    Male   Entire\n    763     Domestic Short hair 13.2375086    Male Neutered\n    764     Domestic Short hair 11.3319644    Male Neutered\n    765     Domestic Short hair  1.3990418    Male  Unknown\n    766      Domestic Long Hair 12.7967146  Female Neutered\n    767     Domestic Short hair  7.4031485  Female  Unknown\n    768     Domestic Short hair  7.4031485  Female Neutered\n    769     Domestic Short hair  7.2744695  Female  Unknown\n    770     Domestic Short hair         NA  Female Neutered\n    771     Domestic Short hair 14.9979466    Male Neutered\n    772     Domestic Short hair  2.4394251  Female  Unknown\n    773     Domestic Short hair  6.7816564    Male Neutered\n    774     Domestic Short hair  5.8343600    Male  Unknown\n    775     Domestic Short hair  5.8343600    Male  Unknown\n    776     Domestic Short hair  7.7891855  Female  Unknown\n    777     Domestic Short hair 11.5427789    Male  Unknown\n    778     Domestic Short hair 13.1170431    Male  Unknown\n    779     Domestic Short hair  2.6119097    Male Neutered\n    780     Domestic Short hair  4.3559206    Male  Unknown\n    781     Domestic Short hair 10.9158111    Male Neutered\n    782     Domestic Short hair  8.6707734  Female  Unknown\n    783     Domestic Short hair  6.5763176  Female  Unknown\n    784     Domestic Short hair  3.8932238  Female  Unknown\n    785     Domestic Short hair 20.9117043    Male  Unknown\n    786     Domestic Short hair 11.8658453  Female  Unknown\n    787     Domestic Short hair  1.2648871  Female  Unknown\n    788     Domestic Short hair  5.9110198    Male Neutered\n    789     Domestic Short hair  7.4140999    Male Neutered\n    790     Domestic Short hair  2.6639288  Female  Unknown\n    791     Domestic Short hair  2.9596167  Female  Unknown\n    792     Domestic Short hair 18.4503765    Male  Unknown\n    793     Domestic Short hair  3.6057495  Female  Unknown\n    794     Domestic Short hair  1.4565366    Male Neutered\n    795     Domestic Short hair 13.4839151  Female  Unknown\n    796     Domestic Short hair 13.4839151  Female Neutered\n    797     Domestic Short hair 16.5831622    Male Neutered\n    798     Domestic Short hair  8.7036277  Female Neutered\n    799     Domestic Short hair 15.4168378  Female  Unknown\n    800     Domestic Short hair 15.8357290  Female Neutered\n    801     Domestic Short hair 10.7515400  Female Neutered\n    802     Domestic Short hair  5.1663244  Female Neutered\n    803     Domestic Short hair 11.2991102  Female  Unknown\n    804     Domestic Short hair  4.6379192  Female Neutered\n    805     Domestic Short hair  2.7515400    Male  Unknown\n    806     Domestic Short hair  1.5304586    Male Neutered\n    807     Domestic Short hair  2.4010951  Female Neutered\n    808     Domestic Short hair         NA    Male  Unknown\n    809     Domestic Short hair  2.1081451  Female Neutered\n    810     Domestic Short hair 16.8377823    Male Neutered\n    811     Domestic Short hair  1.2855798    Male Neutered\n    812     Domestic Short hair         NA  Female Neutered\n    813     Domestic Short hair  0.9707322  Female   Entire\n    814     Domestic Short hair  0.9707299  Female   Entire\n    815     Domestic Short hair  0.9707004  Female  Unknown\n    816     Domestic Short hair  6.0971937  Female   Entire\n    817     Domestic Short hair  6.5790554  Female Neutered\n    818     Domestic Short hair  3.2443532    Male Neutered\n    819     Domestic Short hair  0.9281314  Female  Unknown\n    820     Domestic Short hair  1.3744011    Male Neutered\n    821     Domestic Short hair 18.3928816  Female Neutered\n    822     Domestic Short hair  5.0184805  Female  Unknown\n    823     Domestic Short hair  3.2114990    Male Neutered\n    824     Domestic Short hair  0.9707026  Female   Entire\n    825     Domestic Short hair  0.9719370  Female  Unknown\n    826     Domestic Short hair  1.5304586    Male  Unknown\n    827     Domestic Short hair  8.2819986  Female  Unknown\n    828     Domestic Short hair 14.8364134  Female  Unknown\n    829     Domestic Short hair  7.5674196  Female Neutered\n    830     Domestic Short hair  3.9041752    Male  Unknown\n    831     Domestic Short hair  3.8850103    Male  Unknown\n    832     Domestic Short hair  7.7371663    Male Neutered\n    833     Domestic Short hair  3.4880219    Male Neutered\n    834     Domestic Short hair  7.4140999  Female  Unknown\n    835     Domestic Short hair  4.2655715    Male  Unknown\n    836     Domestic Short hair  8.4626968    Male  Unknown\n    837     Domestic Short hair  8.7337440    Male  Unknown\n    838     Domestic Short hair  2.5106092  Female  Unknown\n    839     Domestic Short hair 16.7748118    Male   Entire\n    840     Domestic Short hair  1.3470226  Female Neutered\n    841     Domestic Short hair  1.3086927  Female Neutered\n    842     Domestic Short hair  0.9034908  Female  Unknown\n    843     Domestic Short hair  0.9226557    Male  Unknown\n    844     Domestic Short hair  3.3073238    Male  Unknown\n    845     Domestic Short hair 11.1786448  Female  Unknown\n    846     Domestic Short hair 11.6687201    Male Neutered\n    847     Domestic Short hair  4.0602327    Male  Unknown\n    848     Domestic Short hair  0.7857632  Female   Entire\n    849     Domestic Short hair  7.7316906    Male Neutered\n    850     Domestic Short hair 11.7207392    Male Neutered\n    851     Domestic Short hair 10.6885695    Male Neutered\n    852     Domestic Short hair  3.6878850  Female  Unknown\n    853     Domestic Short hair  2.6885695  Female Neutered\n    854     Domestic Short hair  3.2498289  Female  Unknown\n    855     Domestic Short hair  7.6960986    Male Neutered\n    856     Domestic Short hair 15.8877481    Male  Unknown\n    857     Domestic Short hair  4.8651608    Male  Unknown\n    858     Domestic Short hair  1.9603012  Female  Unknown\n    859     Domestic Short hair  6.3737166    Male  Unknown\n    860     Domestic Short hair  6.7926078  Female Neutered\n    861     Domestic Short hair 15.5017112    Male Neutered\n    862     Domestic Short hair 10.1984942  Female  Unknown\n    863     Domestic Short hair  2.6119097    Male  Unknown\n    864     Domestic Short hair  2.5489391    Male  Unknown\n    865     Domestic Short hair  2.4996578    Male Neutered\n    866     Domestic Short hair 11.7919233  Female Neutered\n    867     Domestic Short hair 12.8733744    Male Neutered\n    868     Domestic Short hair  6.8227242    Male  Unknown\n    869     Domestic Short hair 19.3812457  Female Neutered\n    870     Domestic Short hair  1.1800137  Female Neutered\n    871     Domestic Short hair 14.9075975  Female Neutered\n    872     Domestic Short hair  1.5742642  Female Neutered\n    873     Domestic Short hair  1.4072553  Female  Unknown\n    874     Domestic Short hair  1.7385352    Male Neutered\n    875     Domestic Short hair  1.6481862    Male Neutered\n    876     Domestic Short hair  1.4620123  Female  Unknown\n    877     Domestic Short hair  1.8672142    Male  Unknown\n    878     Domestic Short hair  3.8576318  Female  Unknown\n    879     Domestic Short hair  3.8576318    Male  Unknown\n    880     Domestic Short hair  4.3504449    Male  Unknown\n    881     Domestic Short hair 10.6803559    Male  Unknown\n    882     Domestic Short hair  2.9596167  Female Neutered\n    883     Domestic Short hair  3.9972621    Male  Unknown\n    884     Domestic Short hair 11.1238877  Female  Unknown\n    885     Domestic Short hair  4.9746749    Male Neutered\n    886     Domestic Short hair  9.3305955    Male Neutered\n    887     Domestic Short hair 16.1642710  Female  Unknown\n    888     Domestic Short hair 18.6694045    Male Neutered\n    889     Domestic Short hair 12.5338809  Female Neutered\n    890     Domestic Short hair 13.5003422  Female  Unknown\n    891     Domestic Short hair  5.3935661    Male  Unknown\n    892     Domestic Short hair 19.5017112  Female Neutered\n    893     Domestic Short hair  1.7138946    Male  Unknown\n    894     Domestic Short hair 16.5831622  Female  Unknown\n    895     Domestic Short hair 15.8850103    Male  Unknown\n    896     Domestic Short hair 11.7043121    Male Neutered\n    897     Domestic Short hair  2.4804928    Male Neutered\n    898     Domestic Short hair  2.4668036    Male  Unknown\n    899     Domestic Short hair  2.7679671  Female  Unknown\n    900     Domestic Short hair  1.3497604  Female  Unknown\n    901     Domestic Short hair         NA    Male Neutered\n    902     Domestic Short hair  1.8206708  Female  Unknown\n    903     Domestic Short hair  9.6673511  Female  Unknown\n    904     Domestic Short hair  2.4010951  Female   Entire\n    905     Domestic Short hair         NA    Male Neutered\n    906     Domestic Short hair  0.8925394    Male  Unknown\n    907     Domestic Short hair 17.7686516  Female Neutered\n    908     Domestic Short hair 12.8952772  Female Neutered\n    909     Domestic Short hair 12.9117043    Male  Unknown\n    910     Domestic Short hair  3.4688569  Female  Unknown\n    911     Domestic Short hair  3.3785079    Male   Entire\n    912     Domestic Short hair  3.5592060    Male Neutered\n    913     Domestic Short hair  3.5592060  Female  Unknown\n    914     Domestic Short hair  5.6618754  Female Neutered\n    915     Domestic Short hair  8.2464066  Female  Unknown\n    916     Domestic Short hair  2.2477755  Female   Entire\n    917     Domestic Short hair 22.7433265  Female  Unknown\n    918     Domestic Short hair  2.7351129  Female  Unknown\n    919     Domestic Short hair  1.2265572  Female Neutered\n    920     Domestic Short hair 13.7494867    Male  Unknown\n    921     Domestic Short hair 11.1156742  Female  Unknown\n    922     Domestic Short hair  5.3086927  Female Neutered\n    923     Domestic Short hair  1.3470226  Female Neutered\n    924     Domestic Short hair  1.5003422    Male  Unknown\n    925     Domestic Short hair  4.8213552  Female  Unknown\n    926     Domestic Short hair  2.8199863  Female  Unknown\n    927     Domestic Short hair         NA    Male   Entire\n    928     Domestic Short hair  2.3326489    Male  Unknown\n    929     Domestic Short hair  5.7494867  Female  Unknown\n    930     Domestic Short hair  4.3367556    Male  Unknown\n    931     Domestic Short hair  3.5592060  Female Neutered\n    932     Domestic Short hair 10.2368241    Male  Unknown\n    933     Domestic Short hair  3.7919233  Female Neutered\n    934     Domestic Short hair  6.2614648    Male  Unknown\n    935     Domestic Short hair  5.2210815  Female  Unknown\n    936     Domestic Short hair 12.2108145  Female  Unknown\n    937     Domestic Short hair  0.7857632  Female  Unknown\n    938     Domestic Short hair  2.7433265  Female Neutered\n    939     Domestic Short hair  0.8925394    Male  Unknown\n    940     Domestic Short hair 13.2073922    Male  Unknown\n    941    Domestic Medium Hair  9.3771389  Female Neutered\n    942 Domestic Semi Long Hair  4.3668720  Female Neutered\n    943      Domestic Long Hair 11.3264887  Female Neutered\n    944 Domestic Semi Long Hair  1.4401095    Male  Unknown\n    945 Domestic Semi Long Hair  9.2648871  Female Neutered\n    946      Domestic Long Hair  3.5592060  Female  Unknown\n    947                  Bengal  2.4503765  Female  Unknown\n    948      Domestic Long Hair  2.5598905  Female Neutered\n    949    Domestic Medium Hair 21.5441478  Female  Unknown\n    950 Domestic Semi Long Hair  1.4537988  Female Neutered\n    951    Domestic Medium Hair  1.5085558  Female   Entire\n    952                 Burmese  4.3394935    Male  Unknown\n    953                 Burmese  1.1060917  Female  Unknown\n    954                 Burmese 16.9171800    Male Neutered\n    955                 Burmese 14.9924709  Female Neutered\n    956     Domestic Short hair  2.6830938    Male Neutered\n    957     Domestic Short hair 11.8986995    Male   Entire\n    958     Domestic Short hair  3.9123888  Female  Unknown\n    959     Domestic Short hair  1.7193703    Male Neutered\n    960     Domestic Short hair  1.4373717  Female Neutered\n    961     Domestic Short hair  6.2669405    Male Neutered\n    962     Domestic Short hair 11.6824093    Male Neutered\n    963     Domestic Short hair 18.6694045    Male Neutered\n    964     Domestic Short hair         NA  Female  Unknown\n    965     Domestic Short hair  8.5065024  Female  Unknown\n    966     Domestic Short hair 15.2826831    Male  Unknown\n    967     Domestic Short hair  6.8418891    Male  Unknown\n    968     Domestic Short hair  2.0944559  Female Neutered\n    969     Domestic Short hair  1.1772758    Male Neutered\n    970     Domestic Short hair  2.2505133    Male Neutered\n    971     Domestic Short hair  9.8234086    Male  Unknown\n    972                  Moggie  7.8329911  Female  Unknown\n    973     Domestic Short hair         NA    Male  Unknown\n    974     Domestic Short hair         NA    Male  Unknown\n    975     Domestic Short hair  1.2292950  Female  Unknown\n    976     Domestic Short hair  6.8062971  Female Neutered\n    977     Domestic Short hair  1.8015058  Female Neutered\n    978     Domestic Short hair  7.2908966    Male  Unknown\n    979     Domestic Short hair  1.6235455    Male   Entire\n    980     Domestic Short hair         NA    Male  Unknown\n    981     Domestic Short hair  0.8925394  Female  Unknown\n    982     Domestic Short hair  5.7768652    Male Neutered\n    983     Domestic Short hair  7.3292266  Female Neutered\n    984     Domestic Short hair  3.6002738    Male  Unknown\n    985                 Burmese 10.5735797    Male  Unknown\n    986      British Short Hair  3.2772074  Female Neutered\n    987                 Burmese 13.6673511    Male  Unknown\n    988                 Burmese  6.6228611    Male  Unknown\n    989      British Short Hair  2.8802190    Male  Unknown\n    990                 Ragdoll  3.6605065    Male  Unknown\n    991      British Short Hair 11.2580424  Female Neutered\n    992                 Ragdoll  3.4469541    Male Neutered\n    993                Siberian  2.1738535    Male Neutered\n    994     Domestic Short hair 12.2381930  Female  Unknown\n    995     Domestic Short hair  6.7268994    Male  Unknown\n    996     Domestic Short hair  2.7077344  Female Neutered\n    997     Domestic Short hair  2.3983573    Male  Unknown\n    998     Domestic Short hair  8.1040383    Male  Unknown\n    999     Domestic Short hair  1.8398357    Male  Unknown\n   1000     Domestic Short hair  1.5085558  Female Neutered\n [ reached 'max' / getOption(\"max.print\") -- omitted 284547 rows ]"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#cats-dataset",
    "href": "Lectures/Lec01/Lec01.html#cats-dataset",
    "title": "PSTAT 100: Lecture 01",
    "section": " Cats Dataset",
    "text": "Cats Dataset\nInitial Thoughts\n\nOn the one hand, we could make some observations about how the data is displayed\n\nFor example, it’s a pretty big dataset (I even had to truncate the output so that it fits in this presentation!)\nThe entries are displayed tabularly (sometimes called “rectangularly”)\n\nOn the other, we could make observations about what the data is saying\n\nEach row represents information about a particular cat\nFrom each cat, we have information on a series of attributes (sex, age, etc.)"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#semantics-vs.-structure",
    "href": "Lectures/Lec01/Lec01.html#semantics-vs.-structure",
    "title": "PSTAT 100: Lecture 01",
    "section": " Semantics vs. Structure",
    "text": "Semantics vs. Structure\n\nIn general, we distinguish between the semantics and structure of a particular dataset.\nThe semantics of a dataset relate to the meaning behind the data.\n\nWhat is the data trying to tell us?\n\nThe structure of a dataset pertains to how the data is displayed or organized.\n\nHow is the data telling us what it is telling us?\n\nWe’ll focus on data semantics for today, and return to the topic of data structure tomorrow."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-semantics",
    "href": "Lectures/Lec01/Lec01.html#data-semantics",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Semantics",
    "text": "Data Semantics\nDefinition\n\n\n\n\n\n\nDefinition: Data\n\n\nWe define an observation to be a collection of values measured on certain attributes (aka variables). From a semantic standpoint, we define data to be a collection of observations collected on observational units."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#cats-dataset-1",
    "href": "Lectures/Lec01/Lec01.html#cats-dataset-1",
    "title": "PSTAT 100: Lecture 01",
    "section": " Cats Dataset",
    "text": "Cats Dataset\nSemantics\n\n\n Cat.ID               Breed      Age    Sex Neutered\n      1 Domestic Short hair 14.75154   Male Neutered\n      2 Domestic Short hair 13.33060   Male  Unknown\n      3 Domestic Short hair 14.52704 Female Neutered\n      4 Domestic Short hair 14.83641   Male Neutered\n [ reached 'max' / getOption(\"max.print\") -- omitted 285543 rows ]\n\n\n\nExample Observation:\n\nThere was a 14.75154-year old Neutered Male Domestic Short Hair Cat, whose ID was 1."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#cats-dataset-2",
    "href": "Lectures/Lec01/Lec01.html#cats-dataset-2",
    "title": "PSTAT 100: Lecture 01",
    "section": " Cats Dataset",
    "text": "Cats Dataset\nSemantics\n\nThere was a cat whose ID was 1, whose breed was “Domestic Short hair”, whose age was 14.75154, whose sex was “Male”, and whose Neutered status was “Neutered”.\n\n\nVariables: ID, Breed, Age, Sex, Neutered Status\n\n\n\nThere was a cat whose ID was 1, whose breed was “Domestic Short hair”, whose age was 14.75154, whose sex was “Male”, and whose Neutered status was “Neutered”.\n\n\n\nValues: (1, “Domestic Short hair”, 14.75154, “Male”, “Neutered”)"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#data-semantics-1",
    "href": "Lectures/Lec01/Lec01.html#data-semantics-1",
    "title": "PSTAT 100: Lecture 01",
    "section": " Data Semantics",
    "text": "Data Semantics\nObservational Units\n\nWhen trying to identify the observational units of a particular dataset, I like to ask myself the question: “if I were to replicate this data (i.e. re-collect it myself), what object/item would I actually observe/take measurements on?”\n\nFor example, if I wanted to replicate the cats dataset, I would need to start by collecting a bunch of cats, on which I could take measurements of whatever attributes I want.\n\nNote that observational units aren’t always living entities; we could imagine a dataset in which countries are the observational units (e.g. we could measure various attributes - like GDP, life expectancy, etc. - about the different countries of the world)"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#another-dataset",
    "href": "Lectures/Lec01/Lec01.html#another-dataset",
    "title": "PSTAT 100: Lecture 01",
    "section": " Another Dataset",
    "text": "Another Dataset\nUndergraduate PSTAT Course Enrollments\n\n\n      Course               Title S25 W25 F24 M24 S24 W24 F23 M23 S23 W23 F22\n    PSTAT 5A  UNDERSTANDING DATA 167 222 213  76 258 283 549 110 212 279 499\n    PSTAT 5H          STATISTICS  11  14  30  NA  31  24  25  NA  31  22   4\n   PSTAT 5LS  STAT LIFE SCIENCES 355 340 348  59 304 299  NA  39 299 294  NA\n     PSTAT 8  TRANS DS PROB STAT  70 105 137  22  83 134 132  18  86 156  70\n    PSTAT 10  DATA SCIENCE PRINC 235 241 286  93 234 260 285  83 240 282 257\n    PSTAT 99 INDEPENDENT STUDIES   1   2  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 100        DS_CONC&ANLS 109 131 108  NA  95  NA 104  48 125 127  NA\n   PSTAT 105  INTRO N-PARAM METH  NA  79  NA  NA  NA  NA  39  NA  NA  NA  79\n   PSTAT 109 STATISTICS FOR ECON  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 115 BAYES DATA ANALYSIS  81  56  74  25  74  96  16  15  38  70  63\n  PSTAT 120A   PROB & STATISTICS 310 383 345  75 367 372 419  86 237 246 419\n  PSTAT 120B   PROB & STATISTICS 312 329 236 136 382 241 261 102 256 256 165\n  PSTAT 120C   PROB & STATISTICS 163  NA  37 129 131  39  19  81  65  31  87\n   PSTAT 122 DESIGN OF EXPERMNTS 240 210 201  NA 177 162 167  NA 194 187 182\n   PSTAT 123  SAMPLING TECHNIQUE  NA  NA  NA  NA  NA 137  NA  NA  NA  NA  NA\n   PSTAT 126 REGRESSION ANALYSIS 197 214 272  94 147 200 123  84 149 175 182\n   PSTAT 127    ADV STATS MODELS  NA  NA  72  NA  NA  NA  57  NA  NA  73  NA\n   PSTAT 130    SAS BASE PROGRAM 116 120 121 108 122  97 120  95 119  98  97\n   PSTAT 131  STAT MACHINE LEARN  96 156  64  80  93 138 150  55 108 197 178\n   PSTAT 132 DATABASES FOR STATS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 134   STAT DATA SCIENCE  46  91  78  NA  70  78  80  NA  87  42  33\n   PSTAT 135  BIG DATA ANALYTICS  96  NA  NA  NA  NA  99  NA  NA  NA  93  NA\n   PSTAT 140 STATISTICAL PROCESS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 160A  STOCHASTIC PROCESS 132 217 126  NA 100 153 132  NA 108 161 184\n  PSTAT 160B  STOCHASTIC PROCESS 116  77  86  NA 106  73  43   7  82  81  58\n   PSTAT 170  INTRO MATH FINANCE 116  65  92  19 125  65  59  17  77  57  55\n   PSTAT 171   MATH COMPOUND INT  73  77  96  47  84  68 102  32  64  69 108\n  PSTAT 172A    ACTUARIAL STAT I  NA  49  NA  NA  NA  60  NA  NA  NA  43  NA\n  PSTAT 172B   ACTUARIAL STAT II  14  NA  NA  NA  20  NA  NA  NA  23  NA  NA\n   PSTAT 173         RISK THEORY  NA  NA  64  NA  NA  NA  35  NA  NA  NA  43\n   PSTAT 174         TIME SERIES  NA  89  83  NA 104  63  NA  NA 170 118  69\n   PSTAT 175   SURVIVAL ANALYSIS  71  NA  NA  NA  55  NA  18  NA  NA  NA  73\n   PSTAT 176    ADV MATH FINANCE  17  NA  NA  NA  15  NA  NA  NA  13  NA  NA\n   PSTAT 177      FINANCIAL RISK  31  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 182T  ACTUARIAL TUTORIAL  12  20  15  NA  17   6   4  NA   6   4   7\n   PSTAT 183  ACTUARIAL CONCEPTS  28  NA  NA  NA  44  NA  NA  NA  46  NA  NA\n   PSTAT 190        ULA TRAINING  NA  NA  14  NA  NA  NA   5  NA  NA  NA  20\n   PSTAT 191       ULA PRACTICUM  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 193 INTERNSHIP IN STATS   4   3   4  28   6   4   8  20   6   3   2\n   PSTAT 194  GRP STDY ADV STDNT  NA  NA  NA  11  29  NA  NA  NA  28  NA  NA\n   PSTAT 195      SPECIAL TOPICS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 196   RESEARCH IN ACTSC  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 197A    DS CAPSTONE PREP  NA  NA  59  NA  NA  NA  58  NA  NA  NA  59\n  PSTAT 197B DS CAPSTONE PROJECT  NA  58  NA  NA  NA  56  NA  NA  NA  53  NA\n  PSTAT 197C DS CAPSTONE PROJECT  52  NA  NA  NA  53  NA  NA  NA  46  NA  NA\n   PSTAT 199 INDEPENDENT STUDIES  23  22  18   6  19  17  23   6  21  17  21\n PSTAT 199RA INDEP RESEARCH ASST  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n M22 S22 W22\n 116 194 278\n  NA  NA  NA\n  63 294 284\n  23  59  NA\n  87 278 287\n  NA  NA  NA\n  NA  95  88\n  NA  NA  93\n  NA  NA  NA\n  NA  NA  81\n  65 244 229\n 174 216 241\n 109 119  NA\n  NA 137 119\n  NA  NA  NA\n  67 250 123\n  NA  78  91\n 138 122  98\n  NA  75  76\n  NA  NA  NA\n  22  NA  66\n  NA  NA  NA\n  NA  NA  NA\n  51 130  77\n  54 109  72\n  41  74  69\n  49  70  68\n  NA  NA  60\n  NA  26  NA\n  NA  NA  50\n  NA  61  74\n  NA  NA  NA\n  NA  15  NA\n  NA  NA  NA\n  NA  12   5\n  NA  68  NA\n  NA  NA  NA\n  NA  NA  NA\n  35   5   4\n  NA  66  NA\n  NA  NA  NA\n  NA  NA  NA\n  NA  NA  NA\n  NA  NA  46\n  NA  47  NA\n  10  19   5\n  NA  NA  NA"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#another-dataset-1",
    "href": "Lectures/Lec01/Lec01.html#another-dataset-1",
    "title": "PSTAT 100: Lecture 01",
    "section": " Another Dataset",
    "text": "Another Dataset\nUndergraduate PSTAT Course Enrollments\n\nObservational Units: UCSB Courses\nAn observation: The enrollment for PSTAT 5A, titled “Understanding Data” was 167 in Spring 2025, 222 in Winter 2025, 213 in Fall 2024, etc.\nVariables: Spring 2025, Winter 2025, Fall 2024, etc,\nIs that right, though?\n\nWhat is the value of Spring 2025 - is it really 167?\nIsn’t 167 the value of a Course Enrollment variable?\nIsn’t Spring 2025 actually itself a value of another variable (one we might call Quarter)?"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#another-dataset-2",
    "href": "Lectures/Lec01/Lec01.html#another-dataset-2",
    "title": "PSTAT 100: Lecture 01",
    "section": " Another Dataset",
    "text": "Another Dataset\nUndergraduate PSTAT Course Enrollments\n\nAt this point, we find ourselves at a bit of a crossroads.\nFor now, let’s adopt the following set of variables (tomorrow, we’ll discuss whether or not this choice is unique - spoiler alert, it is not!)\n\nCourse: the course ID\nCourse Title: the course title\nQuarter: the quarter in which the course was offered\nEnrollment: the enrollment count of the particular course in a particular quarter"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#another-dataset-3",
    "href": "Lectures/Lec01/Lec01.html#another-dataset-3",
    "title": "PSTAT 100: Lecture 01",
    "section": " Another Dataset",
    "text": "Another Dataset\nUndergraduate PSTAT Course Enrollments\n\nOriginal FormatNew Format A Question\n\n\n\n\n      Course               Title S25 W25 F24 M24 S24 W24 F23 M23 S23 W23 F22\n    PSTAT 5A  UNDERSTANDING DATA 167 222 213  76 258 283 549 110 212 279 499\n    PSTAT 5H          STATISTICS  11  14  30  NA  31  24  25  NA  31  22   4\n   PSTAT 5LS  STAT LIFE SCIENCES 355 340 348  59 304 299  NA  39 299 294  NA\n     PSTAT 8  TRANS DS PROB STAT  70 105 137  22  83 134 132  18  86 156  70\n    PSTAT 10  DATA SCIENCE PRINC 235 241 286  93 234 260 285  83 240 282 257\n    PSTAT 99 INDEPENDENT STUDIES   1   2  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 100        DS_CONC&ANLS 109 131 108  NA  95  NA 104  48 125 127  NA\n   PSTAT 105  INTRO N-PARAM METH  NA  79  NA  NA  NA  NA  39  NA  NA  NA  79\n   PSTAT 109 STATISTICS FOR ECON  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 115 BAYES DATA ANALYSIS  81  56  74  25  74  96  16  15  38  70  63\n  PSTAT 120A   PROB & STATISTICS 310 383 345  75 367 372 419  86 237 246 419\n  PSTAT 120B   PROB & STATISTICS 312 329 236 136 382 241 261 102 256 256 165\n  PSTAT 120C   PROB & STATISTICS 163  NA  37 129 131  39  19  81  65  31  87\n   PSTAT 122 DESIGN OF EXPERMNTS 240 210 201  NA 177 162 167  NA 194 187 182\n   PSTAT 123  SAMPLING TECHNIQUE  NA  NA  NA  NA  NA 137  NA  NA  NA  NA  NA\n   PSTAT 126 REGRESSION ANALYSIS 197 214 272  94 147 200 123  84 149 175 182\n   PSTAT 127    ADV STATS MODELS  NA  NA  72  NA  NA  NA  57  NA  NA  73  NA\n   PSTAT 130    SAS BASE PROGRAM 116 120 121 108 122  97 120  95 119  98  97\n   PSTAT 131  STAT MACHINE LEARN  96 156  64  80  93 138 150  55 108 197 178\n   PSTAT 132 DATABASES FOR STATS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 134   STAT DATA SCIENCE  46  91  78  NA  70  78  80  NA  87  42  33\n   PSTAT 135  BIG DATA ANALYTICS  96  NA  NA  NA  NA  99  NA  NA  NA  93  NA\n   PSTAT 140 STATISTICAL PROCESS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 160A  STOCHASTIC PROCESS 132 217 126  NA 100 153 132  NA 108 161 184\n  PSTAT 160B  STOCHASTIC PROCESS 116  77  86  NA 106  73  43   7  82  81  58\n   PSTAT 170  INTRO MATH FINANCE 116  65  92  19 125  65  59  17  77  57  55\n   PSTAT 171   MATH COMPOUND INT  73  77  96  47  84  68 102  32  64  69 108\n  PSTAT 172A    ACTUARIAL STAT I  NA  49  NA  NA  NA  60  NA  NA  NA  43  NA\n  PSTAT 172B   ACTUARIAL STAT II  14  NA  NA  NA  20  NA  NA  NA  23  NA  NA\n   PSTAT 173         RISK THEORY  NA  NA  64  NA  NA  NA  35  NA  NA  NA  43\n   PSTAT 174         TIME SERIES  NA  89  83  NA 104  63  NA  NA 170 118  69\n   PSTAT 175   SURVIVAL ANALYSIS  71  NA  NA  NA  55  NA  18  NA  NA  NA  73\n   PSTAT 176    ADV MATH FINANCE  17  NA  NA  NA  15  NA  NA  NA  13  NA  NA\n   PSTAT 177      FINANCIAL RISK  31  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 182T  ACTUARIAL TUTORIAL  12  20  15  NA  17   6   4  NA   6   4   7\n   PSTAT 183  ACTUARIAL CONCEPTS  28  NA  NA  NA  44  NA  NA  NA  46  NA  NA\n   PSTAT 190        ULA TRAINING  NA  NA  14  NA  NA  NA   5  NA  NA  NA  20\n   PSTAT 191       ULA PRACTICUM  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 193 INTERNSHIP IN STATS   4   3   4  28   6   4   8  20   6   3   2\n   PSTAT 194  GRP STDY ADV STDNT  NA  NA  NA  11  29  NA  NA  NA  28  NA  NA\n   PSTAT 195      SPECIAL TOPICS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 196   RESEARCH IN ACTSC  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 197A    DS CAPSTONE PREP  NA  NA  59  NA  NA  NA  58  NA  NA  NA  59\n  PSTAT 197B DS CAPSTONE PROJECT  NA  58  NA  NA  NA  56  NA  NA  NA  53  NA\n  PSTAT 197C DS CAPSTONE PROJECT  52  NA  NA  NA  53  NA  NA  NA  46  NA  NA\n   PSTAT 199 INDEPENDENT STUDIES  23  22  18   6  19  17  23   6  21  17  21\n PSTAT 199RA INDEP RESEARCH ASST  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n M22 S22 W22\n 116 194 278\n  NA  NA  NA\n  63 294 284\n  23  59  NA\n  87 278 287\n  NA  NA  NA\n  NA  95  88\n  NA  NA  93\n  NA  NA  NA\n  NA  NA  81\n  65 244 229\n 174 216 241\n 109 119  NA\n  NA 137 119\n  NA  NA  NA\n  67 250 123\n  NA  78  91\n 138 122  98\n  NA  75  76\n  NA  NA  NA\n  22  NA  66\n  NA  NA  NA\n  NA  NA  NA\n  51 130  77\n  54 109  72\n  41  74  69\n  49  70  68\n  NA  NA  60\n  NA  26  NA\n  NA  NA  50\n  NA  61  74\n  NA  NA  NA\n  NA  15  NA\n  NA  NA  NA\n  NA  12   5\n  NA  68  NA\n  NA  NA  NA\n  NA  NA  NA\n  35   5   4\n  NA  66  NA\n  NA  NA  NA\n  NA  NA  NA\n  NA  NA  NA\n  NA  NA  46\n  NA  47  NA\n  10  19   5\n  NA  NA  NA\n\n\n\n\n\n\n\n\n\n      Course               Title Quarter Enrollment\n    PSTAT 5A  UNDERSTANDING DATA     S25        167\n    PSTAT 5H          STATISTICS     S25         11\n   PSTAT 5LS  STAT LIFE SCIENCES     S25        355\n     PSTAT 8  TRANS DS PROB STAT     S25         70\n    PSTAT 10  DATA SCIENCE PRINC     S25        235\n    PSTAT 99 INDEPENDENT STUDIES     S25          1\n   PSTAT 100        DS_CONC&ANLS     S25        109\n   PSTAT 105  INTRO N-PARAM METH     S25         NA\n   PSTAT 109 STATISTICS FOR ECON     S25         NA\n   PSTAT 115 BAYES DATA ANALYSIS     S25         81\n  PSTAT 120A   PROB & STATISTICS     S25        310\n  PSTAT 120B   PROB & STATISTICS     S25        312\n  PSTAT 120C   PROB & STATISTICS     S25        163\n   PSTAT 122 DESIGN OF EXPERMNTS     S25        240\n   PSTAT 123  SAMPLING TECHNIQUE     S25         NA\n   PSTAT 126 REGRESSION ANALYSIS     S25        197\n   PSTAT 127    ADV STATS MODELS     S25         NA\n   PSTAT 130    SAS BASE PROGRAM     S25        116\n   PSTAT 131  STAT MACHINE LEARN     S25         96\n   PSTAT 132 DATABASES FOR STATS     S25         NA\n   PSTAT 134   STAT DATA SCIENCE     S25         46\n   PSTAT 135  BIG DATA ANALYTICS     S25         96\n   PSTAT 140 STATISTICAL PROCESS     S25         NA\n  PSTAT 160A  STOCHASTIC PROCESS     S25        132\n  PSTAT 160B  STOCHASTIC PROCESS     S25        116\n   PSTAT 170  INTRO MATH FINANCE     S25        116\n   PSTAT 171   MATH COMPOUND INT     S25         73\n  PSTAT 172A    ACTUARIAL STAT I     S25         NA\n  PSTAT 172B   ACTUARIAL STAT II     S25         14\n   PSTAT 173         RISK THEORY     S25         NA\n   PSTAT 174         TIME SERIES     S25         NA\n   PSTAT 175   SURVIVAL ANALYSIS     S25         71\n   PSTAT 176    ADV MATH FINANCE     S25         17\n   PSTAT 177      FINANCIAL RISK     S25         31\n  PSTAT 182T  ACTUARIAL TUTORIAL     S25         12\n   PSTAT 183  ACTUARIAL CONCEPTS     S25         28\n   PSTAT 190        ULA TRAINING     S25         NA\n   PSTAT 191       ULA PRACTICUM     S25         NA\n   PSTAT 193 INTERNSHIP IN STATS     S25          4\n   PSTAT 194  GRP STDY ADV STDNT     S25         NA\n   PSTAT 195      SPECIAL TOPICS     S25         NA\n   PSTAT 196   RESEARCH IN ACTSC     S25         NA\n  PSTAT 197A    DS CAPSTONE PREP     S25         NA\n  PSTAT 197B DS CAPSTONE PROJECT     S25         NA\n  PSTAT 197C DS CAPSTONE PROJECT     S25         52\n   PSTAT 199 INDEPENDENT STUDIES     S25         23\n PSTAT 199RA INDEP RESEARCH ASST     S25         NA\n    PSTAT 5A  UNDERSTANDING DATA     W25        222\n    PSTAT 5H          STATISTICS     W25         14\n   PSTAT 5LS  STAT LIFE SCIENCES     W25        340\n     PSTAT 8  TRANS DS PROB STAT     W25        105\n    PSTAT 10  DATA SCIENCE PRINC     W25        241\n    PSTAT 99 INDEPENDENT STUDIES     W25          2\n   PSTAT 100        DS_CONC&ANLS     W25        131\n   PSTAT 105  INTRO N-PARAM METH     W25         79\n   PSTAT 109 STATISTICS FOR ECON     W25         NA\n   PSTAT 115 BAYES DATA ANALYSIS     W25         56\n  PSTAT 120A   PROB & STATISTICS     W25        383\n  PSTAT 120B   PROB & STATISTICS     W25        329\n  PSTAT 120C   PROB & STATISTICS     W25         NA\n   PSTAT 122 DESIGN OF EXPERMNTS     W25        210\n   PSTAT 123  SAMPLING TECHNIQUE     W25         NA\n   PSTAT 126 REGRESSION ANALYSIS     W25        214\n   PSTAT 127    ADV STATS MODELS     W25         NA\n   PSTAT 130    SAS BASE PROGRAM     W25        120\n   PSTAT 131  STAT MACHINE LEARN     W25        156\n   PSTAT 132 DATABASES FOR STATS     W25         NA\n   PSTAT 134   STAT DATA SCIENCE     W25         91\n   PSTAT 135  BIG DATA ANALYTICS     W25         NA\n   PSTAT 140 STATISTICAL PROCESS     W25         NA\n  PSTAT 160A  STOCHASTIC PROCESS     W25        217\n  PSTAT 160B  STOCHASTIC PROCESS     W25         77\n   PSTAT 170  INTRO MATH FINANCE     W25         65\n   PSTAT 171   MATH COMPOUND INT     W25         77\n  PSTAT 172A    ACTUARIAL STAT I     W25         49\n  PSTAT 172B   ACTUARIAL STAT II     W25         NA\n   PSTAT 173         RISK THEORY     W25         NA\n   PSTAT 174         TIME SERIES     W25         89\n   PSTAT 175   SURVIVAL ANALYSIS     W25         NA\n   PSTAT 176    ADV MATH FINANCE     W25         NA\n   PSTAT 177      FINANCIAL RISK     W25         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     W25         20\n   PSTAT 183  ACTUARIAL CONCEPTS     W25         NA\n   PSTAT 190        ULA TRAINING     W25         NA\n   PSTAT 191       ULA PRACTICUM     W25         NA\n   PSTAT 193 INTERNSHIP IN STATS     W25          3\n   PSTAT 194  GRP STDY ADV STDNT     W25         NA\n   PSTAT 195      SPECIAL TOPICS     W25         NA\n   PSTAT 196   RESEARCH IN ACTSC     W25         NA\n  PSTAT 197A    DS CAPSTONE PREP     W25         NA\n  PSTAT 197B DS CAPSTONE PROJECT     W25         58\n  PSTAT 197C DS CAPSTONE PROJECT     W25         NA\n   PSTAT 199 INDEPENDENT STUDIES     W25         22\n PSTAT 199RA INDEP RESEARCH ASST     W25         NA\n    PSTAT 5A  UNDERSTANDING DATA     F24        213\n    PSTAT 5H          STATISTICS     F24         30\n   PSTAT 5LS  STAT LIFE SCIENCES     F24        348\n     PSTAT 8  TRANS DS PROB STAT     F24        137\n    PSTAT 10  DATA SCIENCE PRINC     F24        286\n    PSTAT 99 INDEPENDENT STUDIES     F24         NA\n   PSTAT 100        DS_CONC&ANLS     F24        108\n   PSTAT 105  INTRO N-PARAM METH     F24         NA\n   PSTAT 109 STATISTICS FOR ECON     F24         NA\n   PSTAT 115 BAYES DATA ANALYSIS     F24         74\n  PSTAT 120A   PROB & STATISTICS     F24        345\n  PSTAT 120B   PROB & STATISTICS     F24        236\n  PSTAT 120C   PROB & STATISTICS     F24         37\n   PSTAT 122 DESIGN OF EXPERMNTS     F24        201\n   PSTAT 123  SAMPLING TECHNIQUE     F24         NA\n   PSTAT 126 REGRESSION ANALYSIS     F24        272\n   PSTAT 127    ADV STATS MODELS     F24         72\n   PSTAT 130    SAS BASE PROGRAM     F24        121\n   PSTAT 131  STAT MACHINE LEARN     F24         64\n   PSTAT 132 DATABASES FOR STATS     F24         NA\n   PSTAT 134   STAT DATA SCIENCE     F24         78\n   PSTAT 135  BIG DATA ANALYTICS     F24         NA\n   PSTAT 140 STATISTICAL PROCESS     F24         NA\n  PSTAT 160A  STOCHASTIC PROCESS     F24        126\n  PSTAT 160B  STOCHASTIC PROCESS     F24         86\n   PSTAT 170  INTRO MATH FINANCE     F24         92\n   PSTAT 171   MATH COMPOUND INT     F24         96\n  PSTAT 172A    ACTUARIAL STAT I     F24         NA\n  PSTAT 172B   ACTUARIAL STAT II     F24         NA\n   PSTAT 173         RISK THEORY     F24         64\n   PSTAT 174         TIME SERIES     F24         83\n   PSTAT 175   SURVIVAL ANALYSIS     F24         NA\n   PSTAT 176    ADV MATH FINANCE     F24         NA\n   PSTAT 177      FINANCIAL RISK     F24         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     F24         15\n   PSTAT 183  ACTUARIAL CONCEPTS     F24         NA\n   PSTAT 190        ULA TRAINING     F24         14\n   PSTAT 191       ULA PRACTICUM     F24         NA\n   PSTAT 193 INTERNSHIP IN STATS     F24          4\n   PSTAT 194  GRP STDY ADV STDNT     F24         NA\n   PSTAT 195      SPECIAL TOPICS     F24         NA\n   PSTAT 196   RESEARCH IN ACTSC     F24         NA\n  PSTAT 197A    DS CAPSTONE PREP     F24         59\n  PSTAT 197B DS CAPSTONE PROJECT     F24         NA\n  PSTAT 197C DS CAPSTONE PROJECT     F24         NA\n   PSTAT 199 INDEPENDENT STUDIES     F24         18\n PSTAT 199RA INDEP RESEARCH ASST     F24         NA\n    PSTAT 5A  UNDERSTANDING DATA     M24         76\n    PSTAT 5H          STATISTICS     M24         NA\n   PSTAT 5LS  STAT LIFE SCIENCES     M24         59\n     PSTAT 8  TRANS DS PROB STAT     M24         22\n    PSTAT 10  DATA SCIENCE PRINC     M24         93\n    PSTAT 99 INDEPENDENT STUDIES     M24         NA\n   PSTAT 100        DS_CONC&ANLS     M24         NA\n   PSTAT 105  INTRO N-PARAM METH     M24         NA\n   PSTAT 109 STATISTICS FOR ECON     M24         NA\n   PSTAT 115 BAYES DATA ANALYSIS     M24         25\n  PSTAT 120A   PROB & STATISTICS     M24         75\n  PSTAT 120B   PROB & STATISTICS     M24        136\n  PSTAT 120C   PROB & STATISTICS     M24        129\n   PSTAT 122 DESIGN OF EXPERMNTS     M24         NA\n   PSTAT 123  SAMPLING TECHNIQUE     M24         NA\n   PSTAT 126 REGRESSION ANALYSIS     M24         94\n   PSTAT 127    ADV STATS MODELS     M24         NA\n   PSTAT 130    SAS BASE PROGRAM     M24        108\n   PSTAT 131  STAT MACHINE LEARN     M24         80\n   PSTAT 132 DATABASES FOR STATS     M24         NA\n   PSTAT 134   STAT DATA SCIENCE     M24         NA\n   PSTAT 135  BIG DATA ANALYTICS     M24         NA\n   PSTAT 140 STATISTICAL PROCESS     M24         NA\n  PSTAT 160A  STOCHASTIC PROCESS     M24         NA\n  PSTAT 160B  STOCHASTIC PROCESS     M24         NA\n   PSTAT 170  INTRO MATH FINANCE     M24         19\n   PSTAT 171   MATH COMPOUND INT     M24         47\n  PSTAT 172A    ACTUARIAL STAT I     M24         NA\n  PSTAT 172B   ACTUARIAL STAT II     M24         NA\n   PSTAT 173         RISK THEORY     M24         NA\n   PSTAT 174         TIME SERIES     M24         NA\n   PSTAT 175   SURVIVAL ANALYSIS     M24         NA\n   PSTAT 176    ADV MATH FINANCE     M24         NA\n   PSTAT 177      FINANCIAL RISK     M24         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     M24         NA\n   PSTAT 183  ACTUARIAL CONCEPTS     M24         NA\n   PSTAT 190        ULA TRAINING     M24         NA\n   PSTAT 191       ULA PRACTICUM     M24         NA\n   PSTAT 193 INTERNSHIP IN STATS     M24         28\n   PSTAT 194  GRP STDY ADV STDNT     M24         11\n   PSTAT 195      SPECIAL TOPICS     M24         NA\n   PSTAT 196   RESEARCH IN ACTSC     M24         NA\n  PSTAT 197A    DS CAPSTONE PREP     M24         NA\n  PSTAT 197B DS CAPSTONE PROJECT     M24         NA\n  PSTAT 197C DS CAPSTONE PROJECT     M24         NA\n   PSTAT 199 INDEPENDENT STUDIES     M24          6\n PSTAT 199RA INDEP RESEARCH ASST     M24         NA\n    PSTAT 5A  UNDERSTANDING DATA     S24        258\n    PSTAT 5H          STATISTICS     S24         31\n   PSTAT 5LS  STAT LIFE SCIENCES     S24        304\n     PSTAT 8  TRANS DS PROB STAT     S24         83\n    PSTAT 10  DATA SCIENCE PRINC     S24        234\n    PSTAT 99 INDEPENDENT STUDIES     S24         NA\n   PSTAT 100        DS_CONC&ANLS     S24         95\n   PSTAT 105  INTRO N-PARAM METH     S24         NA\n   PSTAT 109 STATISTICS FOR ECON     S24         NA\n   PSTAT 115 BAYES DATA ANALYSIS     S24         74\n  PSTAT 120A   PROB & STATISTICS     S24        367\n  PSTAT 120B   PROB & STATISTICS     S24        382\n  PSTAT 120C   PROB & STATISTICS     S24        131\n   PSTAT 122 DESIGN OF EXPERMNTS     S24        177\n   PSTAT 123  SAMPLING TECHNIQUE     S24         NA\n   PSTAT 126 REGRESSION ANALYSIS     S24        147\n   PSTAT 127    ADV STATS MODELS     S24         NA\n   PSTAT 130    SAS BASE PROGRAM     S24        122\n   PSTAT 131  STAT MACHINE LEARN     S24         93\n   PSTAT 132 DATABASES FOR STATS     S24         NA\n   PSTAT 134   STAT DATA SCIENCE     S24         70\n   PSTAT 135  BIG DATA ANALYTICS     S24         NA\n   PSTAT 140 STATISTICAL PROCESS     S24         NA\n  PSTAT 160A  STOCHASTIC PROCESS     S24        100\n  PSTAT 160B  STOCHASTIC PROCESS     S24        106\n   PSTAT 170  INTRO MATH FINANCE     S24        125\n   PSTAT 171   MATH COMPOUND INT     S24         84\n  PSTAT 172A    ACTUARIAL STAT I     S24         NA\n  PSTAT 172B   ACTUARIAL STAT II     S24         20\n   PSTAT 173         RISK THEORY     S24         NA\n   PSTAT 174         TIME SERIES     S24        104\n   PSTAT 175   SURVIVAL ANALYSIS     S24         55\n   PSTAT 176    ADV MATH FINANCE     S24         15\n   PSTAT 177      FINANCIAL RISK     S24         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     S24         17\n   PSTAT 183  ACTUARIAL CONCEPTS     S24         44\n   PSTAT 190        ULA TRAINING     S24         NA\n   PSTAT 191       ULA PRACTICUM     S24         NA\n   PSTAT 193 INTERNSHIP IN STATS     S24          6\n   PSTAT 194  GRP STDY ADV STDNT     S24         29\n   PSTAT 195      SPECIAL TOPICS     S24         NA\n   PSTAT 196   RESEARCH IN ACTSC     S24         NA\n  PSTAT 197A    DS CAPSTONE PREP     S24         NA\n  PSTAT 197B DS CAPSTONE PROJECT     S24         NA\n  PSTAT 197C DS CAPSTONE PROJECT     S24         53\n   PSTAT 199 INDEPENDENT STUDIES     S24         19\n PSTAT 199RA INDEP RESEARCH ASST     S24         NA\n    PSTAT 5A  UNDERSTANDING DATA     W24        283\n    PSTAT 5H          STATISTICS     W24         24\n   PSTAT 5LS  STAT LIFE SCIENCES     W24        299\n     PSTAT 8  TRANS DS PROB STAT     W24        134\n    PSTAT 10  DATA SCIENCE PRINC     W24        260\n    PSTAT 99 INDEPENDENT STUDIES     W24         NA\n   PSTAT 100        DS_CONC&ANLS     W24         NA\n   PSTAT 105  INTRO N-PARAM METH     W24         NA\n   PSTAT 109 STATISTICS FOR ECON     W24         NA\n   PSTAT 115 BAYES DATA ANALYSIS     W24         96\n  PSTAT 120A   PROB & STATISTICS     W24        372\n  PSTAT 120B   PROB & STATISTICS     W24        241\n  PSTAT 120C   PROB & STATISTICS     W24         39\n   PSTAT 122 DESIGN OF EXPERMNTS     W24        162\n   PSTAT 123  SAMPLING TECHNIQUE     W24        137\n   PSTAT 126 REGRESSION ANALYSIS     W24        200\n   PSTAT 127    ADV STATS MODELS     W24         NA\n   PSTAT 130    SAS BASE PROGRAM     W24         97\n   PSTAT 131  STAT MACHINE LEARN     W24        138\n   PSTAT 132 DATABASES FOR STATS     W24         NA\n   PSTAT 134   STAT DATA SCIENCE     W24         78\n   PSTAT 135  BIG DATA ANALYTICS     W24         99\n   PSTAT 140 STATISTICAL PROCESS     W24         NA\n  PSTAT 160A  STOCHASTIC PROCESS     W24        153\n  PSTAT 160B  STOCHASTIC PROCESS     W24         73\n   PSTAT 170  INTRO MATH FINANCE     W24         65\n   PSTAT 171   MATH COMPOUND INT     W24         68\n  PSTAT 172A    ACTUARIAL STAT I     W24         60\n  PSTAT 172B   ACTUARIAL STAT II     W24         NA\n   PSTAT 173         RISK THEORY     W24         NA\n   PSTAT 174         TIME SERIES     W24         63\n   PSTAT 175   SURVIVAL ANALYSIS     W24         NA\n   PSTAT 176    ADV MATH FINANCE     W24         NA\n   PSTAT 177      FINANCIAL RISK     W24         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     W24          6\n   PSTAT 183  ACTUARIAL CONCEPTS     W24         NA\n   PSTAT 190        ULA TRAINING     W24         NA\n   PSTAT 191       ULA PRACTICUM     W24         NA\n   PSTAT 193 INTERNSHIP IN STATS     W24          4\n   PSTAT 194  GRP STDY ADV STDNT     W24         NA\n   PSTAT 195      SPECIAL TOPICS     W24         NA\n   PSTAT 196   RESEARCH IN ACTSC     W24         NA\n  PSTAT 197A    DS CAPSTONE PREP     W24         NA\n  PSTAT 197B DS CAPSTONE PROJECT     W24         56\n  PSTAT 197C DS CAPSTONE PROJECT     W24         NA\n   PSTAT 199 INDEPENDENT STUDIES     W24         17\n PSTAT 199RA INDEP RESEARCH ASST     W24         NA\n    PSTAT 5A  UNDERSTANDING DATA     F23        549\n    PSTAT 5H          STATISTICS     F23         25\n   PSTAT 5LS  STAT LIFE SCIENCES     F23         NA\n     PSTAT 8  TRANS DS PROB STAT     F23        132\n    PSTAT 10  DATA SCIENCE PRINC     F23        285\n    PSTAT 99 INDEPENDENT STUDIES     F23         NA\n   PSTAT 100        DS_CONC&ANLS     F23        104\n   PSTAT 105  INTRO N-PARAM METH     F23         39\n   PSTAT 109 STATISTICS FOR ECON     F23         NA\n   PSTAT 115 BAYES DATA ANALYSIS     F23         16\n  PSTAT 120A   PROB & STATISTICS     F23        419\n  PSTAT 120B   PROB & STATISTICS     F23        261\n  PSTAT 120C   PROB & STATISTICS     F23         19\n   PSTAT 122 DESIGN OF EXPERMNTS     F23        167\n   PSTAT 123  SAMPLING TECHNIQUE     F23         NA\n   PSTAT 126 REGRESSION ANALYSIS     F23        123\n   PSTAT 127    ADV STATS MODELS     F23         57\n   PSTAT 130    SAS BASE PROGRAM     F23        120\n   PSTAT 131  STAT MACHINE LEARN     F23        150\n   PSTAT 132 DATABASES FOR STATS     F23         NA\n   PSTAT 134   STAT DATA SCIENCE     F23         80\n   PSTAT 135  BIG DATA ANALYTICS     F23         NA\n   PSTAT 140 STATISTICAL PROCESS     F23         NA\n  PSTAT 160A  STOCHASTIC PROCESS     F23        132\n  PSTAT 160B  STOCHASTIC PROCESS     F23         43\n   PSTAT 170  INTRO MATH FINANCE     F23         59\n   PSTAT 171   MATH COMPOUND INT     F23        102\n  PSTAT 172A    ACTUARIAL STAT I     F23         NA\n  PSTAT 172B   ACTUARIAL STAT II     F23         NA\n   PSTAT 173         RISK THEORY     F23         35\n   PSTAT 174         TIME SERIES     F23         NA\n   PSTAT 175   SURVIVAL ANALYSIS     F23         18\n   PSTAT 176    ADV MATH FINANCE     F23         NA\n   PSTAT 177      FINANCIAL RISK     F23         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     F23          4\n   PSTAT 183  ACTUARIAL CONCEPTS     F23         NA\n   PSTAT 190        ULA TRAINING     F23          5\n   PSTAT 191       ULA PRACTICUM     F23         NA\n   PSTAT 193 INTERNSHIP IN STATS     F23          8\n   PSTAT 194  GRP STDY ADV STDNT     F23         NA\n   PSTAT 195      SPECIAL TOPICS     F23         NA\n   PSTAT 196   RESEARCH IN ACTSC     F23         NA\n  PSTAT 197A    DS CAPSTONE PREP     F23         58\n  PSTAT 197B DS CAPSTONE PROJECT     F23         NA\n  PSTAT 197C DS CAPSTONE PROJECT     F23         NA\n   PSTAT 199 INDEPENDENT STUDIES     F23         23\n PSTAT 199RA INDEP RESEARCH ASST     F23         NA\n    PSTAT 5A  UNDERSTANDING DATA     M23        110\n    PSTAT 5H          STATISTICS     M23         NA\n   PSTAT 5LS  STAT LIFE SCIENCES     M23         39\n     PSTAT 8  TRANS DS PROB STAT     M23         18\n    PSTAT 10  DATA SCIENCE PRINC     M23         83\n    PSTAT 99 INDEPENDENT STUDIES     M23         NA\n   PSTAT 100        DS_CONC&ANLS     M23         48\n   PSTAT 105  INTRO N-PARAM METH     M23         NA\n   PSTAT 109 STATISTICS FOR ECON     M23         NA\n   PSTAT 115 BAYES DATA ANALYSIS     M23         15\n  PSTAT 120A   PROB & STATISTICS     M23         86\n  PSTAT 120B   PROB & STATISTICS     M23        102\n  PSTAT 120C   PROB & STATISTICS     M23         81\n   PSTAT 122 DESIGN OF EXPERMNTS     M23         NA\n   PSTAT 123  SAMPLING TECHNIQUE     M23         NA\n   PSTAT 126 REGRESSION ANALYSIS     M23         84\n   PSTAT 127    ADV STATS MODELS     M23         NA\n   PSTAT 130    SAS BASE PROGRAM     M23         95\n   PSTAT 131  STAT MACHINE LEARN     M23         55\n   PSTAT 132 DATABASES FOR STATS     M23         NA\n   PSTAT 134   STAT DATA SCIENCE     M23         NA\n   PSTAT 135  BIG DATA ANALYTICS     M23         NA\n   PSTAT 140 STATISTICAL PROCESS     M23         NA\n  PSTAT 160A  STOCHASTIC PROCESS     M23         NA\n  PSTAT 160B  STOCHASTIC PROCESS     M23          7\n   PSTAT 170  INTRO MATH FINANCE     M23         17\n   PSTAT 171   MATH COMPOUND INT     M23         32\n  PSTAT 172A    ACTUARIAL STAT I     M23         NA\n  PSTAT 172B   ACTUARIAL STAT II     M23         NA\n   PSTAT 173         RISK THEORY     M23         NA\n   PSTAT 174         TIME SERIES     M23         NA\n   PSTAT 175   SURVIVAL ANALYSIS     M23         NA\n   PSTAT 176    ADV MATH FINANCE     M23         NA\n   PSTAT 177      FINANCIAL RISK     M23         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     M23         NA\n   PSTAT 183  ACTUARIAL CONCEPTS     M23         NA\n   PSTAT 190        ULA TRAINING     M23         NA\n   PSTAT 191       ULA PRACTICUM     M23         NA\n   PSTAT 193 INTERNSHIP IN STATS     M23         20\n   PSTAT 194  GRP STDY ADV STDNT     M23         NA\n   PSTAT 195      SPECIAL TOPICS     M23         NA\n   PSTAT 196   RESEARCH IN ACTSC     M23         NA\n  PSTAT 197A    DS CAPSTONE PREP     M23         NA\n  PSTAT 197B DS CAPSTONE PROJECT     M23         NA\n  PSTAT 197C DS CAPSTONE PROJECT     M23         NA\n   PSTAT 199 INDEPENDENT STUDIES     M23          6\n PSTAT 199RA INDEP RESEARCH ASST     M23         NA\n    PSTAT 5A  UNDERSTANDING DATA     S23        212\n    PSTAT 5H          STATISTICS     S23         31\n   PSTAT 5LS  STAT LIFE SCIENCES     S23        299\n     PSTAT 8  TRANS DS PROB STAT     S23         86\n    PSTAT 10  DATA SCIENCE PRINC     S23        240\n    PSTAT 99 INDEPENDENT STUDIES     S23         NA\n   PSTAT 100        DS_CONC&ANLS     S23        125\n   PSTAT 105  INTRO N-PARAM METH     S23         NA\n   PSTAT 109 STATISTICS FOR ECON     S23         NA\n   PSTAT 115 BAYES DATA ANALYSIS     S23         38\n  PSTAT 120A   PROB & STATISTICS     S23        237\n  PSTAT 120B   PROB & STATISTICS     S23        256\n  PSTAT 120C   PROB & STATISTICS     S23         65\n   PSTAT 122 DESIGN OF EXPERMNTS     S23        194\n   PSTAT 123  SAMPLING TECHNIQUE     S23         NA\n   PSTAT 126 REGRESSION ANALYSIS     S23        149\n   PSTAT 127    ADV STATS MODELS     S23         NA\n   PSTAT 130    SAS BASE PROGRAM     S23        119\n   PSTAT 131  STAT MACHINE LEARN     S23        108\n   PSTAT 132 DATABASES FOR STATS     S23         NA\n   PSTAT 134   STAT DATA SCIENCE     S23         87\n   PSTAT 135  BIG DATA ANALYTICS     S23         NA\n   PSTAT 140 STATISTICAL PROCESS     S23         NA\n  PSTAT 160A  STOCHASTIC PROCESS     S23        108\n  PSTAT 160B  STOCHASTIC PROCESS     S23         82\n   PSTAT 170  INTRO MATH FINANCE     S23         77\n   PSTAT 171   MATH COMPOUND INT     S23         64\n  PSTAT 172A    ACTUARIAL STAT I     S23         NA\n  PSTAT 172B   ACTUARIAL STAT II     S23         23\n   PSTAT 173         RISK THEORY     S23         NA\n   PSTAT 174         TIME SERIES     S23        170\n   PSTAT 175   SURVIVAL ANALYSIS     S23         NA\n   PSTAT 176    ADV MATH FINANCE     S23         13\n   PSTAT 177      FINANCIAL RISK     S23         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     S23          6\n   PSTAT 183  ACTUARIAL CONCEPTS     S23         46\n   PSTAT 190        ULA TRAINING     S23         NA\n   PSTAT 191       ULA PRACTICUM     S23         NA\n   PSTAT 193 INTERNSHIP IN STATS     S23          6\n   PSTAT 194  GRP STDY ADV STDNT     S23         28\n   PSTAT 195      SPECIAL TOPICS     S23         NA\n   PSTAT 196   RESEARCH IN ACTSC     S23         NA\n  PSTAT 197A    DS CAPSTONE PREP     S23         NA\n  PSTAT 197B DS CAPSTONE PROJECT     S23         NA\n  PSTAT 197C DS CAPSTONE PROJECT     S23         46\n   PSTAT 199 INDEPENDENT STUDIES     S23         21\n PSTAT 199RA INDEP RESEARCH ASST     S23         NA\n    PSTAT 5A  UNDERSTANDING DATA     W23        279\n    PSTAT 5H          STATISTICS     W23         22\n   PSTAT 5LS  STAT LIFE SCIENCES     W23        294\n     PSTAT 8  TRANS DS PROB STAT     W23        156\n    PSTAT 10  DATA SCIENCE PRINC     W23        282\n    PSTAT 99 INDEPENDENT STUDIES     W23         NA\n   PSTAT 100        DS_CONC&ANLS     W23        127\n   PSTAT 105  INTRO N-PARAM METH     W23         NA\n   PSTAT 109 STATISTICS FOR ECON     W23         NA\n   PSTAT 115 BAYES DATA ANALYSIS     W23         70\n  PSTAT 120A   PROB & STATISTICS     W23        246\n  PSTAT 120B   PROB & STATISTICS     W23        256\n  PSTAT 120C   PROB & STATISTICS     W23         31\n   PSTAT 122 DESIGN OF EXPERMNTS     W23        187\n   PSTAT 123  SAMPLING TECHNIQUE     W23         NA\n   PSTAT 126 REGRESSION ANALYSIS     W23        175\n   PSTAT 127    ADV STATS MODELS     W23         73\n   PSTAT 130    SAS BASE PROGRAM     W23         98\n   PSTAT 131  STAT MACHINE LEARN     W23        197\n   PSTAT 132 DATABASES FOR STATS     W23         NA\n   PSTAT 134   STAT DATA SCIENCE     W23         42\n   PSTAT 135  BIG DATA ANALYTICS     W23         93\n   PSTAT 140 STATISTICAL PROCESS     W23         NA\n  PSTAT 160A  STOCHASTIC PROCESS     W23        161\n  PSTAT 160B  STOCHASTIC PROCESS     W23         81\n   PSTAT 170  INTRO MATH FINANCE     W23         57\n   PSTAT 171   MATH COMPOUND INT     W23         69\n  PSTAT 172A    ACTUARIAL STAT I     W23         43\n  PSTAT 172B   ACTUARIAL STAT II     W23         NA\n   PSTAT 173         RISK THEORY     W23         NA\n   PSTAT 174         TIME SERIES     W23        118\n   PSTAT 175   SURVIVAL ANALYSIS     W23         NA\n   PSTAT 176    ADV MATH FINANCE     W23         NA\n   PSTAT 177      FINANCIAL RISK     W23         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     W23          4\n   PSTAT 183  ACTUARIAL CONCEPTS     W23         NA\n   PSTAT 190        ULA TRAINING     W23         NA\n   PSTAT 191       ULA PRACTICUM     W23         NA\n   PSTAT 193 INTERNSHIP IN STATS     W23          3\n   PSTAT 194  GRP STDY ADV STDNT     W23         NA\n   PSTAT 195      SPECIAL TOPICS     W23         NA\n   PSTAT 196   RESEARCH IN ACTSC     W23         NA\n  PSTAT 197A    DS CAPSTONE PREP     W23         NA\n  PSTAT 197B DS CAPSTONE PROJECT     W23         53\n  PSTAT 197C DS CAPSTONE PROJECT     W23         NA\n   PSTAT 199 INDEPENDENT STUDIES     W23         17\n PSTAT 199RA INDEP RESEARCH ASST     W23         NA\n    PSTAT 5A  UNDERSTANDING DATA     F22        499\n    PSTAT 5H          STATISTICS     F22          4\n   PSTAT 5LS  STAT LIFE SCIENCES     F22         NA\n     PSTAT 8  TRANS DS PROB STAT     F22         70\n    PSTAT 10  DATA SCIENCE PRINC     F22        257\n    PSTAT 99 INDEPENDENT STUDIES     F22         NA\n   PSTAT 100        DS_CONC&ANLS     F22         NA\n   PSTAT 105  INTRO N-PARAM METH     F22         79\n   PSTAT 109 STATISTICS FOR ECON     F22         NA\n   PSTAT 115 BAYES DATA ANALYSIS     F22         63\n  PSTAT 120A   PROB & STATISTICS     F22        419\n  PSTAT 120B   PROB & STATISTICS     F22        165\n  PSTAT 120C   PROB & STATISTICS     F22         87\n   PSTAT 122 DESIGN OF EXPERMNTS     F22        182\n   PSTAT 123  SAMPLING TECHNIQUE     F22         NA\n   PSTAT 126 REGRESSION ANALYSIS     F22        182\n   PSTAT 127    ADV STATS MODELS     F22         NA\n   PSTAT 130    SAS BASE PROGRAM     F22         97\n   PSTAT 131  STAT MACHINE LEARN     F22        178\n   PSTAT 132 DATABASES FOR STATS     F22         NA\n   PSTAT 134   STAT DATA SCIENCE     F22         33\n   PSTAT 135  BIG DATA ANALYTICS     F22         NA\n   PSTAT 140 STATISTICAL PROCESS     F22         NA\n  PSTAT 160A  STOCHASTIC PROCESS     F22        184\n  PSTAT 160B  STOCHASTIC PROCESS     F22         58\n   PSTAT 170  INTRO MATH FINANCE     F22         55\n   PSTAT 171   MATH COMPOUND INT     F22        108\n  PSTAT 172A    ACTUARIAL STAT I     F22         NA\n  PSTAT 172B   ACTUARIAL STAT II     F22         NA\n   PSTAT 173         RISK THEORY     F22         43\n   PSTAT 174         TIME SERIES     F22         69\n   PSTAT 175   SURVIVAL ANALYSIS     F22         73\n   PSTAT 176    ADV MATH FINANCE     F22         NA\n   PSTAT 177      FINANCIAL RISK     F22         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     F22          7\n   PSTAT 183  ACTUARIAL CONCEPTS     F22         NA\n   PSTAT 190        ULA TRAINING     F22         20\n   PSTAT 191       ULA PRACTICUM     F22         NA\n   PSTAT 193 INTERNSHIP IN STATS     F22          2\n   PSTAT 194  GRP STDY ADV STDNT     F22         NA\n   PSTAT 195      SPECIAL TOPICS     F22         NA\n   PSTAT 196   RESEARCH IN ACTSC     F22         NA\n  PSTAT 197A    DS CAPSTONE PREP     F22         59\n  PSTAT 197B DS CAPSTONE PROJECT     F22         NA\n  PSTAT 197C DS CAPSTONE PROJECT     F22         NA\n   PSTAT 199 INDEPENDENT STUDIES     F22         21\n PSTAT 199RA INDEP RESEARCH ASST     F22         NA\n    PSTAT 5A  UNDERSTANDING DATA     M22        116\n    PSTAT 5H          STATISTICS     M22         NA\n   PSTAT 5LS  STAT LIFE SCIENCES     M22         63\n     PSTAT 8  TRANS DS PROB STAT     M22         23\n    PSTAT 10  DATA SCIENCE PRINC     M22         87\n    PSTAT 99 INDEPENDENT STUDIES     M22         NA\n   PSTAT 100        DS_CONC&ANLS     M22         NA\n   PSTAT 105  INTRO N-PARAM METH     M22         NA\n   PSTAT 109 STATISTICS FOR ECON     M22         NA\n   PSTAT 115 BAYES DATA ANALYSIS     M22         NA\n  PSTAT 120A   PROB & STATISTICS     M22         65\n  PSTAT 120B   PROB & STATISTICS     M22        174\n  PSTAT 120C   PROB & STATISTICS     M22        109\n   PSTAT 122 DESIGN OF EXPERMNTS     M22         NA\n   PSTAT 123  SAMPLING TECHNIQUE     M22         NA\n   PSTAT 126 REGRESSION ANALYSIS     M22         67\n   PSTAT 127    ADV STATS MODELS     M22         NA\n   PSTAT 130    SAS BASE PROGRAM     M22        138\n   PSTAT 131  STAT MACHINE LEARN     M22         NA\n   PSTAT 132 DATABASES FOR STATS     M22         NA\n   PSTAT 134   STAT DATA SCIENCE     M22         22\n   PSTAT 135  BIG DATA ANALYTICS     M22         NA\n   PSTAT 140 STATISTICAL PROCESS     M22         NA\n  PSTAT 160A  STOCHASTIC PROCESS     M22         51\n  PSTAT 160B  STOCHASTIC PROCESS     M22         54\n   PSTAT 170  INTRO MATH FINANCE     M22         41\n   PSTAT 171   MATH COMPOUND INT     M22         49\n  PSTAT 172A    ACTUARIAL STAT I     M22         NA\n  PSTAT 172B   ACTUARIAL STAT II     M22         NA\n   PSTAT 173         RISK THEORY     M22         NA\n   PSTAT 174         TIME SERIES     M22         NA\n   PSTAT 175   SURVIVAL ANALYSIS     M22         NA\n   PSTAT 176    ADV MATH FINANCE     M22         NA\n   PSTAT 177      FINANCIAL RISK     M22         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     M22         NA\n   PSTAT 183  ACTUARIAL CONCEPTS     M22         NA\n   PSTAT 190        ULA TRAINING     M22         NA\n   PSTAT 191       ULA PRACTICUM     M22         NA\n   PSTAT 193 INTERNSHIP IN STATS     M22         35\n   PSTAT 194  GRP STDY ADV STDNT     M22         NA\n   PSTAT 195      SPECIAL TOPICS     M22         NA\n   PSTAT 196   RESEARCH IN ACTSC     M22         NA\n  PSTAT 197A    DS CAPSTONE PREP     M22         NA\n  PSTAT 197B DS CAPSTONE PROJECT     M22         NA\n  PSTAT 197C DS CAPSTONE PROJECT     M22         NA\n   PSTAT 199 INDEPENDENT STUDIES     M22         10\n PSTAT 199RA INDEP RESEARCH ASST     M22         NA\n    PSTAT 5A  UNDERSTANDING DATA     S22        194\n    PSTAT 5H          STATISTICS     S22         NA\n   PSTAT 5LS  STAT LIFE SCIENCES     S22        294\n     PSTAT 8  TRANS DS PROB STAT     S22         59\n    PSTAT 10  DATA SCIENCE PRINC     S22        278\n    PSTAT 99 INDEPENDENT STUDIES     S22         NA\n   PSTAT 100        DS_CONC&ANLS     S22         95\n   PSTAT 105  INTRO N-PARAM METH     S22         NA\n   PSTAT 109 STATISTICS FOR ECON     S22         NA\n   PSTAT 115 BAYES DATA ANALYSIS     S22         NA\n  PSTAT 120A   PROB & STATISTICS     S22        244\n  PSTAT 120B   PROB & STATISTICS     S22        216\n  PSTAT 120C   PROB & STATISTICS     S22        119\n   PSTAT 122 DESIGN OF EXPERMNTS     S22        137\n   PSTAT 123  SAMPLING TECHNIQUE     S22         NA\n   PSTAT 126 REGRESSION ANALYSIS     S22        250\n   PSTAT 127    ADV STATS MODELS     S22         78\n   PSTAT 130    SAS BASE PROGRAM     S22        122\n   PSTAT 131  STAT MACHINE LEARN     S22         75\n   PSTAT 132 DATABASES FOR STATS     S22         NA\n   PSTAT 134   STAT DATA SCIENCE     S22         NA\n   PSTAT 135  BIG DATA ANALYTICS     S22         NA\n   PSTAT 140 STATISTICAL PROCESS     S22         NA\n  PSTAT 160A  STOCHASTIC PROCESS     S22        130\n  PSTAT 160B  STOCHASTIC PROCESS     S22        109\n   PSTAT 170  INTRO MATH FINANCE     S22         74\n   PSTAT 171   MATH COMPOUND INT     S22         70\n  PSTAT 172A    ACTUARIAL STAT I     S22         NA\n  PSTAT 172B   ACTUARIAL STAT II     S22         26\n   PSTAT 173         RISK THEORY     S22         NA\n   PSTAT 174         TIME SERIES     S22         61\n   PSTAT 175   SURVIVAL ANALYSIS     S22         NA\n   PSTAT 176    ADV MATH FINANCE     S22         15\n   PSTAT 177      FINANCIAL RISK     S22         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     S22         12\n   PSTAT 183  ACTUARIAL CONCEPTS     S22         68\n   PSTAT 190        ULA TRAINING     S22         NA\n   PSTAT 191       ULA PRACTICUM     S22         NA\n   PSTAT 193 INTERNSHIP IN STATS     S22          5\n   PSTAT 194  GRP STDY ADV STDNT     S22         66\n   PSTAT 195      SPECIAL TOPICS     S22         NA\n   PSTAT 196   RESEARCH IN ACTSC     S22         NA\n  PSTAT 197A    DS CAPSTONE PREP     S22         NA\n  PSTAT 197B DS CAPSTONE PROJECT     S22         NA\n  PSTAT 197C DS CAPSTONE PROJECT     S22         47\n   PSTAT 199 INDEPENDENT STUDIES     S22         19\n PSTAT 199RA INDEP RESEARCH ASST     S22         NA\n    PSTAT 5A  UNDERSTANDING DATA     W22        278\n    PSTAT 5H          STATISTICS     W22         NA\n   PSTAT 5LS  STAT LIFE SCIENCES     W22        284\n     PSTAT 8  TRANS DS PROB STAT     W22         NA\n    PSTAT 10  DATA SCIENCE PRINC     W22        287\n    PSTAT 99 INDEPENDENT STUDIES     W22         NA\n   PSTAT 100        DS_CONC&ANLS     W22         88\n   PSTAT 105  INTRO N-PARAM METH     W22         93\n   PSTAT 109 STATISTICS FOR ECON     W22         NA\n   PSTAT 115 BAYES DATA ANALYSIS     W22         81\n  PSTAT 120A   PROB & STATISTICS     W22        229\n  PSTAT 120B   PROB & STATISTICS     W22        241\n  PSTAT 120C   PROB & STATISTICS     W22         NA\n   PSTAT 122 DESIGN OF EXPERMNTS     W22        119\n   PSTAT 123  SAMPLING TECHNIQUE     W22         NA\n   PSTAT 126 REGRESSION ANALYSIS     W22        123\n   PSTAT 127    ADV STATS MODELS     W22         91\n   PSTAT 130    SAS BASE PROGRAM     W22         98\n   PSTAT 131  STAT MACHINE LEARN     W22         76\n   PSTAT 132 DATABASES FOR STATS     W22         NA\n   PSTAT 134   STAT DATA SCIENCE     W22         66\n   PSTAT 135  BIG DATA ANALYTICS     W22         NA\n   PSTAT 140 STATISTICAL PROCESS     W22         NA\n  PSTAT 160A  STOCHASTIC PROCESS     W22         77\n  PSTAT 160B  STOCHASTIC PROCESS     W22         72\n   PSTAT 170  INTRO MATH FINANCE     W22         69\n   PSTAT 171   MATH COMPOUND INT     W22         68\n  PSTAT 172A    ACTUARIAL STAT I     W22         60\n  PSTAT 172B   ACTUARIAL STAT II     W22         NA\n   PSTAT 173         RISK THEORY     W22         50\n   PSTAT 174         TIME SERIES     W22         74\n   PSTAT 175   SURVIVAL ANALYSIS     W22         NA\n   PSTAT 176    ADV MATH FINANCE     W22         NA\n   PSTAT 177      FINANCIAL RISK     W22         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     W22          5\n   PSTAT 183  ACTUARIAL CONCEPTS     W22         NA\n   PSTAT 190        ULA TRAINING     W22         NA\n   PSTAT 191       ULA PRACTICUM     W22         NA\n   PSTAT 193 INTERNSHIP IN STATS     W22          4\n   PSTAT 194  GRP STDY ADV STDNT     W22         NA\n   PSTAT 195      SPECIAL TOPICS     W22         NA\n   PSTAT 196   RESEARCH IN ACTSC     W22         NA\n  PSTAT 197A    DS CAPSTONE PREP     W22         NA\n  PSTAT 197B DS CAPSTONE PROJECT     W22         46\n  PSTAT 197C DS CAPSTONE PROJECT     W22         NA\n   PSTAT 199 INDEPENDENT STUDIES     W22          5\n PSTAT 199RA INDEP RESEARCH ASST     W22         NA\n\n\n\n\n\nCould we have instead used Spring 2025 Enrollment, Winter 2025 Enrollment, etc. as our variables?\nWell, we could… again, more on that during tomorrow’s lecture. (Spoiler: it’s not really a good idea.)"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#another-dataset-4",
    "href": "Lectures/Lec01/Lec01.html#another-dataset-4",
    "title": "PSTAT 100: Lecture 01",
    "section": " Another Dataset",
    "text": "Another Dataset\nUndergraduate PSTAT Course Enrollments\n\n\n\n\n\n\nMoral of the Story\n\n\nIt is not always the case that the variables in a dataset are the same as the column names.\n\n\n\n\nThis starts to get into the structure of a dataset, so we’ll save a further discussion on this point for tomorrow’s lecture.\n\nFor now, I simply encourage you to think critically when trying to identify the variables in a particular dataset.\n\nThe good news is that, in many cases, the work is done for us: many datasets will come equipped with a data dictionary, which is a specification of all the variables in the dataset and a brief description of what they represent."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#variable-classification-1",
    "href": "Lectures/Lec01/Lec01.html#variable-classification-1",
    "title": "PSTAT 100: Lecture 01",
    "section": " Variable Classification",
    "text": "Variable Classification\nFirst Level\n\nNotice how in both of the datasets we explored today, there were a few different types of variables.\nFor example, some variables have values that are numbers (e.g. the age of a cat; the enrollment total of a course; etc.) whereas others have values that are words (e.g. the species of a cat; the title of a course; etc.)\nIndeed, at the highest level, variables are classified as either numerical or categorical.\n\nNumerical variables are those whose values are numbers; categorical variables are those whose values are categories."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#variable-classification-2",
    "href": "Lectures/Lec01/Lec01.html#variable-classification-2",
    "title": "PSTAT 100: Lecture 01",
    "section": "Variable Classification",
    "text": "Variable Classification\nFirst Level\n\n\n\n\n\n\nCaution\n\n\nIt is a mistake to conclude that a variable is numerical solely because its recorded values are numbers.\n\n\n\n\nFor example, months can be encoded as either January, February, etc. or as 1, 2, 3.\n\nJust because we’re using 1 to mean January doesn’t mean that a month variable is numerical - its possible values are still only categories, and hence it is a categorical variable.\n1 + 2 is 3, but January plus February is not March.\n\nThe better check is whether sums/differences of values have interpretive meaning- if so, the variable is numerical. Otherwise, the variable is categorical."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#your-turn",
    "href": "Lectures/Lec01/Lec01.html#your-turn",
    "title": "PSTAT 100: Lecture 01",
    "section": " Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nYour Turn!\n\n\nTurn to your neighbors, and come up with a few examples of numerical variables and a few examples of categorical variables.\n\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#variable-classification-3",
    "href": "Lectures/Lec01/Lec01.html#variable-classification-3",
    "title": "PSTAT 100: Lecture 01",
    "section": "Variable Classification",
    "text": "Variable Classification\nSecond Level\n\nNot all numerical variables are alike.\nFor example, consider the following two: “number of accidents recorded along a highway”, and “height of an individual.”\nBoth variables are numerical (sums/differences have interpretive meaning).\nHowever, most of us have an intuitive feeling that the set of all possible values associated with “number of accidents recorded along a highway” is more restrictive than the set of possible values associated with “height of an individual.”"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#variable-classification-4",
    "href": "Lectures/Lec01/Lec01.html#variable-classification-4",
    "title": "PSTAT 100: Lecture 01",
    "section": "Variable Classification",
    "text": "Variable Classification\nSecond Level\n\n\n\n\n\n\nDefinition\n\n\nA numerical variable whose set of possible values is finite or countable is said to be discrete; a numerical variable whose set of possible values is uncountable is said to be continuous.\n\n\n\n\nNote how this mirrors the definition of discrete and continuous random variables that you (hopefully) saw in PSTAT 120A!\nEven within categorical variables, there’s a second level of classification. Consider: “letter grade” and “favorite color.”\nA grade of A+ is better than a grade of A, which is better than a grade of A-, etc. whereas green is not inherently better than red, which is not inherently better than purple, etc."
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#variable-classification-5",
    "href": "Lectures/Lec01/Lec01.html#variable-classification-5",
    "title": "PSTAT 100: Lecture 01",
    "section": "Variable Classification",
    "text": "Variable Classification\nSecond Level\n\n\n\n\n\n\nDefinition\n\n\nA categorical variable whose set of possible values has an intrinsic order is said to be ordinal; a categorical variable whose set of possible values has no intrinsic order is said to be nominal.\n\n\n\n\n\n\n\n\n\n\n\ndata_classification\n\n\ncluster_main\n\n\n\ncluster_0\n\n\n\ncluster_1\n\n\n\ncluster_2\n\n\n\ncluster_3\n\n\n\n\nData\n\nVariable\n\n\n\nnumerical\n\nNumerical\n\n\n\nData-&gt;numerical\n\n\n\n\n\ncategorical\n\nCategorical\n\n\n\nData-&gt;categorical\n\n\n\n\n\ncontinuous\n\nContinuous\n\n\n\nnumerical-&gt;continuous\n\n\n\n\n\ndiscrete\n\nDiscrete\n\n\n\nnumerical-&gt;discrete\n\n\n\n\n\nnominal\n\nNominal\n\n\n\ncategorical-&gt;nominal\n\n\n\n\n\nordinal\n\nOrdinal\n\n\n\ncategorical-&gt;ordinal"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#your-turn-2",
    "href": "Lectures/Lec01/Lec01.html#your-turn-2",
    "title": "PSTAT 100: Lecture 01",
    "section": " Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nYour Turn!\n\n\nFor the variables you and your neighbor(s) came up with in the previous activity, classify them as discrete, continuous, ordinal, or nominal.\n\n\n\n\n\n\n−+\n04:00"
  },
  {
    "objectID": "Lectures/Lec01/Lec01.html#next-time",
    "href": "Lectures/Lec01/Lec01.html#next-time",
    "title": "PSTAT 100: Lecture 01",
    "section": " Next Time",
    "text": "Next Time\n\nWe’ll continue our discussion on data.\n\nSpecifically, we’ll take a closer look at the structure (as opposed to semantics) of a dataset\nWe’ll then discuss a framework to unify the semantics and structure of a dataset.\n\nReminder: please start Homework 1 early!\n\nProblem 1 is a Linear Algebra review, and Problem 2 combines Linear Algebra and PSTAT 120A (so you should be able to complete both problems already).\nFor problem 3, you’ll need to wait until Thursday’s lecture.\n\nIf you are able, please bring your laptops to tomorrow’s lecture."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "PSTAT 100: Summer 2025",
    "section": "",
    "text": "PSTAT 100 - Data Science: Concepts and Analysis\n\n\n\n\nInstructor:\nEthan P. Marzban (He/Him)\n\n\n\n\nQuarter:\nSummer Session A, 2025\n\n\n\nCourse Description: Overview of data science key concepts and the use of tools for data retrieval, analysis, visualization, and reproducible research. Topics include an introduction to inference and prediction, principles of measurement, missing data, and notions of causality, statistical “traps”, and concepts in data ethics and privacy. Case studies will illustrate the importance of domain knowledge. Credit units: 4.\n\n\n\n\n\n\n\n\nWelcome to PSTAT 100! This is the official course page for the Summer Session A, 2025 iteration of the course - the Spring 2024 iteration has been moved to ucsb-pstat100-archives.github.io.\nLecture slides can be found on the Schedule; labs and project datasets can be found on our Course Computing Server, a link to which can be found on our course Canvas page. Please note, for security purposes, we can only share the link to the server with students who are currently enrolled in the course.\n\n\n\n\n\n\n\n\n    \n        \n            Important Course Assessments/Deadlines\n            \n                \n                    Homework 1\n                    Week 1 | Sunday, June 29, 2025\n                \n                \n                    In-Class Assessment 1\n                    Week 2 | Thursday, July 3, 2025\n                \n                \n                    Mid-Quarter Project\n                    Week 3 | Sunday, July 13, 2025\n                \n                \n                    Homework 2\n                    Week 4 | Sunday, July 20, 2025\n                \n                \n                    In-Class Assessment 2\n                    Week 5 | Thursday, July 24, 2025\n                \n                \n                    Final Project\n                    Week 6 | Friday, August 8, 2025\n                \n            \n        \n    \n\n\n\n\n\n\n\nImportant\n\n\n\nIn addition to the above deadlines, there will be two labs every week which you will be asked to turn in. These labs are designed to be completed during our scheduled Discussion Section periods."
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#recap",
    "href": "Lectures/Lec06/Lec06.html#recap",
    "title": "PSTAT 100: Lecture 06",
    "section": " Recap",
    "text": "Recap\nDimension Reduction\n\nData may be high dimensional in the sense of containing many variables.\nIt is possible, though, to reduce the dimensionality of a dataset while not losing too much information.\nMore formally, we considered the idea of projecting our data matrix into a smaller-dimensional subspace so as to preserve as much variance as possible.\n\nThis approach is the background of Principal Components Analysis\n\nGiven a mean-centered data matrix \\(\\mat{X}\\), we saw that the unit vector \\(\\vect{v}\\) such that the projected data \\(\\mat{X} \\vect{v}\\) has maximal variance is the eigenvector of \\((\\tmat{X} \\mat{X})\\) with the largest associated eigenvalue."
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#pca",
    "href": "Lectures/Lec06/Lec06.html#pca",
    "title": "PSTAT 100: Lecture 06",
    "section": " PCA",
    "text": "PCA\nDimension Reduction\n\nFor example, suppose we have a 6-dimensional data matrix \\(\\mat{X}\\) (i.e. a matrix with 6 columns), assumed to be mean-centered.\nA two-dimensional representation of \\(\\mat{X}\\) would be found by:\n\nFinding the eigenvectors \\(\\vect{v}_1\\) and \\(\\vect{v}_2\\) of \\((\\tmat{X} \\mat{X})\\) that have the two largest eigenvalues\nProjecting \\(\\mat{X}\\) into the subspace spanned by \\(\\vect{v}_1\\) and \\(\\vect{v}_2\\); i.e. by performing the multiplication \\[ \\mat{X} \\begin{bmatrix} | & | \\\\ \\vect{v}_1 & \\vect{v}_2 \\\\ | & | \\\\ \\end{bmatrix} \\]"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#pca-1",
    "href": "Lectures/Lec06/Lec06.html#pca-1",
    "title": "PSTAT 100: Lecture 06",
    "section": " PCA",
    "text": "PCA\nDimension Reduction"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#pca-2",
    "href": "Lectures/Lec06/Lec06.html#pca-2",
    "title": "PSTAT 100: Lecture 06",
    "section": " PCA",
    "text": "PCA\nTerminology\n\nAdmittedly, the terminology surrounding PCA is a bit varied.\nHere is the terminology we’ll adopt for this class:\n\nThe principal components (PCs) are the directions along which the projected data has maximal variance.\nThe elements of the PCs will be called principal component loadings (or just ‘loadings’).\nThe data projected along the PCs will be called scores.\n\nThus, the scores are linear combinations of the original columns of the data matrix, with coefficients determined by the PC loadings.\n\n\nAgain, some people use the term “Principal Component” to mean other things - we’re adopting the above terminology for this class."
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#pca-3",
    "href": "Lectures/Lec06/Lec06.html#pca-3",
    "title": "PSTAT 100: Lecture 06",
    "section": " PCA",
    "text": "PCA\nTerminology\n\n\nNote that the scores are not just variables from the original data matrix; they are essentially linear combinations of several variables from the dataset.\n\nThey can be thought of as the linear combinations of variables that provide the most information"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#warning",
    "href": "Lectures/Lec06/Lec06.html#warning",
    "title": "PSTAT 100: Lecture 06",
    "section": " Warning",
    "text": "Warning\nMean-Centering Data\n\nOver the next few slides, we’re going to establish some linear algebra results that connect various properties of matrices.\nA question we will often have to contend with is: is our data mean-centered or not?\nI’ll do my best to be explicit about whether or not we are assuming mean-centered data or not.\nAs a general rule-of-thumb: most of the linear algebra results we will derive hold for any arbitrary data matrix, mean-centered or not.\n\nHowever, the minute we start interpreting these linear algebra quantities (e.g. eigenvectors) in terms of PCA, we’ll need to assume mean-centered data."
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#matrix-spectra",
    "href": "Lectures/Lec06/Lec06.html#matrix-spectra",
    "title": "PSTAT 100: Lecture 06",
    "section": " Matrix Spectra",
    "text": "Matrix Spectra\n\nLet’s start by assuming an arbitrary (not necessarily mean-centered) data matrix \\(\\mat{X}\\). How can we go about finding the eigenvalues and eigenvectors of \\((\\tmat{X} \\mat{X})\\)?\nRecall (from Math 4A and Homework 1) that there are two main ways to decompose a matrix: eigendecomposition (EVD) and singular value decomposition (SVD).\nAlso recall that the SVD can be thought of as a “generalization” of the EVD.\n\nSpecifically, only diagonalizable (and, consequently, square) matrices admit an EVD, whereas any matrix admits an SVD."
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#matrix-spectra-1",
    "href": "Lectures/Lec06/Lec06.html#matrix-spectra-1",
    "title": "PSTAT 100: Lecture 06",
    "section": " Matrix Spectra",
    "text": "Matrix Spectra\nSVD"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#matrix-spectra-2",
    "href": "Lectures/Lec06/Lec06.html#matrix-spectra-2",
    "title": "PSTAT 100: Lecture 06",
    "section": " Matrix Spectra",
    "text": "Matrix Spectra\nSVD\n\nsvd( x, nu = min(n, p), nv = min(n, p) )\n\n\nExample CodeExample Math\n\n\n\nsvd(matrix(c(1, 2, 3, 0, 1, 1, 2, 1, 2), nrow = 3, byrow = T))\n\n$d\n[1] 4.8348990 1.2637105 0.1636685\n\n$u\n           [,1]       [,2]       [,3]\n[1,] -0.7659032 -0.4194393 -0.4873018\n[2,] -0.2615772 -0.4890773  0.8320942\n[3,] -0.5873412  0.7647706  0.2648701\n\n$v\n           [,1]       [,2]       [,3]\n[1,] -0.4013705  0.8784465  0.2592944\n[2,] -0.4924042 -0.4456599  0.7476131\n[3,] -0.7722952 -0.1723921 -0.6114255\n\n\n\n\n\n\\[\n\\begin{align*}\n\\begin{pmatrix} 1 & 2 & 3 \\\\ 0 & 1 & 1 \\\\ 2 & 1 & 2 \\\\ \\end{pmatrix} & = \\left(\\begin{array}{rrr} -0.766 & -0.419 & -0.487 \\\\ -0.262 & -0.489  & 0.832 \\\\ -0.587 & 0.765 & 0.265  \\\\ \\end{array} \\right) \\begin{pmatrix} 4.835 & 0 & 0 \\\\ 0 & 1.264 & 0 \\\\ 0 & 0 & 0.164 \\end{pmatrix} \\left( \\begin{array}{rrr} -0.401 & -0.492 & -0.772 \\\\ 0.878 & -0.446 & -0.172 \\\\ 0.259 & 0.748 & -0.611 \\end{array} \\right) \\\\[3mm]\n\\mat{X} \\hspace{12mm} & = \\hspace{35mm} \\mat{U} \\hspace{68mm}  \\mat{\\Sigma} \\hspace{69mm} \\tmat{V} \\\\\n\\end{align*}\n\\]"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#matrix-spectra-3",
    "href": "Lectures/Lec06/Lec06.html#matrix-spectra-3",
    "title": "PSTAT 100: Lecture 06",
    "section": " Matrix Spectra",
    "text": "Matrix Spectra\nSVD vs. EVD\n\nNote: \\[\\begin{align*}\n  \\tmat{X} \\mat{X} & = (\\mat{U} \\mat{\\Sigma} \\tmat{V})^{\\mathsf{T}} (\\mat{U} \\mat{\\Sigma} \\tmat{V}) \\\\\n& = \\mat{V} \\tmat{\\Sigma} \\tmat{U} \\mat{U} \\mat{\\Sigma} \\tmat{V}  \\\\\n& = \\mat{V} \\tmat{\\Sigma} \\mat{\\Sigma} \\tmat{V}   \\\\\n& = \\mat{V} \\mat{\\Sigma}^2 \\tmat{V} \\\\\n\\implies (\\tmat{X}\\mat{X}) \\mat{V} & = \\mat{V} \\mat{\\Sigma}^2 \\tmat{V} \\mat{V} \\\\\n& = \\mat{V} \\mat{\\Sigma}^2\n\\end{align*}\\]"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#matrix-spectra-4",
    "href": "Lectures/Lec06/Lec06.html#matrix-spectra-4",
    "title": "PSTAT 100: Lecture 06",
    "section": " Matrix Spectra",
    "text": "Matrix Spectra\nEVD vs. SVD\n\n\n\n\n\n\nMoral\n\n\nIf the SVD of \\(\\mat{X}\\) is given by \\(\\mat{X} = \\mat{U} \\mat{\\Sigma} \\tmat{V}\\), then \\(\\mat{\\Sigma}^2\\) is the matrix of eigenvalues of \\((\\tmat{X} \\mat{X})\\) and \\(\\mat{V}\\) is the matrix of eigenvectors of \\((\\tmat{X} \\mat{X})\\).\n\n\n\n\nXSVDEVDprcomp()\n\n\n\nX &lt;- matrix(c(1, 2, 3,\n              0, 1, 1,\n              2, 1, 2),\n            nrow = 3,\n            byrow = T)\n\n\n\n\nsvd(X)$v\n\n           [,1]       [,2]       [,3]\n[1,] -0.4013705  0.8784465  0.2592944\n[2,] -0.4924042 -0.4456599  0.7476131\n[3,] -0.7722952 -0.1723921 -0.6114255\n\n\n\n\n\neigen(t(X) %*% X)$vectors\n\n           [,1]       [,2]       [,3]\n[1,] -0.4013705  0.8784465 -0.2592944\n[2,] -0.4924042 -0.4456599 -0.7476131\n[3,] -0.7722952 -0.1723921  0.6114255\n\n\n\n\n\nprcomp(X, center = F)\n\nStandard deviations (1, .., p=3):\n[1] 3.4187899 0.8935783 0.1157311\n\nRotation (n x k) = (3 x 3):\n            PC1        PC2        PC3\n[1,] -0.4013705  0.8784465  0.2592944\n[2,] -0.4924042 -0.4456599  0.7476131\n[3,] -0.7722952 -0.1723921 -0.6114255"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#pca-4",
    "href": "Lectures/Lec06/Lec06.html#pca-4",
    "title": "PSTAT 100: Lecture 06",
    "section": " PCA",
    "text": "PCA\n\nThe eigenvectors of the matrix \\((\\tmat{X} \\mat{X})\\) represent the directions of maximal variance (i.e. if we project \\(\\mat{X}\\) along these directions, we get maximum variance), provided \\(\\mat{X}\\) is mean-centered.\n\nSo, the vectors on the previous slides aren’t really interpretable as the PCs.\nBut, if our matrix were mean-centered, we see that the principal components can be computed through:\n\nthe direct eigendecomposition of \\(\\tmat{X} \\mat{X}\\),\nthe singular value decomposition of \\(\\mat{X}\\), or\nthe prcomp() function in R.\n\n\nAgain, even if \\(\\mat{X}\\) is not mean-centered, the above three methods will produce the same result. The only difference is that, under non-centered data, the result is not necessarily interpretable as the matrix of PCs."
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#pca-5",
    "href": "Lectures/Lec06/Lec06.html#pca-5",
    "title": "PSTAT 100: Lecture 06",
    "section": " PCA",
    "text": "PCA\n\nXSVDEVDprcomp()\n\n\n\nX &lt;- matrix(c(1, 2, 3,\n              0, 1, 1,\n              2, 1, 2),\n            nrow = 3,\n            byrow = T) %&gt;% scale()\n\n\n\n\nsvd(X)$v\n\n           [,1]          [,2]       [,3]\n[1,] -0.3535534  8.660254e-01  0.3535534\n[2,] -0.6123724 -5.000000e-01  0.6123724\n[3,] -0.7071068 -1.665335e-16 -0.7071068\n\n\n\n\n\neigen(t(X) %*% X)$vectors\n\n           [,1]          [,2]       [,3]\n[1,] -0.3535534  8.660254e-01  0.3535534\n[2,] -0.6123724 -5.000000e-01  0.6123724\n[3,] -0.7071068  7.771561e-16 -0.7071068\n\n\n\n\n\nprcomp(X)\n\nStandard deviations (1, .., p=3):\n[1] 1.414214e+00 1.000000e+00 6.640980e-17\n\nRotation (n x k) = (3 x 3):\n            PC1           PC2        PC3\n[1,] -0.3535534  8.660254e-01  0.3535534\n[2,] -0.6123724 -5.000000e-01  0.6123724\n[3,] -0.7071068 -1.665335e-16 -0.7071068"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#pca-a-quick-recap",
    "href": "Lectures/Lec06/Lec06.html#pca-a-quick-recap",
    "title": "PSTAT 100: Lecture 06",
    "section": " PCA: A Quick Recap",
    "text": "PCA: A Quick Recap\n\nMultiplying the original (n × p) data matrix \\(\\mat{X}\\) by a matrix constructed from the first d (for d ≤ n) principal components (each of dimension p) will result in an (n × d) matrix, the columns of which we call the scores.\n\nWe obtain the scores by either:\n\ncomputing \\(\\mat{X} \\mat{V}\\) and extracting the first few columns, or\ncomputing \\(\\mat{U} \\mat{\\Sigma}\\) and extracting the first few columns.\n\n\nMathematical justification: \\[ \\mat{X} = \\mat{U} \\mat{\\Sigma} \\tmat{V} \\ \\implies \\ \\mat{X} \\mat{V} = \\mat{U} \\mat{\\Sigma} \\tmat{V}  \\mat{V} = \\mat{U} \\mat{\\Sigma} \\]"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#pca-6",
    "href": "Lectures/Lec06/Lec06.html#pca-6",
    "title": "PSTAT 100: Lecture 06",
    "section": " PCA",
    "text": "PCA\nScores\n\nXUsing prcomp()Using U∑Using XV\n\n\n\nX &lt;- matrix(c(1, 2, 3,\n              0, 1, 1,\n              2, 1, 2),\n            nrow = 3,\n            byrow = T) %&gt;% scale()\n\n\n\n\nX %*% prcomp(X)[[2]]\n\n               PC1        PC2          PC3\n[1,] -1.414214e+00 -0.5773503 1.110223e-16\n[2,]  1.414214e+00 -0.5773503 1.110223e-16\n[3,] -1.439405e-16  1.1547005 2.433064e-17\n\n\n\n\n\nsvd(X)$u %*% diag(svd(X)$d)\n\n              [,1]       [,2]         [,3]\n[1,] -1.414214e+00 -0.5773503 1.080837e-16\n[2,]  1.414214e+00 -0.5773503 1.080837e-16\n[3,] -1.367162e-16  1.1547005 1.080837e-16\n\n\n\n\n\nX %*% svd(X)$v\n\n              [,1]       [,2]         [,3]\n[1,] -1.414214e+00 -0.5773503 1.110223e-16\n[2,]  1.414214e+00 -0.5773503 1.110223e-16\n[3,] -1.439405e-16  1.1547005 2.433064e-17\n\n\n\n\n\n\n\n\n\nqr(X)$rank\n\n[1] 2"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#matrix-spectra-5",
    "href": "Lectures/Lec06/Lec06.html#matrix-spectra-5",
    "title": "PSTAT 100: Lecture 06",
    "section": " Matrix Spectra",
    "text": "Matrix Spectra\nVariance\n\nYesterday we argued that the variance of the projected data along each PC (eigenvector) is proportional to the associated eigenvalue.\n\nIn other words, the variance of the scores can be recovered using either the EVD, SVD, or result of prcomp().\n\n\n\n\nUsing SVDUsing EVDUsing prcomp()Directly\n\n\n\nsvd(X)$d^2 / (ncol(X) - 1)\n\n[1] 2.000000e+00 1.000000e+00 1.752312e-32\n\n\n\n\n\nEVD_XTX &lt;- eigen(t(X) %*% X)\nEVD_XTX$values / (ncol(X) - 1)\n\n[1] 2.000000e+00 1.000000e+00 2.220446e-15\n\n\n\n\n\nprcomp(X)$sdev^2\n\n[1] 2.000000e+00 1.000000e+00 4.410261e-33\n\n\n\n\n\n(X %*% prcomp(X)$rotation) %&gt;% apply(MARGIN = 2, FUN = var)\n\n         PC1          PC2          PC3 \n2.000000e+00 1.000000e+00 2.505148e-33"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#pca-7",
    "href": "Lectures/Lec06/Lec06.html#pca-7",
    "title": "PSTAT 100: Lecture 06",
    "section": " PCA",
    "text": "PCA\nInverting PCA\n\n\nSo, this tells us how to go from, say, a \\((6 \\times 4)\\) matrix to a \\((6 \\times 2)\\) matrix. How do we go back to a \\((6 \\times 4)\\) matrix?"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#pca-8",
    "href": "Lectures/Lec06/Lec06.html#pca-8",
    "title": "PSTAT 100: Lecture 06",
    "section": " PCA",
    "text": "PCA\nInverting PCA\n\nNote:\n\n\n\\[\\begin{align*}\n  \\mat{X} \\mat{V} & := \\mat{Z}  \\\\\n  \\mat{X} \\mat{V} \\tmat{V}  & = \\mat{Z} \\tmat{V}  \\\\\n  \\mat{X} & = \\mat{Z} \\tmat{V}\n\\end{align*}\\]\n\n\nMotivated by this, let \\(\\mat{Z}\\) denote a low-rank projection of \\(\\mat{X}\\); i.e. \\(\\mat{Z} = \\mat{X} \\mat{V}_d\\) where \\(\\mat{V}_d\\) is the (p × d) matrix whose columns are the first d prinipcal components. A low-rank reconstruction of \\(\\mat{X}\\) is then \\[ \\mat{X}_d := \\mat{Z} \\tmat{V}_d = \\mat{X} \\mat{V}_d \\tmat{V}_d\\]"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#pca-9",
    "href": "Lectures/Lec06/Lec06.html#pca-9",
    "title": "PSTAT 100: Lecture 06",
    "section": " PCA",
    "text": "PCA\nInverting PCA\n\nPerhaps I should explain a bit further what I mean by a “reconstruction” of \\(\\mat{X}\\).\nBy properties of matrix multiplication, \\(\\mat{X}_d\\) will be of size (n × p), i.e. the same size as the original \\(\\mat{X}\\).\nHowever, since \\(\\mat{V}_d\\) is of rank d, \\(\\mat{X}_d\\) will be of rank d.\nSo, this is what I mean by a “low-rank reconstruction” of \\(\\mat{X}\\): a matrix whose dimensions are the same as \\(\\mat{X}\\), but whose rank is smaller than that of \\(\\mat{X}\\).\nWe can define the reconstruction error to be \\(\\mathrm{R}(\\mat{X}_d, \\mat{X}) := \\| \\mat{X}_d - \\mat{X} \\|^2\\), where \\(\\| \\cdot \\|\\) denotes an appropriately-defined matrix norm."
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#example",
    "href": "Lectures/Lec06/Lec06.html#example",
    "title": "PSTAT 100: Lecture 06",
    "section": " Example",
    "text": "Example\n\nWhew, that’s a lot of math!\nLet’s work through an example together. We’ll start off with \\[ \\mat{X} = \\begin{pmatrix} 1 & 2 & 3 & 1 \\\\ 2 & 0 & 1 & 2 \\\\ 3 & 0 & 0 & 1 \\\\ 2 & 1 & 1 & 0 \\\\ 0 & 1 & 0 & 0 \\\\ 2 & 1 & 1 & 1 \\\\ \\end{pmatrix} \\]"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#example-1",
    "href": "Lectures/Lec06/Lec06.html#example-1",
    "title": "PSTAT 100: Lecture 06",
    "section": " Example",
    "text": "Example\n\n\nOver the next few slides, I’ll project \\(\\mat{X}\\) into a smaller-dimensional subspace using the first 2, 3, and 4 principal components, then invert the projection and display the “recovered” \\(\\mat{X}\\) (which will be the mean-centered version of \\(\\mat{X}\\)):\n\n\n\n\nCode\nX &lt;- matrix(c(1, 2, 3, 1,\n         2, 0, 1, 2,\n         3, 0, 0, 1,\n         2, 1, 1, 0,\n         0, 1, 0, 0,\n         2, 1, 1, 1),\n       nrow = 6,\n       byrow = T)\n\nX_c &lt;- scale(X, scale = F)\n\nX_c \n\n\n           [,1]       [,2] [,3]       [,4]\n[1,] -0.6666667  1.1666667    2  0.1666667\n[2,]  0.3333333 -0.8333333    0  1.1666667\n[3,]  1.3333333 -0.8333333   -1  0.1666667\n[4,]  0.3333333  0.1666667    0 -0.8333333\n[5,] -1.6666667  0.1666667   -1 -0.8333333\n[6,]  0.3333333  0.1666667    0  0.1666667\nattr(,\"scaled:center\")\n[1] 1.6666667 0.8333333 1.0000000 0.8333333"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#example-2",
    "href": "Lectures/Lec06/Lec06.html#example-2",
    "title": "PSTAT 100: Lecture 06",
    "section": " Example",
    "text": "Example\n2-Dimensional Subspace\n\nProjectRecoverCompare\n\n\nMultiply \\(\\mat{X}\\) by the matrix containing the first two principal components:\n\n(X2 &lt;- prcomp(X)$x[,1:2])\n\n             PC1        PC2\n[1,] -2.22141095  0.9476208\n[2,]  0.78993734  0.8220772\n[3,]  1.82811089  0.2313481\n[4,] -0.02366601 -0.2547062\n[5,] -0.49186600 -2.0209854\n[6,]  0.11889473  0.2746455\n\n\n\n\nBackwards-project using the first two principal components:\n\nX2 %*% t(prcomp(X)$rotation[,1:2])\n\n           [,1]        [,2]        [,3]       [,4]\n[1,] -0.6824534  1.15684238  1.99860514  0.1849387\n[2,]  0.9013719 -0.43233075  0.01912272  0.5477820\n[3,]  1.1362868 -0.97030623 -1.00802682  0.3830813\n[4,] -0.1577576  0.01711215 -0.14544752 -0.1382030\n[5,] -1.4188787  0.29648176 -0.96215851 -1.1399328\n[6,]  0.2214310 -0.06779931  0.09790498  0.1623338\n\n\n\n\n\nX_c\n\n           [,1]       [,2] [,3]       [,4]\n[1,] -0.6666667  1.1666667    2  0.1666667\n[2,]  0.3333333 -0.8333333    0  1.1666667\n[3,]  1.3333333 -0.8333333   -1  0.1666667\n[4,]  0.3333333  0.1666667    0 -0.8333333\n[5,] -1.6666667  0.1666667   -1 -0.8333333\n[6,]  0.3333333  0.1666667    0  0.1666667\nattr(,\"scaled:center\")\n[1] 1.6666667 0.8333333 1.0000000 0.8333333"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#example-3",
    "href": "Lectures/Lec06/Lec06.html#example-3",
    "title": "PSTAT 100: Lecture 06",
    "section": " Example",
    "text": "Example\n3-Dimensional Subspace\n\nProjectRecoverCompare\n\n\nMultiply \\(\\mat{X}\\) by the matrix containing the first three principal components:\n\n(X3 &lt;- prcomp(X)$x[,1:3])\n\n             PC1        PC2         PC3\n[1,] -2.22141095  0.9476208  0.02606604\n[2,]  0.78993734  0.8220772 -0.92336792\n[3,]  1.82811089  0.2313481  0.32095854\n[4,] -0.02366601 -0.2547062  0.85861868\n[5,] -0.49186600 -2.0209854 -0.41659441\n[6,]  0.11889473  0.2746455  0.13431906\n\n\n\n\nBackwards-project using the first two principal components:\n\nX3 %*% t(prcomp(X)$rotation[,1:3])\n\n           [,1]        [,2]        [,3]        [,4]\n[1,] -0.6668552  1.16553247  2.00064836  0.16605904\n[2,]  0.3488162 -0.74016994 -0.05325683  1.21657701\n[3,]  1.3283527 -0.86330271 -0.98286801  0.15061120\n[4,]  0.3560513  0.30336477 -0.07814344 -0.76010018\n[5,] -1.6681744  0.15759445 -0.99481387 -0.83819359\n[6,]  0.3018094 -0.02301903  0.10843378  0.06504651\n\n\n\n\n\nX_c\n\n           [,1]       [,2] [,3]       [,4]\n[1,] -0.6666667  1.1666667    2  0.1666667\n[2,]  0.3333333 -0.8333333    0  1.1666667\n[3,]  1.3333333 -0.8333333   -1  0.1666667\n[4,]  0.3333333  0.1666667    0 -0.8333333\n[5,] -1.6666667  0.1666667   -1 -0.8333333\n[6,]  0.3333333  0.1666667    0  0.1666667\nattr(,\"scaled:center\")\n[1] 1.6666667 0.8333333 1.0000000 0.8333333"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#example-4",
    "href": "Lectures/Lec06/Lec06.html#example-4",
    "title": "PSTAT 100: Lecture 06",
    "section": " Example",
    "text": "Example\n4-Dimensional Subspace\n\nProjectRecoverCompare\n\n\nMultiply \\(\\mat{X}\\) by the matrix containing the four three principal components:\n\n(X4 &lt;- prcomp(X)$x[,1:4])\n\n             PC1        PC2         PC3          PC4\n[1,] -2.22141095  0.9476208  0.02606604  0.001453105\n[2,]  0.78993734  0.8220772 -0.92336792 -0.119358571\n[3,]  1.82811089  0.2313481  0.32095854  0.038396007\n[4,] -0.02366601 -0.2547062  0.85861868 -0.175134144\n[5,] -0.49186600 -2.0209854 -0.41659441  0.011623098\n[6,]  0.11889473  0.2746455  0.13431906  0.243020505\n\n\n\n\nBackwards-project using the first two principal components:\n\nX4 %*% t(prcomp(X)$rotation[,1:4])\n\n           [,1]       [,2]          [,3]       [,4]\n[1,] -0.6666667  1.1666667  2.000000e+00  0.1666667\n[2,]  0.3333333 -0.8333333  7.535993e-17  1.1666667\n[3,]  1.3333333 -0.8333333 -1.000000e+00  0.1666667\n[4,]  0.3333333  0.1666667 -3.215917e-17 -0.8333333\n[5,] -1.6666667  0.1666667 -1.000000e+00 -0.8333333\n[6,]  0.3333333  0.1666667 -3.564466e-17  0.1666667\n\n\n\n\n\nX_c\n\n           [,1]       [,2] [,3]       [,4]\n[1,] -0.6666667  1.1666667    2  0.1666667\n[2,]  0.3333333 -0.8333333    0  1.1666667\n[3,]  1.3333333 -0.8333333   -1  0.1666667\n[4,]  0.3333333  0.1666667    0 -0.8333333\n[5,] -1.6666667  0.1666667   -1 -0.8333333\n[6,]  0.3333333  0.1666667    0  0.1666667\nattr(,\"scaled:center\")\n[1] 1.6666667 0.8333333 1.0000000 0.8333333"
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#screeplots",
    "href": "Lectures/Lec06/Lec06.html#screeplots",
    "title": "PSTAT 100: Lecture 06",
    "section": " Screeplots",
    "text": "Screeplots\nHow Much Variance?\n\nSo, as the last demo illustrated: as we increase the dimension onto which we are projecting, the reconstructed matrix will become more and more similar to the original matrix.\nAs always, there’s a tradeoff.\n\nOn the one hand, we want our reconstructed matrix to be as similar to the original as possible.\nOn the other, however, we want some dimension reduction.\nSo, how much dimension reduction should we perform?\n\nTo answer this qeustion, we’ll go back to a fact from yesterday’s lecture: the variance of the data projected along the kth principal component is proportional to \\(\\lambda_k\\), the associated eigenvalue."
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#screeplots-1",
    "href": "Lectures/Lec06/Lec06.html#screeplots-1",
    "title": "PSTAT 100: Lecture 06",
    "section": " Screeplots",
    "text": "Screeplots\nHow Much Variance?\n\nTherefore, the proportion of the total variance captured by the kth principal component (i.e. the proportion of the total variance present in the variance of the data projected along the kth PC) is given by \\[ s_k := \\frac{\\lambda_k}{\\sum_{k} \\lambda_k} = \\frac{\\sigma_k^2}{\\sum_{k} \\sigma_k^2} \\] where \\(\\sigma_k\\) is the kth singular value of \\(\\mat{X}\\).\nA plot of sk vs k is called a screeplot, named after a particular rock formation."
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#screeplots-2",
    "href": "Lectures/Lec06/Lec06.html#screeplots-2",
    "title": "PSTAT 100: Lecture 06",
    "section": " Screeplots",
    "text": "Screeplots\nHow Much Variance?\n\nIn practice, to figure out the ideal number of PCs to use, look for an “elbow” in the screeplot.\n\n\n\n\n\n\nCode\nset.seed(100)  ## for reproducibility\nS_Mat &lt;- toeplitz(c(10, rep(1, 5)))\nX &lt;- mvrnorm(n = 10, mu = rep(0, 6), Sigma = S_Mat)\n\nPCA_X &lt;- prcomp(X, scale. = TRUE)\ns_k &lt;- PCA_X$sdev^2 / sum(PCA_X$sdev^2)\n\ndata.frame(k = 1:ncol(X), y = s_k) %&gt;% \n  ggplot(aes(x = k, y = s_k)) +\n  geom_point(size = 5) + geom_line(linewidth = 1) +\n  theme_minimal(base_size = 24) + ylab(\"prop. var\") +\n  ggtitle(\"Example Screeplot\")\n\n\n\n\n\n\n\n\n\n\n\n\nThe first five PCs capture around nearly 94% of the total variance!\nSo, for this matrix, around 5 dimensions is sufficient; the sixth contributed very little toward the total variance."
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#live-demo",
    "href": "Lectures/Lec06/Lec06.html#live-demo",
    "title": "PSTAT 100: Lecture 06",
    "section": " Live Demo!",
    "text": "Live Demo!\n\n\n\n\n\n\nLive Demo\n\n\nTime for another live demo! Feel free to boot up your laptops and follow along. In this demo we’ll take a look at the notion of reconstruction error, which essentially is a measure of how poorly our reconstructed matrix is doing at approximating the original matrix.\nBackground: The MNIST (Modified National Institute of Standards and Technology) database contains around 70,000 handwritten digits, collected from a combination of high school students and US Census Bureau employees. Each digit is stored as a 28px by 28px image, with an additional classifier label (indicating what digit the image is supposed to be)."
  },
  {
    "objectID": "Lectures/Lec06/Lec06.html#next-time",
    "href": "Lectures/Lec06/Lec06.html#next-time",
    "title": "PSTAT 100: Lecture 06",
    "section": " Next Time",
    "text": "Next Time\n\nIn lab today, you will work through another example of PCA.\n\nSpecifically, you will explore the voting habits of the 118th House of Representatives.\n\nTonight’s lab also marks the end of material that is fair game for the first ICA.\n\nTo be clear, PCA is fair game for the ICA.\n\nWe’ll spend tomorrow’s lecture reviewing for the ICA, so please come with questions!"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#leadup",
    "href": "Lectures/Lec09/Lec09.html#leadup",
    "title": "PSTAT 100: Lecture 09",
    "section": " Leadup",
    "text": "Leadup\n\nSo far, we’ve spent a lot of time describing and analyzing data.\n\nSemantics vs structure; visualizations; designing studies; collecting data etc.\n\nIndeed, much of what we have done is a part of descriptive statistics which, in a sense, is the branch of statistics devoted to describing data.\nNow, yesterday we started talking about how samples are taken from a population.\nAssuming appropriate scope of inference, do we have enough statistical tools to use our data to actually say something about the population?\nWith our current tools: no.\n\nBut, this is where inferential statistics comes into play."
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#probability-vs.-statistics",
    "href": "Lectures/Lec09/Lec09.html#probability-vs.-statistics",
    "title": "PSTAT 100: Lecture 09",
    "section": " Probability vs. Statistics",
    "text": "Probability vs. Statistics\nAn Illustration\n\nConsider a bucket comprised of blue and gold marbles, and suppose we know how many blue and gold marbles there are.\n\nFrom this bucket, we take a sample of marbles.\n\n\n\n\n\n\n\n\n\nWe then use our information of the configuration of marbles in the bucket to inform us about what’s in our hand.\n\nE.g. what’s the expected number of gold marbles in our hand?\nE.g. what’s the probability that we have more than 3 blue marbles in our hand?"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#probability-vs.-statistics-1",
    "href": "Lectures/Lec09/Lec09.html#probability-vs.-statistics-1",
    "title": "PSTAT 100: Lecture 09",
    "section": " Probability vs. Statistics",
    "text": "Probability vs. Statistics\nAn Illustration\n\nConsider now the opposite scenario: we do not know anything about the configuration of marbles in the bucket. All we have is a sample of, say, 11 blue and 6 gold marbles drawn from this bucket.\n\n\n\n\n\n\n\n\nWe then use our information on the configuration of marbles in our hand to inform us about what’s in the bucket.\n\nE.g. what’s the expected number of gold marbles in the bucket?\nE.g. what’s the probability that there are more than 3 blue marbles in the bucket?"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#statistical-inference",
    "href": "Lectures/Lec09/Lec09.html#statistical-inference",
    "title": "PSTAT 100: Lecture 09",
    "section": " Statistical Inference",
    "text": "Statistical Inference\nGeneral Framework\n\nNow, instead of marbles in a bucket, imagine units in our sampled population.\n\n\n\n\nWe have a population, governed by a set of population parameters that are unobserved (but that we’d like to make claims about).\nTo make claims about the population parameters, we take a sample.\nWe then use our sample to make inferences (i.e. claims) about the population parameters."
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#example-cats",
    "href": "Lectures/Lec09/Lec09.html#example-cats",
    "title": "PSTAT 100: Lecture 09",
    "section": " Example: Cats",
    "text": "Example: Cats\n\nAs an example, suppose we wish to determine the true average weight of all cats in the world. Call this quantity µ.\nClearly, a census is impossible here; we cannot weigh every single cat in the world and average their weights.\nInstead, we can take repeated samples (say, SRSes) of n cats and use these samples to say something about µ.\nLet’s establish some notation.\n\nDefine Yi to be the weight of a randomly-selected cat. This is random.\nDefine yi to be the weight of a specific cat (e.g. Kitty). This is deterministic."
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#cats",
    "href": "Lectures/Lec09/Lec09.html#cats",
    "title": "PSTAT 100: Lecture 09",
    "section": " Cats!",
    "text": "Cats!"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#cats-1",
    "href": "Lectures/Lec09/Lec09.html#cats-1",
    "title": "PSTAT 100: Lecture 09",
    "section": " Cats!",
    "text": "Cats!"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#cats-2",
    "href": "Lectures/Lec09/Lec09.html#cats-2",
    "title": "PSTAT 100: Lecture 09",
    "section": " Cats!",
    "text": "Cats!"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#cats-3",
    "href": "Lectures/Lec09/Lec09.html#cats-3",
    "title": "PSTAT 100: Lecture 09",
    "section": " Cats!",
    "text": "Cats!"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#cats-4",
    "href": "Lectures/Lec09/Lec09.html#cats-4",
    "title": "PSTAT 100: Lecture 09",
    "section": " Cats!",
    "text": "Cats!\n\nA random sample of cat weights is then a collection \\(\\{Y_1, \\cdots, Y_n\\}\\) of random variables (in this case, random cat weights).\n\nA particular realization of a sample is then \\(\\{y_1, \\cdots, y_n\\}\\).\n\nDoesn’t it seem tempting to use the average weight of our sampled cats to say something about the average weight of all cats (µ)?\nIndeed, we can define the sample mean to be \\[ \\overline{Y}_n := \\frac{1}{n} \\sum_{i=1}^{n} Y_i \\] a quantity you should hopefully recognize from PSTAT 120A!"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#statistics-and-estimators",
    "href": "Lectures/Lec09/Lec09.html#statistics-and-estimators",
    "title": "PSTAT 100: Lecture 09",
    "section": " Statistics and Estimators",
    "text": "Statistics and Estimators\n\nWe define a statistic to be a function of our random sample \\((Y_1, \\cdots, Y_n)\\).\n\nExample: sample mean: \\(\\overline{Y}_n := \\frac{1}{n} \\sum_{i=1}^{n} Y_i\\)\nExample: sample variance: \\(S_n^2 := \\frac{1}{n - 1} \\sum_{i=1}^{n} (Y_i - \\overline{Y}_n)^2\\)\nExample: sample maximum: \\(Y_{(n)} := \\max\\{Y_1, \\cdots, Y_n\\}\\)\n\nBy definition, statistics are random variables.\n\nFor example, different samples of cat weights will have potentially different observed averages, variances, and maxima.\nThe distribution of a statistic is called its sampling distribution\n\nA statistic used in service of estimating a population parameter is called an estimator, and the value of an estimator corresponding to a particualar realized sample is called an estimate"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#statistics-and-estimators-1",
    "href": "Lectures/Lec09/Lec09.html#statistics-and-estimators-1",
    "title": "PSTAT 100: Lecture 09",
    "section": " Statistics and Estimators",
    "text": "Statistics and Estimators\nExample\n\n\n\n\n\n\nExample\n\n\nA vet wishes to estimate the true weight of all cats in the world. She takes a sample of 10 cats, and finds their average weight to be 9.12 lbs.\n\n\n\n\nThe population parameter is the true average weight of all cats in the world (which we can call µ).\nThe estimator is the sample mean: we are using sample means to estimate µ.\nThe estimate in this scenario is 9.12 lbs, as this is a particular realization of our estimator."
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\n\nAs we will soon see, it’s often very useful to derive the sampling distribution of a particular statistic.\nThere are two main ways to derive sampling distributions: using a simulation-based approach, and using a theoretical approach. Let’s start off with a simulation-based approach.\nTo make things more concrete, suppose \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, 1)\\).\n\nIf it’s helpful, you can again think of Yi as the weight of a randomly-selected cat; now, we’re saying that this random variable follows a normal distribution with mean µ and variance 1, and that cat weights are independent across cats.\n\n\n\n\n\n\n\n\n\nGoal\n\n\nDetermine the sampling distribution of \\(\\overline{Y}_n := n^{-1} \\sum_{i=1}^{n} Y_i\\)."
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-1",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-1",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nNormal Example\n\nRecall that the whole notion of a sampling distribution arises because our statistics (in this case, the sample mean) are random.\n\nDifferent samples of cats will yield different observed sample mean weights\nIn essence, the sampling distribution seeks to capture the randomness or variability present in a statistic.\n\nWith computer technology, we can try to capture this variability empirically:\n\nSimulate taking a sample of n cats, and record the average weight\nRepeat this a very large number of times, and examine the distribution of the sample means.\n\nThis distribution should, in theory, give us a good sense of the sampling distribution of the sample mean!"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-2",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-2",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nNormal Example\n\nThe first question is: how do we simulate taking a sample of cats?\nBecause we are assuming the weight of a randomly-selected cat follows a normal distribution, we can use R’s built-in rnorm() function.\nFor example, to draw a sample of size 10 from a \\(\\mathcal{N}(10.2, 1)\\) distribution, we would run\n\n\n\nset.seed(100)   ## for reproducibility\nrnorm(n = 10, mean = 10.2, sd = 1) %&gt;% round(3)\n\n [1]  9.698 10.332 10.121 11.087 10.317 10.519  9.618 10.915  9.375  9.840\n\n\n\n\nAgain, in the context of our cat-weight example, these values represent a hypothetical collection of the weights of 10 different cats."
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-3",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-3",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nNormal Example\n\n\nCode\nset.seed(100)   ## for reproducibility\n\nmeans_10 &lt;- c()\nn &lt;- 10         ## sample size\nB &lt;- 1000       ## number of samples\nfor(b in 1:B){\n  means_10 &lt;- c(means_10,rnorm(n, 10.2, 1) %&gt;% mean())\n}"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-4",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-4",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nNormal Example\n\n\nCode\nset.seed(100)   ## for reproducibility\n\nmeans_50 &lt;- c()\nn &lt;- 50         ## sample size\nB &lt;- 1000       ## number of samples\nfor(b in 1:B){\n  means_50 &lt;- c(means_50,rnorm(n, 10.2, 1) %&gt;% mean())\n}"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-5",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-5",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nNormal Example\n\n\nCode\nset.seed(100)   ## for reproducibility\n\nmeans_100 &lt;- c()\nn &lt;- 100         ## sample size\nB &lt;- 1000       ## number of samples\nfor(b in 1:B){\n  means_100 &lt;- c(means_100,rnorm(n, 10.2, 1) %&gt;% mean())\n}"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-6",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-6",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nNormal Example\n\nSome interesting takeaways:\n\nRegardless of the sample size, the sampling distribution of \\(\\overline{Y}_n\\) appears to be roughly normal.\nRegardless of the sample size, the sampling distribution of \\(\\overline{Y}_n\\) appears to centered at the population mean (10.2).\nAs the sample size increases, the sampling distribution of \\(\\overline{Y}_n\\) becomes more tightly concentrated about the population mean (10.2)\n\nGuess what- this shouldn’t be a surprise!"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-7",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-7",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nSample Mean: Normal Population\n\n\n\n\n\n\nSample Mean of Normally-Distributed Random Variables\n\n\nIf \\(Y_1, \\cdots, Y_n \\iid \\mathcal{N}(\\mu, \\sigma^2)\\), then \\[ \\overline{Y}_n := \\left( \\frac{1}{n} \\sum_{i=1}^{n} Y_i \\right) \\sim \\mathcal{N}\\left( \\mu, \\ \\frac{\\sigma^2}{n} \\right) \\]\n\n\n\n\nThis is a result you saw in PSTAT 120A, and proved using Moment-Generating Functions.\nIn the context of sampling, here’s what this says: if we assume a normally-distributed population, then the sampling distribution of the sample mean is also normal."
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-8",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-8",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nSample Mean: Normal Population"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-9",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-9",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nSample Variance: Normal Population\n\nNow, note (again) that our sampling distribution of the sample mean is centered at the true value of the population mean (which, in the simulation, is 10.2).\nIndeed:\n\n\n\\[ \\mathbb{E}[\\overline{Y}_n] = \\mathbb{E}\\left[ \\frac{1}{n} \\sum_{i=1}^{n} Y_i \\right] = \\frac{1}{n} \\sum_{i=1}^{n} \\E[Y_i] = \\frac{1}{n} \\sum_{i=1}^{n} (\\mu) = \\frac{1}{n} \\cdot n \\mu = \\mu \\]\n\n\nSo, the expected value of the sample mean \\(\\overline{Y}_n\\) is the population mean µ: on average, the sample mean will guess the true population mean bang-on."
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#bias",
    "href": "Lectures/Lec09/Lec09.html#bias",
    "title": "PSTAT 100: Lecture 09",
    "section": " Bias",
    "text": "Bias\n\nWe define the bias (sometimes called the statistical bias, to distinguish from the forms of bias we talked about yesterday) of an estimator to be the difference between the expected value of the estimator and the parameter it’s trying to estimate: \\[ \\mathrm{Bias}(\\widehat{\\theta}_n, \\theta) := \\E[\\widehat{\\theta}_n] - \\theta \\]\nFor example, based on what we did on the previous slide, \\[ \\mathrm{Bias}(\\overline{Y}_n , \\mu) = \\E[\\overline{Y}_n] - \\mu = \\mu - \\mu = 0 \\]\n\nAn estimator whose bias is equal to zero is said to be unbiased.\nFor example, the sample mean is an unbiased estimator for the population mean."
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#bias-1",
    "href": "Lectures/Lec09/Lec09.html#bias-1",
    "title": "PSTAT 100: Lecture 09",
    "section": " Bias",
    "text": "Bias\n\nHere are three parameters that arise frequently throughout statistics, and a corresponding unbiased estimator for each:\n\n\n\n\n\n\n\n\n\n\n\n\nParameter  Name\nParameter Symbol\nCommon Estimator\n\n\n\n\nMean\nµ\nSample Mean: \\(\\overline{Y}_n := (1/n) \\sum_{i=1}^{n} Y_i\\)\n\n\nVariance\nσ2\nSample Variance: \\(S_n^2 := (n-1)^{-1} \\sum_{i=1}^{n} (Y_i - \\overline{Y}_n)^2\\)\n\n\nProportion\np\nSample Proportion: \\(\\widehat{P}_n := \\mathrm{prop}(\\mathrm{success})\\)"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#proportions-as-means",
    "href": "Lectures/Lec09/Lec09.html#proportions-as-means",
    "title": "PSTAT 100: Lecture 09",
    "section": " Proportions as Means",
    "text": "Proportions as Means\n\nBy the way, like we talked about in lecture yesterday, proportions are actually just a special case of means: specifically, a proportion is just a mean of binary 0/1 values.\nAs an example, imagine tossing a coin:"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#your-turn",
    "href": "Lectures/Lec09/Lec09.html#your-turn",
    "title": "PSTAT 100: Lecture 09",
    "section": " Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nYour Turn!\n\n\nAt Stellardollar Coffee, the time X (in minutes) a randomly-selected person spends waiting in line follows a distribution with density function given by \\[ f_X(x) = \\begin{cases} \\frac{1}{\\beta} e^{-x/\\beta} & \\text{if } x \\geq 0 \\\\ 0 & \\text{otherwise} \\\\ \\end{cases} \\]\n\n\nIn terms of β, what is the population average wait time? (I.e., what is \\(\\E[X]\\)?)\nIf X represents the (random) wait time of a randomly-selected customer from Stellardollar Coffee, is X2 an unbiased estimator for the true average wait time of customers?\nIf X and Y represent the (random) wait times of two randomly-selected customers, is the average wait time (X + Y)/2 an unbiased estimator for the true average wait time of customers?\n\n\n\n\n\n\n\n\n−+\n05:00"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#simulations",
    "href": "Lectures/Lec09/Lec09.html#simulations",
    "title": "PSTAT 100: Lecture 09",
    "section": " Simulations",
    "text": "Simulations\n\nLet’s consider again part (c) of the previous “Your Turn” exercise.\nSpecifically, let’s see if we can implement a simulation-based approach to answering it.\nHere’s the idea:\n\nSimulate the two wait times X and Y\nCompute their average\nRepeat steps 1 and 2 a large number of times, and compute the sample average of these values\n\nIt seems that this final sample average should be close to the true theoretical expectation.\n\nIndeed, this is a simple example of a Monte Carlo Simulation"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#simulations-1",
    "href": "Lectures/Lec09/Lec09.html#simulations-1",
    "title": "PSTAT 100: Lecture 09",
    "section": " Simulations",
    "text": "Simulations\n\nset.seed(100)   ## for reproducibility\ntrue_beta &lt;- 2  ## for the purposes of simulation\n\nB &lt;- 1000            ## the number of times to run the simulation\nsamp_means &lt;- c()    ## initialize a blank vector to store the sample means\n\nfor(b in 1:B) {\n  X &lt;- rexp(1, rate = 1/2)     ## simulate the first wait time\n  Y &lt;- rexp(1, rate = 1/2)     ## simulate the second wait time\n  samp_means &lt;- c(samp_means, mean(c(X, Y)))\n}\n\n\nHere’s our approximation to \\(\\mathbb{E}[(X + Y)/2]\\):\n\n\n\nmean(samp_means)\n\n[1] 1.951942"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-10",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-10",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nSample Mean: Non-Normal Population\n\nFinally, we close out by exploring the sampling distribution of the sample mean, assuming a non-normal population.\nHere is the general algorithm we’ll use:\n\nSimulate a draw of size n (for different values of n) from the Exp(2) distribution\nCompute the mean of these simulated values\nRepeat a large number (1000) times, and examine the histogram of resulting sample mean values.\n\nThis histogram should give us a general idea of what the sampling distribution of \\(\\overline{Y}_n\\) when \\(Y_1, \\cdots, Y_n\\) are i.i.d. Exp(2) random variables."
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-11",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-11",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nSample Mean: Non-Normal Population"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-12",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-12",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nSample Mean: Non-Normal Population\n\nAs the sample size increases, the sampling distribution of \\(\\overline{Y}_n\\) starts to look more and more like a normal distribution…\nAgain - this is actually old news!\n\n\n\n\n\n\n\n\nCentral Limit Theorem\n\n\nGiven an i.i.d. sample (Y1, …, Yn) from a distribution with finite mean µ  and finite variance σ2, \\[ \\frac{\\sqrt{n}(\\overline{Y}_n - \\mu)}{\\sigma} \\stackrel{\\cdot}{\\sim} \\mathcal{N}(0, 1) \\quad \\iff \\quad  \\overline{Y}_n \\stackrel{\\cdot}{\\sim} \\mathcal{N}\\left(\\mu, \\ \\frac{\\sigma^2}{n} \\right) \\]\n\n\n\n\n\nHere, \\(\\stackrel{\\cdot}{\\sim}\\) can be read as “approximately distributed as”"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#sampling-distributions-13",
    "href": "Lectures/Lec09/Lec09.html#sampling-distributions-13",
    "title": "PSTAT 100: Lecture 09",
    "section": " Sampling Distributions",
    "text": "Sampling Distributions\nSample Mean: Non-Normal Population"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#collective-exercise",
    "href": "Lectures/Lec09/Lec09.html#collective-exercise",
    "title": "PSTAT 100: Lecture 09",
    "section": " Collective Exercise",
    "text": "Collective Exercise\n\n\n\n\n\n\nLet’s Work On This Together!\n\n\nThe amount of time a randomly-selected Santa Barbara MTD bus is delayed is a random variable with mean 4 minutes and standard deviation 3 minutes.\n\n\nWhat is the probability that a randomly-selected bus is early? (Hint: think about what this means in the context of the problem.)\nA collection of 81 independent buses is taken, and the average (mean) amount of delay is recorded. What is the probability that the average amount of delay among these 81 buses lies between 3 minutes and 5 minutes?"
  },
  {
    "objectID": "Lectures/Lec09/Lec09.html#next-time",
    "href": "Lectures/Lec09/Lec09.html#next-time",
    "title": "PSTAT 100: Lecture 09",
    "section": " Next Time",
    "text": "Next Time\n\nTomorrow, we’ll continue our discussion of estimation.\n\nWe’ll further explore the notion of statistical bias\nWe’ll also introduce confidence intervals, which arise very frequently in statistics.\n\nIn lab today, you’ll get some practice with the sampling techniques we discussed yesterday (and explore the effects of bias), along with some practice with sampling distributions.\nPlease do not forget that the Mid-Quarter Project is due THIS SUNDAY (July 13, 2025) by 11:59pm, on Gradescope.\n\nOnly one of your group members needs to submit; on Gradescope, there will be a way for them to include all group member’s names."
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#review-data-semantics",
    "href": "Lectures/Lec02/Lec02.html#review-data-semantics",
    "title": "PSTAT 100: Lecture 02",
    "section": " Review: Data Semantics",
    "text": "Review: Data Semantics\nDefinition\n\n\n\n\n\n\nDefinition: Data\n\n\nWe define an observation to be a collection of values measured on certain attributes (aka variables). From a semantic standpoint, we define data to be a collection of observations collected on observational units."
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#review-data-semantics-1",
    "href": "Lectures/Lec02/Lec02.html#review-data-semantics-1",
    "title": "PSTAT 100: Lecture 02",
    "section": " Review: Data Semantics",
    "text": "Review: Data Semantics\nAnother Illustration"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#review-course-enrollments-dataset",
    "href": "Lectures/Lec02/Lec02.html#review-course-enrollments-dataset",
    "title": "PSTAT 100: Lecture 02",
    "section": " Review: Course Enrollments Dataset",
    "text": "Review: Course Enrollments Dataset\nSome Sample Observations\n\n\nThe enrollment for PSTAT 5A, titled “Understanding Data,” was 167 in Spring 2025\nThe enrollment for PSTAT 5A, titled “Understanding Data,” was 222 in Winter 2025\nThe enrollment for PSTAT 5H, titled “Statistics,” was 11 in Spring 2025\n\n\n\nWide LayoutLong Layout\n\n\n\n\n      Course               Title S25 W25 F24 M24 S24 W24 F23 M23 S23 W23 F22\n    PSTAT 5A  UNDERSTANDING DATA 167 222 213  76 258 283 549 110 212 279 499\n    PSTAT 5H          STATISTICS  11  14  30  NA  31  24  25  NA  31  22   4\n   PSTAT 5LS  STAT LIFE SCIENCES 355 340 348  59 304 299  NA  39 299 294  NA\n     PSTAT 8  TRANS DS PROB STAT  70 105 137  22  83 134 132  18  86 156  70\n    PSTAT 10  DATA SCIENCE PRINC 235 241 286  93 234 260 285  83 240 282 257\n    PSTAT 99 INDEPENDENT STUDIES   1   2  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 100        DS_CONC&ANLS 109 131 108  NA  95  NA 104  48 125 127  NA\n   PSTAT 105  INTRO N-PARAM METH  NA  79  NA  NA  NA  NA  39  NA  NA  NA  79\n   PSTAT 109 STATISTICS FOR ECON  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 115 BAYES DATA ANALYSIS  81  56  74  25  74  96  16  15  38  70  63\n  PSTAT 120A   PROB & STATISTICS 310 383 345  75 367 372 419  86 237 246 419\n  PSTAT 120B   PROB & STATISTICS 312 329 236 136 382 241 261 102 256 256 165\n  PSTAT 120C   PROB & STATISTICS 163  NA  37 129 131  39  19  81  65  31  87\n   PSTAT 122 DESIGN OF EXPERMNTS 240 210 201  NA 177 162 167  NA 194 187 182\n   PSTAT 123  SAMPLING TECHNIQUE  NA  NA  NA  NA  NA 137  NA  NA  NA  NA  NA\n   PSTAT 126 REGRESSION ANALYSIS 197 214 272  94 147 200 123  84 149 175 182\n   PSTAT 127    ADV STATS MODELS  NA  NA  72  NA  NA  NA  57  NA  NA  73  NA\n   PSTAT 130    SAS BASE PROGRAM 116 120 121 108 122  97 120  95 119  98  97\n   PSTAT 131  STAT MACHINE LEARN  96 156  64  80  93 138 150  55 108 197 178\n   PSTAT 132 DATABASES FOR STATS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 134   STAT DATA SCIENCE  46  91  78  NA  70  78  80  NA  87  42  33\n   PSTAT 135  BIG DATA ANALYTICS  96  NA  NA  NA  NA  99  NA  NA  NA  93  NA\n   PSTAT 140 STATISTICAL PROCESS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 160A  STOCHASTIC PROCESS 132 217 126  NA 100 153 132  NA 108 161 184\n  PSTAT 160B  STOCHASTIC PROCESS 116  77  86  NA 106  73  43   7  82  81  58\n   PSTAT 170  INTRO MATH FINANCE 116  65  92  19 125  65  59  17  77  57  55\n   PSTAT 171   MATH COMPOUND INT  73  77  96  47  84  68 102  32  64  69 108\n  PSTAT 172A    ACTUARIAL STAT I  NA  49  NA  NA  NA  60  NA  NA  NA  43  NA\n  PSTAT 172B   ACTUARIAL STAT II  14  NA  NA  NA  20  NA  NA  NA  23  NA  NA\n   PSTAT 173         RISK THEORY  NA  NA  64  NA  NA  NA  35  NA  NA  NA  43\n   PSTAT 174         TIME SERIES  NA  89  83  NA 104  63  NA  NA 170 118  69\n   PSTAT 175   SURVIVAL ANALYSIS  71  NA  NA  NA  55  NA  18  NA  NA  NA  73\n   PSTAT 176    ADV MATH FINANCE  17  NA  NA  NA  15  NA  NA  NA  13  NA  NA\n   PSTAT 177      FINANCIAL RISK  31  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 182T  ACTUARIAL TUTORIAL  12  20  15  NA  17   6   4  NA   6   4   7\n   PSTAT 183  ACTUARIAL CONCEPTS  28  NA  NA  NA  44  NA  NA  NA  46  NA  NA\n   PSTAT 190        ULA TRAINING  NA  NA  14  NA  NA  NA   5  NA  NA  NA  20\n   PSTAT 191       ULA PRACTICUM  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 193 INTERNSHIP IN STATS   4   3   4  28   6   4   8  20   6   3   2\n   PSTAT 194  GRP STDY ADV STDNT  NA  NA  NA  11  29  NA  NA  NA  28  NA  NA\n   PSTAT 195      SPECIAL TOPICS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 196   RESEARCH IN ACTSC  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 197A    DS CAPSTONE PREP  NA  NA  59  NA  NA  NA  58  NA  NA  NA  59\n  PSTAT 197B DS CAPSTONE PROJECT  NA  58  NA  NA  NA  56  NA  NA  NA  53  NA\n  PSTAT 197C DS CAPSTONE PROJECT  52  NA  NA  NA  53  NA  NA  NA  46  NA  NA\n   PSTAT 199 INDEPENDENT STUDIES  23  22  18   6  19  17  23   6  21  17  21\n PSTAT 199RA INDEP RESEARCH ASST  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n M22 S22 W22\n 116 194 278\n  NA  NA  NA\n  63 294 284\n  23  59  NA\n  87 278 287\n  NA  NA  NA\n  NA  95  88\n  NA  NA  93\n  NA  NA  NA\n  NA  NA  81\n  65 244 229\n 174 216 241\n 109 119  NA\n  NA 137 119\n  NA  NA  NA\n  67 250 123\n  NA  78  91\n 138 122  98\n  NA  75  76\n  NA  NA  NA\n  22  NA  66\n  NA  NA  NA\n  NA  NA  NA\n  51 130  77\n  54 109  72\n  41  74  69\n  49  70  68\n  NA  NA  60\n  NA  26  NA\n  NA  NA  50\n  NA  61  74\n  NA  NA  NA\n  NA  15  NA\n  NA  NA  NA\n  NA  12   5\n  NA  68  NA\n  NA  NA  NA\n  NA  NA  NA\n  35   5   4\n  NA  66  NA\n  NA  NA  NA\n  NA  NA  NA\n  NA  NA  NA\n  NA  NA  46\n  NA  47  NA\n  10  19   5\n  NA  NA  NA\n\n\n\n\n\n\n      Course               Title Quarter Enrollment\n    PSTAT 5A  UNDERSTANDING DATA     S25        167\n    PSTAT 5H          STATISTICS     S25         11\n   PSTAT 5LS  STAT LIFE SCIENCES     S25        355\n     PSTAT 8  TRANS DS PROB STAT     S25         70\n    PSTAT 10  DATA SCIENCE PRINC     S25        235\n    PSTAT 99 INDEPENDENT STUDIES     S25          1\n   PSTAT 100        DS_CONC&ANLS     S25        109\n   PSTAT 105  INTRO N-PARAM METH     S25         NA\n   PSTAT 109 STATISTICS FOR ECON     S25         NA\n   PSTAT 115 BAYES DATA ANALYSIS     S25         81\n  PSTAT 120A   PROB & STATISTICS     S25        310\n  PSTAT 120B   PROB & STATISTICS     S25        312\n  PSTAT 120C   PROB & STATISTICS     S25        163\n   PSTAT 122 DESIGN OF EXPERMNTS     S25        240\n   PSTAT 123  SAMPLING TECHNIQUE     S25         NA\n   PSTAT 126 REGRESSION ANALYSIS     S25        197\n   PSTAT 127    ADV STATS MODELS     S25         NA\n   PSTAT 130    SAS BASE PROGRAM     S25        116\n   PSTAT 131  STAT MACHINE LEARN     S25         96\n   PSTAT 132 DATABASES FOR STATS     S25         NA\n   PSTAT 134   STAT DATA SCIENCE     S25         46\n   PSTAT 135  BIG DATA ANALYTICS     S25         96\n   PSTAT 140 STATISTICAL PROCESS     S25         NA\n  PSTAT 160A  STOCHASTIC PROCESS     S25        132\n  PSTAT 160B  STOCHASTIC PROCESS     S25        116\n   PSTAT 170  INTRO MATH FINANCE     S25        116\n   PSTAT 171   MATH COMPOUND INT     S25         73\n  PSTAT 172A    ACTUARIAL STAT I     S25         NA\n  PSTAT 172B   ACTUARIAL STAT II     S25         14\n   PSTAT 173         RISK THEORY     S25         NA\n   PSTAT 174         TIME SERIES     S25         NA\n   PSTAT 175   SURVIVAL ANALYSIS     S25         71\n   PSTAT 176    ADV MATH FINANCE     S25         17\n   PSTAT 177      FINANCIAL RISK     S25         31\n  PSTAT 182T  ACTUARIAL TUTORIAL     S25         12\n   PSTAT 183  ACTUARIAL CONCEPTS     S25         28\n   PSTAT 190        ULA TRAINING     S25         NA\n   PSTAT 191       ULA PRACTICUM     S25         NA\n   PSTAT 193 INTERNSHIP IN STATS     S25          4\n   PSTAT 194  GRP STDY ADV STDNT     S25         NA\n   PSTAT 195      SPECIAL TOPICS     S25         NA\n   PSTAT 196   RESEARCH IN ACTSC     S25         NA\n  PSTAT 197A    DS CAPSTONE PREP     S25         NA\n  PSTAT 197B DS CAPSTONE PROJECT     S25         NA\n  PSTAT 197C DS CAPSTONE PROJECT     S25         52\n   PSTAT 199 INDEPENDENT STUDIES     S25         23\n PSTAT 199RA INDEP RESEARCH ASST     S25         NA\n    PSTAT 5A  UNDERSTANDING DATA     W25        222\n    PSTAT 5H          STATISTICS     W25         14\n   PSTAT 5LS  STAT LIFE SCIENCES     W25        340\n     PSTAT 8  TRANS DS PROB STAT     W25        105\n    PSTAT 10  DATA SCIENCE PRINC     W25        241\n    PSTAT 99 INDEPENDENT STUDIES     W25          2\n   PSTAT 100        DS_CONC&ANLS     W25        131\n   PSTAT 105  INTRO N-PARAM METH     W25         79\n   PSTAT 109 STATISTICS FOR ECON     W25         NA\n   PSTAT 115 BAYES DATA ANALYSIS     W25         56\n  PSTAT 120A   PROB & STATISTICS     W25        383\n  PSTAT 120B   PROB & STATISTICS     W25        329\n  PSTAT 120C   PROB & STATISTICS     W25         NA\n   PSTAT 122 DESIGN OF EXPERMNTS     W25        210\n   PSTAT 123  SAMPLING TECHNIQUE     W25         NA\n   PSTAT 126 REGRESSION ANALYSIS     W25        214\n   PSTAT 127    ADV STATS MODELS     W25         NA\n   PSTAT 130    SAS BASE PROGRAM     W25        120\n   PSTAT 131  STAT MACHINE LEARN     W25        156\n   PSTAT 132 DATABASES FOR STATS     W25         NA\n   PSTAT 134   STAT DATA SCIENCE     W25         91\n   PSTAT 135  BIG DATA ANALYTICS     W25         NA\n   PSTAT 140 STATISTICAL PROCESS     W25         NA\n  PSTAT 160A  STOCHASTIC PROCESS     W25        217\n  PSTAT 160B  STOCHASTIC PROCESS     W25         77\n   PSTAT 170  INTRO MATH FINANCE     W25         65\n   PSTAT 171   MATH COMPOUND INT     W25         77\n  PSTAT 172A    ACTUARIAL STAT I     W25         49\n  PSTAT 172B   ACTUARIAL STAT II     W25         NA\n   PSTAT 173         RISK THEORY     W25         NA\n   PSTAT 174         TIME SERIES     W25         89\n   PSTAT 175   SURVIVAL ANALYSIS     W25         NA\n   PSTAT 176    ADV MATH FINANCE     W25         NA\n   PSTAT 177      FINANCIAL RISK     W25         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     W25         20\n   PSTAT 183  ACTUARIAL CONCEPTS     W25         NA\n   PSTAT 190        ULA TRAINING     W25         NA\n   PSTAT 191       ULA PRACTICUM     W25         NA\n   PSTAT 193 INTERNSHIP IN STATS     W25          3\n   PSTAT 194  GRP STDY ADV STDNT     W25         NA\n   PSTAT 195      SPECIAL TOPICS     W25         NA\n   PSTAT 196   RESEARCH IN ACTSC     W25         NA\n  PSTAT 197A    DS CAPSTONE PREP     W25         NA\n  PSTAT 197B DS CAPSTONE PROJECT     W25         58\n  PSTAT 197C DS CAPSTONE PROJECT     W25         NA\n   PSTAT 199 INDEPENDENT STUDIES     W25         22\n PSTAT 199RA INDEP RESEARCH ASST     W25         NA\n    PSTAT 5A  UNDERSTANDING DATA     F24        213\n    PSTAT 5H          STATISTICS     F24         30\n   PSTAT 5LS  STAT LIFE SCIENCES     F24        348\n     PSTAT 8  TRANS DS PROB STAT     F24        137\n    PSTAT 10  DATA SCIENCE PRINC     F24        286\n    PSTAT 99 INDEPENDENT STUDIES     F24         NA\n   PSTAT 100        DS_CONC&ANLS     F24        108\n   PSTAT 105  INTRO N-PARAM METH     F24         NA\n   PSTAT 109 STATISTICS FOR ECON     F24         NA\n   PSTAT 115 BAYES DATA ANALYSIS     F24         74\n  PSTAT 120A   PROB & STATISTICS     F24        345\n  PSTAT 120B   PROB & STATISTICS     F24        236\n  PSTAT 120C   PROB & STATISTICS     F24         37\n   PSTAT 122 DESIGN OF EXPERMNTS     F24        201\n   PSTAT 123  SAMPLING TECHNIQUE     F24         NA\n   PSTAT 126 REGRESSION ANALYSIS     F24        272\n   PSTAT 127    ADV STATS MODELS     F24         72\n   PSTAT 130    SAS BASE PROGRAM     F24        121\n   PSTAT 131  STAT MACHINE LEARN     F24         64\n   PSTAT 132 DATABASES FOR STATS     F24         NA\n   PSTAT 134   STAT DATA SCIENCE     F24         78\n   PSTAT 135  BIG DATA ANALYTICS     F24         NA\n   PSTAT 140 STATISTICAL PROCESS     F24         NA\n  PSTAT 160A  STOCHASTIC PROCESS     F24        126\n  PSTAT 160B  STOCHASTIC PROCESS     F24         86\n   PSTAT 170  INTRO MATH FINANCE     F24         92\n   PSTAT 171   MATH COMPOUND INT     F24         96\n  PSTAT 172A    ACTUARIAL STAT I     F24         NA\n  PSTAT 172B   ACTUARIAL STAT II     F24         NA\n   PSTAT 173         RISK THEORY     F24         64\n   PSTAT 174         TIME SERIES     F24         83\n   PSTAT 175   SURVIVAL ANALYSIS     F24         NA\n   PSTAT 176    ADV MATH FINANCE     F24         NA\n   PSTAT 177      FINANCIAL RISK     F24         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     F24         15\n   PSTAT 183  ACTUARIAL CONCEPTS     F24         NA\n   PSTAT 190        ULA TRAINING     F24         14\n   PSTAT 191       ULA PRACTICUM     F24         NA\n   PSTAT 193 INTERNSHIP IN STATS     F24          4\n   PSTAT 194  GRP STDY ADV STDNT     F24         NA\n   PSTAT 195      SPECIAL TOPICS     F24         NA\n   PSTAT 196   RESEARCH IN ACTSC     F24         NA\n  PSTAT 197A    DS CAPSTONE PREP     F24         59\n  PSTAT 197B DS CAPSTONE PROJECT     F24         NA\n  PSTAT 197C DS CAPSTONE PROJECT     F24         NA\n   PSTAT 199 INDEPENDENT STUDIES     F24         18\n PSTAT 199RA INDEP RESEARCH ASST     F24         NA\n    PSTAT 5A  UNDERSTANDING DATA     M24         76\n    PSTAT 5H          STATISTICS     M24         NA\n   PSTAT 5LS  STAT LIFE SCIENCES     M24         59\n     PSTAT 8  TRANS DS PROB STAT     M24         22\n    PSTAT 10  DATA SCIENCE PRINC     M24         93\n    PSTAT 99 INDEPENDENT STUDIES     M24         NA\n   PSTAT 100        DS_CONC&ANLS     M24         NA\n   PSTAT 105  INTRO N-PARAM METH     M24         NA\n   PSTAT 109 STATISTICS FOR ECON     M24         NA\n   PSTAT 115 BAYES DATA ANALYSIS     M24         25\n  PSTAT 120A   PROB & STATISTICS     M24         75\n  PSTAT 120B   PROB & STATISTICS     M24        136\n  PSTAT 120C   PROB & STATISTICS     M24        129\n   PSTAT 122 DESIGN OF EXPERMNTS     M24         NA\n   PSTAT 123  SAMPLING TECHNIQUE     M24         NA\n   PSTAT 126 REGRESSION ANALYSIS     M24         94\n   PSTAT 127    ADV STATS MODELS     M24         NA\n   PSTAT 130    SAS BASE PROGRAM     M24        108\n   PSTAT 131  STAT MACHINE LEARN     M24         80\n   PSTAT 132 DATABASES FOR STATS     M24         NA\n   PSTAT 134   STAT DATA SCIENCE     M24         NA\n   PSTAT 135  BIG DATA ANALYTICS     M24         NA\n   PSTAT 140 STATISTICAL PROCESS     M24         NA\n  PSTAT 160A  STOCHASTIC PROCESS     M24         NA\n  PSTAT 160B  STOCHASTIC PROCESS     M24         NA\n   PSTAT 170  INTRO MATH FINANCE     M24         19\n   PSTAT 171   MATH COMPOUND INT     M24         47\n  PSTAT 172A    ACTUARIAL STAT I     M24         NA\n  PSTAT 172B   ACTUARIAL STAT II     M24         NA\n   PSTAT 173         RISK THEORY     M24         NA\n   PSTAT 174         TIME SERIES     M24         NA\n   PSTAT 175   SURVIVAL ANALYSIS     M24         NA\n   PSTAT 176    ADV MATH FINANCE     M24         NA\n   PSTAT 177      FINANCIAL RISK     M24         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     M24         NA\n   PSTAT 183  ACTUARIAL CONCEPTS     M24         NA\n   PSTAT 190        ULA TRAINING     M24         NA\n   PSTAT 191       ULA PRACTICUM     M24         NA\n   PSTAT 193 INTERNSHIP IN STATS     M24         28\n   PSTAT 194  GRP STDY ADV STDNT     M24         11\n   PSTAT 195      SPECIAL TOPICS     M24         NA\n   PSTAT 196   RESEARCH IN ACTSC     M24         NA\n  PSTAT 197A    DS CAPSTONE PREP     M24         NA\n  PSTAT 197B DS CAPSTONE PROJECT     M24         NA\n  PSTAT 197C DS CAPSTONE PROJECT     M24         NA\n   PSTAT 199 INDEPENDENT STUDIES     M24          6\n PSTAT 199RA INDEP RESEARCH ASST     M24         NA\n    PSTAT 5A  UNDERSTANDING DATA     S24        258\n    PSTAT 5H          STATISTICS     S24         31\n   PSTAT 5LS  STAT LIFE SCIENCES     S24        304\n     PSTAT 8  TRANS DS PROB STAT     S24         83\n    PSTAT 10  DATA SCIENCE PRINC     S24        234\n    PSTAT 99 INDEPENDENT STUDIES     S24         NA\n   PSTAT 100        DS_CONC&ANLS     S24         95\n   PSTAT 105  INTRO N-PARAM METH     S24         NA\n   PSTAT 109 STATISTICS FOR ECON     S24         NA\n   PSTAT 115 BAYES DATA ANALYSIS     S24         74\n  PSTAT 120A   PROB & STATISTICS     S24        367\n  PSTAT 120B   PROB & STATISTICS     S24        382\n  PSTAT 120C   PROB & STATISTICS     S24        131\n   PSTAT 122 DESIGN OF EXPERMNTS     S24        177\n   PSTAT 123  SAMPLING TECHNIQUE     S24         NA\n   PSTAT 126 REGRESSION ANALYSIS     S24        147\n   PSTAT 127    ADV STATS MODELS     S24         NA\n   PSTAT 130    SAS BASE PROGRAM     S24        122\n   PSTAT 131  STAT MACHINE LEARN     S24         93\n   PSTAT 132 DATABASES FOR STATS     S24         NA\n   PSTAT 134   STAT DATA SCIENCE     S24         70\n   PSTAT 135  BIG DATA ANALYTICS     S24         NA\n   PSTAT 140 STATISTICAL PROCESS     S24         NA\n  PSTAT 160A  STOCHASTIC PROCESS     S24        100\n  PSTAT 160B  STOCHASTIC PROCESS     S24        106\n   PSTAT 170  INTRO MATH FINANCE     S24        125\n   PSTAT 171   MATH COMPOUND INT     S24         84\n  PSTAT 172A    ACTUARIAL STAT I     S24         NA\n  PSTAT 172B   ACTUARIAL STAT II     S24         20\n   PSTAT 173         RISK THEORY     S24         NA\n   PSTAT 174         TIME SERIES     S24        104\n   PSTAT 175   SURVIVAL ANALYSIS     S24         55\n   PSTAT 176    ADV MATH FINANCE     S24         15\n   PSTAT 177      FINANCIAL RISK     S24         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     S24         17\n   PSTAT 183  ACTUARIAL CONCEPTS     S24         44\n   PSTAT 190        ULA TRAINING     S24         NA\n   PSTAT 191       ULA PRACTICUM     S24         NA\n   PSTAT 193 INTERNSHIP IN STATS     S24          6\n   PSTAT 194  GRP STDY ADV STDNT     S24         29\n   PSTAT 195      SPECIAL TOPICS     S24         NA\n   PSTAT 196   RESEARCH IN ACTSC     S24         NA\n  PSTAT 197A    DS CAPSTONE PREP     S24         NA\n  PSTAT 197B DS CAPSTONE PROJECT     S24         NA\n  PSTAT 197C DS CAPSTONE PROJECT     S24         53\n   PSTAT 199 INDEPENDENT STUDIES     S24         19\n PSTAT 199RA INDEP RESEARCH ASST     S24         NA\n    PSTAT 5A  UNDERSTANDING DATA     W24        283\n    PSTAT 5H          STATISTICS     W24         24\n   PSTAT 5LS  STAT LIFE SCIENCES     W24        299\n     PSTAT 8  TRANS DS PROB STAT     W24        134\n    PSTAT 10  DATA SCIENCE PRINC     W24        260\n    PSTAT 99 INDEPENDENT STUDIES     W24         NA\n   PSTAT 100        DS_CONC&ANLS     W24         NA\n   PSTAT 105  INTRO N-PARAM METH     W24         NA\n   PSTAT 109 STATISTICS FOR ECON     W24         NA\n   PSTAT 115 BAYES DATA ANALYSIS     W24         96\n  PSTAT 120A   PROB & STATISTICS     W24        372\n  PSTAT 120B   PROB & STATISTICS     W24        241\n  PSTAT 120C   PROB & STATISTICS     W24         39\n   PSTAT 122 DESIGN OF EXPERMNTS     W24        162\n   PSTAT 123  SAMPLING TECHNIQUE     W24        137\n   PSTAT 126 REGRESSION ANALYSIS     W24        200\n   PSTAT 127    ADV STATS MODELS     W24         NA\n   PSTAT 130    SAS BASE PROGRAM     W24         97\n   PSTAT 131  STAT MACHINE LEARN     W24        138\n   PSTAT 132 DATABASES FOR STATS     W24         NA\n   PSTAT 134   STAT DATA SCIENCE     W24         78\n   PSTAT 135  BIG DATA ANALYTICS     W24         99\n   PSTAT 140 STATISTICAL PROCESS     W24         NA\n  PSTAT 160A  STOCHASTIC PROCESS     W24        153\n  PSTAT 160B  STOCHASTIC PROCESS     W24         73\n   PSTAT 170  INTRO MATH FINANCE     W24         65\n   PSTAT 171   MATH COMPOUND INT     W24         68\n  PSTAT 172A    ACTUARIAL STAT I     W24         60\n  PSTAT 172B   ACTUARIAL STAT II     W24         NA\n   PSTAT 173         RISK THEORY     W24         NA\n   PSTAT 174         TIME SERIES     W24         63\n   PSTAT 175   SURVIVAL ANALYSIS     W24         NA\n   PSTAT 176    ADV MATH FINANCE     W24         NA\n   PSTAT 177      FINANCIAL RISK     W24         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     W24          6\n   PSTAT 183  ACTUARIAL CONCEPTS     W24         NA\n   PSTAT 190        ULA TRAINING     W24         NA\n   PSTAT 191       ULA PRACTICUM     W24         NA\n   PSTAT 193 INTERNSHIP IN STATS     W24          4\n   PSTAT 194  GRP STDY ADV STDNT     W24         NA\n   PSTAT 195      SPECIAL TOPICS     W24         NA\n   PSTAT 196   RESEARCH IN ACTSC     W24         NA\n  PSTAT 197A    DS CAPSTONE PREP     W24         NA\n  PSTAT 197B DS CAPSTONE PROJECT     W24         56\n  PSTAT 197C DS CAPSTONE PROJECT     W24         NA\n   PSTAT 199 INDEPENDENT STUDIES     W24         17\n PSTAT 199RA INDEP RESEARCH ASST     W24         NA\n    PSTAT 5A  UNDERSTANDING DATA     F23        549\n    PSTAT 5H          STATISTICS     F23         25\n   PSTAT 5LS  STAT LIFE SCIENCES     F23         NA\n     PSTAT 8  TRANS DS PROB STAT     F23        132\n    PSTAT 10  DATA SCIENCE PRINC     F23        285\n    PSTAT 99 INDEPENDENT STUDIES     F23         NA\n   PSTAT 100        DS_CONC&ANLS     F23        104\n   PSTAT 105  INTRO N-PARAM METH     F23         39\n   PSTAT 109 STATISTICS FOR ECON     F23         NA\n   PSTAT 115 BAYES DATA ANALYSIS     F23         16\n  PSTAT 120A   PROB & STATISTICS     F23        419\n  PSTAT 120B   PROB & STATISTICS     F23        261\n  PSTAT 120C   PROB & STATISTICS     F23         19\n   PSTAT 122 DESIGN OF EXPERMNTS     F23        167\n   PSTAT 123  SAMPLING TECHNIQUE     F23         NA\n   PSTAT 126 REGRESSION ANALYSIS     F23        123\n   PSTAT 127    ADV STATS MODELS     F23         57\n   PSTAT 130    SAS BASE PROGRAM     F23        120\n   PSTAT 131  STAT MACHINE LEARN     F23        150\n   PSTAT 132 DATABASES FOR STATS     F23         NA\n   PSTAT 134   STAT DATA SCIENCE     F23         80\n   PSTAT 135  BIG DATA ANALYTICS     F23         NA\n   PSTAT 140 STATISTICAL PROCESS     F23         NA\n  PSTAT 160A  STOCHASTIC PROCESS     F23        132\n  PSTAT 160B  STOCHASTIC PROCESS     F23         43\n   PSTAT 170  INTRO MATH FINANCE     F23         59\n   PSTAT 171   MATH COMPOUND INT     F23        102\n  PSTAT 172A    ACTUARIAL STAT I     F23         NA\n  PSTAT 172B   ACTUARIAL STAT II     F23         NA\n   PSTAT 173         RISK THEORY     F23         35\n   PSTAT 174         TIME SERIES     F23         NA\n   PSTAT 175   SURVIVAL ANALYSIS     F23         18\n   PSTAT 176    ADV MATH FINANCE     F23         NA\n   PSTAT 177      FINANCIAL RISK     F23         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     F23          4\n   PSTAT 183  ACTUARIAL CONCEPTS     F23         NA\n   PSTAT 190        ULA TRAINING     F23          5\n   PSTAT 191       ULA PRACTICUM     F23         NA\n   PSTAT 193 INTERNSHIP IN STATS     F23          8\n   PSTAT 194  GRP STDY ADV STDNT     F23         NA\n   PSTAT 195      SPECIAL TOPICS     F23         NA\n   PSTAT 196   RESEARCH IN ACTSC     F23         NA\n  PSTAT 197A    DS CAPSTONE PREP     F23         58\n  PSTAT 197B DS CAPSTONE PROJECT     F23         NA\n  PSTAT 197C DS CAPSTONE PROJECT     F23         NA\n   PSTAT 199 INDEPENDENT STUDIES     F23         23\n PSTAT 199RA INDEP RESEARCH ASST     F23         NA\n    PSTAT 5A  UNDERSTANDING DATA     M23        110\n    PSTAT 5H          STATISTICS     M23         NA\n   PSTAT 5LS  STAT LIFE SCIENCES     M23         39\n     PSTAT 8  TRANS DS PROB STAT     M23         18\n    PSTAT 10  DATA SCIENCE PRINC     M23         83\n    PSTAT 99 INDEPENDENT STUDIES     M23         NA\n   PSTAT 100        DS_CONC&ANLS     M23         48\n   PSTAT 105  INTRO N-PARAM METH     M23         NA\n   PSTAT 109 STATISTICS FOR ECON     M23         NA\n   PSTAT 115 BAYES DATA ANALYSIS     M23         15\n  PSTAT 120A   PROB & STATISTICS     M23         86\n  PSTAT 120B   PROB & STATISTICS     M23        102\n  PSTAT 120C   PROB & STATISTICS     M23         81\n   PSTAT 122 DESIGN OF EXPERMNTS     M23         NA\n   PSTAT 123  SAMPLING TECHNIQUE     M23         NA\n   PSTAT 126 REGRESSION ANALYSIS     M23         84\n   PSTAT 127    ADV STATS MODELS     M23         NA\n   PSTAT 130    SAS BASE PROGRAM     M23         95\n   PSTAT 131  STAT MACHINE LEARN     M23         55\n   PSTAT 132 DATABASES FOR STATS     M23         NA\n   PSTAT 134   STAT DATA SCIENCE     M23         NA\n   PSTAT 135  BIG DATA ANALYTICS     M23         NA\n   PSTAT 140 STATISTICAL PROCESS     M23         NA\n  PSTAT 160A  STOCHASTIC PROCESS     M23         NA\n  PSTAT 160B  STOCHASTIC PROCESS     M23          7\n   PSTAT 170  INTRO MATH FINANCE     M23         17\n   PSTAT 171   MATH COMPOUND INT     M23         32\n  PSTAT 172A    ACTUARIAL STAT I     M23         NA\n  PSTAT 172B   ACTUARIAL STAT II     M23         NA\n   PSTAT 173         RISK THEORY     M23         NA\n   PSTAT 174         TIME SERIES     M23         NA\n   PSTAT 175   SURVIVAL ANALYSIS     M23         NA\n   PSTAT 176    ADV MATH FINANCE     M23         NA\n   PSTAT 177      FINANCIAL RISK     M23         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     M23         NA\n   PSTAT 183  ACTUARIAL CONCEPTS     M23         NA\n   PSTAT 190        ULA TRAINING     M23         NA\n   PSTAT 191       ULA PRACTICUM     M23         NA\n   PSTAT 193 INTERNSHIP IN STATS     M23         20\n   PSTAT 194  GRP STDY ADV STDNT     M23         NA\n   PSTAT 195      SPECIAL TOPICS     M23         NA\n   PSTAT 196   RESEARCH IN ACTSC     M23         NA\n  PSTAT 197A    DS CAPSTONE PREP     M23         NA\n  PSTAT 197B DS CAPSTONE PROJECT     M23         NA\n  PSTAT 197C DS CAPSTONE PROJECT     M23         NA\n   PSTAT 199 INDEPENDENT STUDIES     M23          6\n PSTAT 199RA INDEP RESEARCH ASST     M23         NA\n    PSTAT 5A  UNDERSTANDING DATA     S23        212\n    PSTAT 5H          STATISTICS     S23         31\n   PSTAT 5LS  STAT LIFE SCIENCES     S23        299\n     PSTAT 8  TRANS DS PROB STAT     S23         86\n    PSTAT 10  DATA SCIENCE PRINC     S23        240\n    PSTAT 99 INDEPENDENT STUDIES     S23         NA\n   PSTAT 100        DS_CONC&ANLS     S23        125\n   PSTAT 105  INTRO N-PARAM METH     S23         NA\n   PSTAT 109 STATISTICS FOR ECON     S23         NA\n   PSTAT 115 BAYES DATA ANALYSIS     S23         38\n  PSTAT 120A   PROB & STATISTICS     S23        237\n  PSTAT 120B   PROB & STATISTICS     S23        256\n  PSTAT 120C   PROB & STATISTICS     S23         65\n   PSTAT 122 DESIGN OF EXPERMNTS     S23        194\n   PSTAT 123  SAMPLING TECHNIQUE     S23         NA\n   PSTAT 126 REGRESSION ANALYSIS     S23        149\n   PSTAT 127    ADV STATS MODELS     S23         NA\n   PSTAT 130    SAS BASE PROGRAM     S23        119\n   PSTAT 131  STAT MACHINE LEARN     S23        108\n   PSTAT 132 DATABASES FOR STATS     S23         NA\n   PSTAT 134   STAT DATA SCIENCE     S23         87\n   PSTAT 135  BIG DATA ANALYTICS     S23         NA\n   PSTAT 140 STATISTICAL PROCESS     S23         NA\n  PSTAT 160A  STOCHASTIC PROCESS     S23        108\n  PSTAT 160B  STOCHASTIC PROCESS     S23         82\n   PSTAT 170  INTRO MATH FINANCE     S23         77\n   PSTAT 171   MATH COMPOUND INT     S23         64\n  PSTAT 172A    ACTUARIAL STAT I     S23         NA\n  PSTAT 172B   ACTUARIAL STAT II     S23         23\n   PSTAT 173         RISK THEORY     S23         NA\n   PSTAT 174         TIME SERIES     S23        170\n   PSTAT 175   SURVIVAL ANALYSIS     S23         NA\n   PSTAT 176    ADV MATH FINANCE     S23         13\n   PSTAT 177      FINANCIAL RISK     S23         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     S23          6\n   PSTAT 183  ACTUARIAL CONCEPTS     S23         46\n   PSTAT 190        ULA TRAINING     S23         NA\n   PSTAT 191       ULA PRACTICUM     S23         NA\n   PSTAT 193 INTERNSHIP IN STATS     S23          6\n   PSTAT 194  GRP STDY ADV STDNT     S23         28\n   PSTAT 195      SPECIAL TOPICS     S23         NA\n   PSTAT 196   RESEARCH IN ACTSC     S23         NA\n  PSTAT 197A    DS CAPSTONE PREP     S23         NA\n  PSTAT 197B DS CAPSTONE PROJECT     S23         NA\n  PSTAT 197C DS CAPSTONE PROJECT     S23         46\n   PSTAT 199 INDEPENDENT STUDIES     S23         21\n PSTAT 199RA INDEP RESEARCH ASST     S23         NA\n    PSTAT 5A  UNDERSTANDING DATA     W23        279\n    PSTAT 5H          STATISTICS     W23         22\n   PSTAT 5LS  STAT LIFE SCIENCES     W23        294\n     PSTAT 8  TRANS DS PROB STAT     W23        156\n    PSTAT 10  DATA SCIENCE PRINC     W23        282\n    PSTAT 99 INDEPENDENT STUDIES     W23         NA\n   PSTAT 100        DS_CONC&ANLS     W23        127\n   PSTAT 105  INTRO N-PARAM METH     W23         NA\n   PSTAT 109 STATISTICS FOR ECON     W23         NA\n   PSTAT 115 BAYES DATA ANALYSIS     W23         70\n  PSTAT 120A   PROB & STATISTICS     W23        246\n  PSTAT 120B   PROB & STATISTICS     W23        256\n  PSTAT 120C   PROB & STATISTICS     W23         31\n   PSTAT 122 DESIGN OF EXPERMNTS     W23        187\n   PSTAT 123  SAMPLING TECHNIQUE     W23         NA\n   PSTAT 126 REGRESSION ANALYSIS     W23        175\n   PSTAT 127    ADV STATS MODELS     W23         73\n   PSTAT 130    SAS BASE PROGRAM     W23         98\n   PSTAT 131  STAT MACHINE LEARN     W23        197\n   PSTAT 132 DATABASES FOR STATS     W23         NA\n   PSTAT 134   STAT DATA SCIENCE     W23         42\n   PSTAT 135  BIG DATA ANALYTICS     W23         93\n   PSTAT 140 STATISTICAL PROCESS     W23         NA\n  PSTAT 160A  STOCHASTIC PROCESS     W23        161\n  PSTAT 160B  STOCHASTIC PROCESS     W23         81\n   PSTAT 170  INTRO MATH FINANCE     W23         57\n   PSTAT 171   MATH COMPOUND INT     W23         69\n  PSTAT 172A    ACTUARIAL STAT I     W23         43\n  PSTAT 172B   ACTUARIAL STAT II     W23         NA\n   PSTAT 173         RISK THEORY     W23         NA\n   PSTAT 174         TIME SERIES     W23        118\n   PSTAT 175   SURVIVAL ANALYSIS     W23         NA\n   PSTAT 176    ADV MATH FINANCE     W23         NA\n   PSTAT 177      FINANCIAL RISK     W23         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     W23          4\n   PSTAT 183  ACTUARIAL CONCEPTS     W23         NA\n   PSTAT 190        ULA TRAINING     W23         NA\n   PSTAT 191       ULA PRACTICUM     W23         NA\n   PSTAT 193 INTERNSHIP IN STATS     W23          3\n   PSTAT 194  GRP STDY ADV STDNT     W23         NA\n   PSTAT 195      SPECIAL TOPICS     W23         NA\n   PSTAT 196   RESEARCH IN ACTSC     W23         NA\n  PSTAT 197A    DS CAPSTONE PREP     W23         NA\n  PSTAT 197B DS CAPSTONE PROJECT     W23         53\n  PSTAT 197C DS CAPSTONE PROJECT     W23         NA\n   PSTAT 199 INDEPENDENT STUDIES     W23         17\n PSTAT 199RA INDEP RESEARCH ASST     W23         NA\n    PSTAT 5A  UNDERSTANDING DATA     F22        499\n    PSTAT 5H          STATISTICS     F22          4\n   PSTAT 5LS  STAT LIFE SCIENCES     F22         NA\n     PSTAT 8  TRANS DS PROB STAT     F22         70\n    PSTAT 10  DATA SCIENCE PRINC     F22        257\n    PSTAT 99 INDEPENDENT STUDIES     F22         NA\n   PSTAT 100        DS_CONC&ANLS     F22         NA\n   PSTAT 105  INTRO N-PARAM METH     F22         79\n   PSTAT 109 STATISTICS FOR ECON     F22         NA\n   PSTAT 115 BAYES DATA ANALYSIS     F22         63\n  PSTAT 120A   PROB & STATISTICS     F22        419\n  PSTAT 120B   PROB & STATISTICS     F22        165\n  PSTAT 120C   PROB & STATISTICS     F22         87\n   PSTAT 122 DESIGN OF EXPERMNTS     F22        182\n   PSTAT 123  SAMPLING TECHNIQUE     F22         NA\n   PSTAT 126 REGRESSION ANALYSIS     F22        182\n   PSTAT 127    ADV STATS MODELS     F22         NA\n   PSTAT 130    SAS BASE PROGRAM     F22         97\n   PSTAT 131  STAT MACHINE LEARN     F22        178\n   PSTAT 132 DATABASES FOR STATS     F22         NA\n   PSTAT 134   STAT DATA SCIENCE     F22         33\n   PSTAT 135  BIG DATA ANALYTICS     F22         NA\n   PSTAT 140 STATISTICAL PROCESS     F22         NA\n  PSTAT 160A  STOCHASTIC PROCESS     F22        184\n  PSTAT 160B  STOCHASTIC PROCESS     F22         58\n   PSTAT 170  INTRO MATH FINANCE     F22         55\n   PSTAT 171   MATH COMPOUND INT     F22        108\n  PSTAT 172A    ACTUARIAL STAT I     F22         NA\n  PSTAT 172B   ACTUARIAL STAT II     F22         NA\n   PSTAT 173         RISK THEORY     F22         43\n   PSTAT 174         TIME SERIES     F22         69\n   PSTAT 175   SURVIVAL ANALYSIS     F22         73\n   PSTAT 176    ADV MATH FINANCE     F22         NA\n   PSTAT 177      FINANCIAL RISK     F22         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     F22          7\n   PSTAT 183  ACTUARIAL CONCEPTS     F22         NA\n   PSTAT 190        ULA TRAINING     F22         20\n   PSTAT 191       ULA PRACTICUM     F22         NA\n   PSTAT 193 INTERNSHIP IN STATS     F22          2\n   PSTAT 194  GRP STDY ADV STDNT     F22         NA\n   PSTAT 195      SPECIAL TOPICS     F22         NA\n   PSTAT 196   RESEARCH IN ACTSC     F22         NA\n  PSTAT 197A    DS CAPSTONE PREP     F22         59\n  PSTAT 197B DS CAPSTONE PROJECT     F22         NA\n  PSTAT 197C DS CAPSTONE PROJECT     F22         NA\n   PSTAT 199 INDEPENDENT STUDIES     F22         21\n PSTAT 199RA INDEP RESEARCH ASST     F22         NA\n    PSTAT 5A  UNDERSTANDING DATA     M22        116\n    PSTAT 5H          STATISTICS     M22         NA\n   PSTAT 5LS  STAT LIFE SCIENCES     M22         63\n     PSTAT 8  TRANS DS PROB STAT     M22         23\n    PSTAT 10  DATA SCIENCE PRINC     M22         87\n    PSTAT 99 INDEPENDENT STUDIES     M22         NA\n   PSTAT 100        DS_CONC&ANLS     M22         NA\n   PSTAT 105  INTRO N-PARAM METH     M22         NA\n   PSTAT 109 STATISTICS FOR ECON     M22         NA\n   PSTAT 115 BAYES DATA ANALYSIS     M22         NA\n  PSTAT 120A   PROB & STATISTICS     M22         65\n  PSTAT 120B   PROB & STATISTICS     M22        174\n  PSTAT 120C   PROB & STATISTICS     M22        109\n   PSTAT 122 DESIGN OF EXPERMNTS     M22         NA\n   PSTAT 123  SAMPLING TECHNIQUE     M22         NA\n   PSTAT 126 REGRESSION ANALYSIS     M22         67\n   PSTAT 127    ADV STATS MODELS     M22         NA\n   PSTAT 130    SAS BASE PROGRAM     M22        138\n   PSTAT 131  STAT MACHINE LEARN     M22         NA\n   PSTAT 132 DATABASES FOR STATS     M22         NA\n   PSTAT 134   STAT DATA SCIENCE     M22         22\n   PSTAT 135  BIG DATA ANALYTICS     M22         NA\n   PSTAT 140 STATISTICAL PROCESS     M22         NA\n  PSTAT 160A  STOCHASTIC PROCESS     M22         51\n  PSTAT 160B  STOCHASTIC PROCESS     M22         54\n   PSTAT 170  INTRO MATH FINANCE     M22         41\n   PSTAT 171   MATH COMPOUND INT     M22         49\n  PSTAT 172A    ACTUARIAL STAT I     M22         NA\n  PSTAT 172B   ACTUARIAL STAT II     M22         NA\n   PSTAT 173         RISK THEORY     M22         NA\n   PSTAT 174         TIME SERIES     M22         NA\n   PSTAT 175   SURVIVAL ANALYSIS     M22         NA\n   PSTAT 176    ADV MATH FINANCE     M22         NA\n   PSTAT 177      FINANCIAL RISK     M22         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     M22         NA\n   PSTAT 183  ACTUARIAL CONCEPTS     M22         NA\n   PSTAT 190        ULA TRAINING     M22         NA\n   PSTAT 191       ULA PRACTICUM     M22         NA\n   PSTAT 193 INTERNSHIP IN STATS     M22         35\n   PSTAT 194  GRP STDY ADV STDNT     M22         NA\n   PSTAT 195      SPECIAL TOPICS     M22         NA\n   PSTAT 196   RESEARCH IN ACTSC     M22         NA\n  PSTAT 197A    DS CAPSTONE PREP     M22         NA\n  PSTAT 197B DS CAPSTONE PROJECT     M22         NA\n  PSTAT 197C DS CAPSTONE PROJECT     M22         NA\n   PSTAT 199 INDEPENDENT STUDIES     M22         10\n PSTAT 199RA INDEP RESEARCH ASST     M22         NA\n    PSTAT 5A  UNDERSTANDING DATA     S22        194\n    PSTAT 5H          STATISTICS     S22         NA\n   PSTAT 5LS  STAT LIFE SCIENCES     S22        294\n     PSTAT 8  TRANS DS PROB STAT     S22         59\n    PSTAT 10  DATA SCIENCE PRINC     S22        278\n    PSTAT 99 INDEPENDENT STUDIES     S22         NA\n   PSTAT 100        DS_CONC&ANLS     S22         95\n   PSTAT 105  INTRO N-PARAM METH     S22         NA\n   PSTAT 109 STATISTICS FOR ECON     S22         NA\n   PSTAT 115 BAYES DATA ANALYSIS     S22         NA\n  PSTAT 120A   PROB & STATISTICS     S22        244\n  PSTAT 120B   PROB & STATISTICS     S22        216\n  PSTAT 120C   PROB & STATISTICS     S22        119\n   PSTAT 122 DESIGN OF EXPERMNTS     S22        137\n   PSTAT 123  SAMPLING TECHNIQUE     S22         NA\n   PSTAT 126 REGRESSION ANALYSIS     S22        250\n   PSTAT 127    ADV STATS MODELS     S22         78\n   PSTAT 130    SAS BASE PROGRAM     S22        122\n   PSTAT 131  STAT MACHINE LEARN     S22         75\n   PSTAT 132 DATABASES FOR STATS     S22         NA\n   PSTAT 134   STAT DATA SCIENCE     S22         NA\n   PSTAT 135  BIG DATA ANALYTICS     S22         NA\n   PSTAT 140 STATISTICAL PROCESS     S22         NA\n  PSTAT 160A  STOCHASTIC PROCESS     S22        130\n  PSTAT 160B  STOCHASTIC PROCESS     S22        109\n   PSTAT 170  INTRO MATH FINANCE     S22         74\n   PSTAT 171   MATH COMPOUND INT     S22         70\n  PSTAT 172A    ACTUARIAL STAT I     S22         NA\n  PSTAT 172B   ACTUARIAL STAT II     S22         26\n   PSTAT 173         RISK THEORY     S22         NA\n   PSTAT 174         TIME SERIES     S22         61\n   PSTAT 175   SURVIVAL ANALYSIS     S22         NA\n   PSTAT 176    ADV MATH FINANCE     S22         15\n   PSTAT 177      FINANCIAL RISK     S22         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     S22         12\n   PSTAT 183  ACTUARIAL CONCEPTS     S22         68\n   PSTAT 190        ULA TRAINING     S22         NA\n   PSTAT 191       ULA PRACTICUM     S22         NA\n   PSTAT 193 INTERNSHIP IN STATS     S22          5\n   PSTAT 194  GRP STDY ADV STDNT     S22         66\n   PSTAT 195      SPECIAL TOPICS     S22         NA\n   PSTAT 196   RESEARCH IN ACTSC     S22         NA\n  PSTAT 197A    DS CAPSTONE PREP     S22         NA\n  PSTAT 197B DS CAPSTONE PROJECT     S22         NA\n  PSTAT 197C DS CAPSTONE PROJECT     S22         47\n   PSTAT 199 INDEPENDENT STUDIES     S22         19\n PSTAT 199RA INDEP RESEARCH ASST     S22         NA\n    PSTAT 5A  UNDERSTANDING DATA     W22        278\n    PSTAT 5H          STATISTICS     W22         NA\n   PSTAT 5LS  STAT LIFE SCIENCES     W22        284\n     PSTAT 8  TRANS DS PROB STAT     W22         NA\n    PSTAT 10  DATA SCIENCE PRINC     W22        287\n    PSTAT 99 INDEPENDENT STUDIES     W22         NA\n   PSTAT 100        DS_CONC&ANLS     W22         88\n   PSTAT 105  INTRO N-PARAM METH     W22         93\n   PSTAT 109 STATISTICS FOR ECON     W22         NA\n   PSTAT 115 BAYES DATA ANALYSIS     W22         81\n  PSTAT 120A   PROB & STATISTICS     W22        229\n  PSTAT 120B   PROB & STATISTICS     W22        241\n  PSTAT 120C   PROB & STATISTICS     W22         NA\n   PSTAT 122 DESIGN OF EXPERMNTS     W22        119\n   PSTAT 123  SAMPLING TECHNIQUE     W22         NA\n   PSTAT 126 REGRESSION ANALYSIS     W22        123\n   PSTAT 127    ADV STATS MODELS     W22         91\n   PSTAT 130    SAS BASE PROGRAM     W22         98\n   PSTAT 131  STAT MACHINE LEARN     W22         76\n   PSTAT 132 DATABASES FOR STATS     W22         NA\n   PSTAT 134   STAT DATA SCIENCE     W22         66\n   PSTAT 135  BIG DATA ANALYTICS     W22         NA\n   PSTAT 140 STATISTICAL PROCESS     W22         NA\n  PSTAT 160A  STOCHASTIC PROCESS     W22         77\n  PSTAT 160B  STOCHASTIC PROCESS     W22         72\n   PSTAT 170  INTRO MATH FINANCE     W22         69\n   PSTAT 171   MATH COMPOUND INT     W22         68\n  PSTAT 172A    ACTUARIAL STAT I     W22         60\n  PSTAT 172B   ACTUARIAL STAT II     W22         NA\n   PSTAT 173         RISK THEORY     W22         50\n   PSTAT 174         TIME SERIES     W22         74\n   PSTAT 175   SURVIVAL ANALYSIS     W22         NA\n   PSTAT 176    ADV MATH FINANCE     W22         NA\n   PSTAT 177      FINANCIAL RISK     W22         NA\n  PSTAT 182T  ACTUARIAL TUTORIAL     W22          5\n   PSTAT 183  ACTUARIAL CONCEPTS     W22         NA\n   PSTAT 190        ULA TRAINING     W22         NA\n   PSTAT 191       ULA PRACTICUM     W22         NA\n   PSTAT 193 INTERNSHIP IN STATS     W22          4\n   PSTAT 194  GRP STDY ADV STDNT     W22         NA\n   PSTAT 195      SPECIAL TOPICS     W22         NA\n   PSTAT 196   RESEARCH IN ACTSC     W22         NA\n  PSTAT 197A    DS CAPSTONE PREP     W22         NA\n  PSTAT 197B DS CAPSTONE PROJECT     W22         46\n  PSTAT 197C DS CAPSTONE PROJECT     W22         NA\n   PSTAT 199 INDEPENDENT STUDIES     W22          5\n PSTAT 199RA INDEP RESEARCH ASST     W22         NA"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#data",
    "href": "Lectures/Lec02/Lec02.html#data",
    "title": "PSTAT 100: Lecture 02",
    "section": " Data",
    "text": "Data\nStructure vs. Semantics\n\n\n\n\n\n\nRecap\n\n\nData has both semantics and structure (though when most people say “data” they are typically refering to the semantics).\n\n\n\n\nBoth the wide and long layouts of the enrollments dataset contain the semantics, but have different structures.\nLoosely speaking, the structure of a given dataset refers to the way the values in the dataset are actually displayed.\n\nSpecification of rows, columns, and number of tables (yes, sometimes we need multiple tables to express a particular dataset!)\nDecision of how to encode particular values (e.g. should we use high, medium, low, or 3, 2, 1?)"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#data-1",
    "href": "Lectures/Lec02/Lec02.html#data-1",
    "title": "PSTAT 100: Lecture 02",
    "section": " Data",
    "text": "Data\nStructure vs. Semantics\n\nThere is some variability “in the wild” when it comes to the structure of datasets, and there isn’t always a single “best” way to structure a given dataset.\nHowever, it is important to note that computer will only ever be able to understand the structure of a dataset: it can only read rows, columns, and entries.\nSo, how can we get a computer to understand the semantics of a dataset?\nIdea: use a structure that maps to the semantics in some way.\n\nIndeed, one popular framework of structuring data that achieves this is the so-called Tidy framework of data."
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#tidy-data",
    "href": "Lectures/Lec02/Lec02.html#tidy-data",
    "title": "PSTAT 100: Lecture 02",
    "section": " Tidy Data",
    "text": "Tidy Data\nDefinition\n\n\n\n\n\n\n\nDefinition\n\n\nDeveloped by Hadley Wickham, the tidy standard of data seeks to map the semantics of a dataset to its structure, by proposing a series of structural constraints:\n\nEach variable forms a column\nEach observation forms a row\nEach type of observational unit forms a table"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#tidy-or-not",
    "href": "Lectures/Lec02/Lec02.html#tidy-or-not",
    "title": "PSTAT 100: Lecture 02",
    "section": " Tidy or Not?",
    "text": "Tidy or Not?\nEnrollments: Wide Layout\n\n\n      Course               Title S25 W25 F24 M24 S24 W24 F23 M23 S23 W23 F22\n    PSTAT 5A  UNDERSTANDING DATA 167 222 213  76 258 283 549 110 212 279 499\n    PSTAT 5H          STATISTICS  11  14  30  NA  31  24  25  NA  31  22   4\n   PSTAT 5LS  STAT LIFE SCIENCES 355 340 348  59 304 299  NA  39 299 294  NA\n     PSTAT 8  TRANS DS PROB STAT  70 105 137  22  83 134 132  18  86 156  70\n    PSTAT 10  DATA SCIENCE PRINC 235 241 286  93 234 260 285  83 240 282 257\n    PSTAT 99 INDEPENDENT STUDIES   1   2  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 100        DS_CONC&ANLS 109 131 108  NA  95  NA 104  48 125 127  NA\n   PSTAT 105  INTRO N-PARAM METH  NA  79  NA  NA  NA  NA  39  NA  NA  NA  79\n   PSTAT 109 STATISTICS FOR ECON  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 115 BAYES DATA ANALYSIS  81  56  74  25  74  96  16  15  38  70  63\n  PSTAT 120A   PROB & STATISTICS 310 383 345  75 367 372 419  86 237 246 419\n  PSTAT 120B   PROB & STATISTICS 312 329 236 136 382 241 261 102 256 256 165\n  PSTAT 120C   PROB & STATISTICS 163  NA  37 129 131  39  19  81  65  31  87\n   PSTAT 122 DESIGN OF EXPERMNTS 240 210 201  NA 177 162 167  NA 194 187 182\n   PSTAT 123  SAMPLING TECHNIQUE  NA  NA  NA  NA  NA 137  NA  NA  NA  NA  NA\n   PSTAT 126 REGRESSION ANALYSIS 197 214 272  94 147 200 123  84 149 175 182\n   PSTAT 127    ADV STATS MODELS  NA  NA  72  NA  NA  NA  57  NA  NA  73  NA\n   PSTAT 130    SAS BASE PROGRAM 116 120 121 108 122  97 120  95 119  98  97\n   PSTAT 131  STAT MACHINE LEARN  96 156  64  80  93 138 150  55 108 197 178\n   PSTAT 132 DATABASES FOR STATS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 134   STAT DATA SCIENCE  46  91  78  NA  70  78  80  NA  87  42  33\n   PSTAT 135  BIG DATA ANALYTICS  96  NA  NA  NA  NA  99  NA  NA  NA  93  NA\n   PSTAT 140 STATISTICAL PROCESS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 160A  STOCHASTIC PROCESS 132 217 126  NA 100 153 132  NA 108 161 184\n  PSTAT 160B  STOCHASTIC PROCESS 116  77  86  NA 106  73  43   7  82  81  58\n   PSTAT 170  INTRO MATH FINANCE 116  65  92  19 125  65  59  17  77  57  55\n   PSTAT 171   MATH COMPOUND INT  73  77  96  47  84  68 102  32  64  69 108\n  PSTAT 172A    ACTUARIAL STAT I  NA  49  NA  NA  NA  60  NA  NA  NA  43  NA\n  PSTAT 172B   ACTUARIAL STAT II  14  NA  NA  NA  20  NA  NA  NA  23  NA  NA\n   PSTAT 173         RISK THEORY  NA  NA  64  NA  NA  NA  35  NA  NA  NA  43\n   PSTAT 174         TIME SERIES  NA  89  83  NA 104  63  NA  NA 170 118  69\n   PSTAT 175   SURVIVAL ANALYSIS  71  NA  NA  NA  55  NA  18  NA  NA  NA  73\n   PSTAT 176    ADV MATH FINANCE  17  NA  NA  NA  15  NA  NA  NA  13  NA  NA\n   PSTAT 177      FINANCIAL RISK  31  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 182T  ACTUARIAL TUTORIAL  12  20  15  NA  17   6   4  NA   6   4   7\n   PSTAT 183  ACTUARIAL CONCEPTS  28  NA  NA  NA  44  NA  NA  NA  46  NA  NA\n   PSTAT 190        ULA TRAINING  NA  NA  14  NA  NA  NA   5  NA  NA  NA  20\n   PSTAT 191       ULA PRACTICUM  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 193 INTERNSHIP IN STATS   4   3   4  28   6   4   8  20   6   3   2\n   PSTAT 194  GRP STDY ADV STDNT  NA  NA  NA  11  29  NA  NA  NA  28  NA  NA\n   PSTAT 195      SPECIAL TOPICS  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n   PSTAT 196   RESEARCH IN ACTSC  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n  PSTAT 197A    DS CAPSTONE PREP  NA  NA  59  NA  NA  NA  58  NA  NA  NA  59\n  PSTAT 197B DS CAPSTONE PROJECT  NA  58  NA  NA  NA  56  NA  NA  NA  53  NA\n  PSTAT 197C DS CAPSTONE PROJECT  52  NA  NA  NA  53  NA  NA  NA  46  NA  NA\n   PSTAT 199 INDEPENDENT STUDIES  23  22  18   6  19  17  23   6  21  17  21\n PSTAT 199RA INDEP RESEARCH ASST  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA  NA\n M22 S22 W22\n 116 194 278\n  NA  NA  NA\n  63 294 284\n  23  59  NA\n  87 278 287\n  NA  NA  NA\n  NA  95  88\n  NA  NA  93\n  NA  NA  NA\n  NA  NA  81\n  65 244 229\n 174 216 241\n 109 119  NA\n  NA 137 119\n  NA  NA  NA\n  67 250 123\n  NA  78  91\n 138 122  98\n  NA  75  76\n  NA  NA  NA\n  22  NA  66\n  NA  NA  NA\n  NA  NA  NA\n  51 130  77\n  54 109  72\n  41  74  69\n  49  70  68\n  NA  NA  60\n  NA  26  NA\n  NA  NA  50\n  NA  61  74\n  NA  NA  NA\n  NA  15  NA\n  NA  NA  NA\n  NA  12   5\n  NA  68  NA\n  NA  NA  NA\n  NA  NA  NA\n  35   5   4\n  NA  66  NA\n  NA  NA  NA\n  NA  NA  NA\n  NA  NA  NA\n  NA  NA  46\n  NA  47  NA\n  10  19   5\n  NA  NA  NA\n\n\n\n\n\n\n\n\nSemantics\n\n\n\n\n\n\n\nObservations:\nEnrollment in a Course in a given Quarter\n\n\nVariables:\nCourse number, title, quarter, and enrollment count\n\n\nObservational Units:\n(UCSB PSTAT Undergrad) Courses\n\n\n\n\n\n\nStructure\n\n\n\nRows:\nCourse-by-Course Records\n\n\nColumns:\nValue of Quarter\n\n\n# of Tables:\n1\n\n\n\n\n\nRules 1 and 2 violated; not tidy"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#tidy-or-not-1",
    "href": "Lectures/Lec02/Lec02.html#tidy-or-not-1",
    "title": "PSTAT 100: Lecture 02",
    "section": " Tidy or Not?",
    "text": "Tidy or Not?\nEnrollments: Long Layout\n\n\n    Course              Title Quarter Enrollment\n  PSTAT 5A UNDERSTANDING DATA     S25        167\n  PSTAT 5H         STATISTICS     S25         11\n PSTAT 5LS STAT LIFE SCIENCES     S25        355\n\n\n\n\n\nSemantics\n\n\n\n\n\n\n\nObservations:\nEnrollment in a Course in a given Quarter\n\n\nVariables:\nCourse number, title, quarter, and enrollment count\n\n\nObservational Units:\n(UCSB PSTAT Undergrad) Courses\n\n\n\n\n\n\nStructure\n\n\n\nRows:\nEnrollment in a Course in a given Quarter\n\n\nColumns:\nCourse number, title, quarter, and enrollment count\n\n\n# of Tables:\n1\n\n\n\n\n\nAll rules satisfied; tidy"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#tidy-or-not-2",
    "href": "Lectures/Lec02/Lec02.html#tidy-or-not-2",
    "title": "PSTAT 100: Lecture 02",
    "section": " Tidy or Not?",
    "text": "Tidy or Not?\nA Brief Interlude\n\nBefore we proceed, I’d like to admit that there’s some subjectivity going on behind the scenes.\nFor example, you might ask: with regards to the enrollments dataset, what if we adopted the following variables:\n\nCourse\nTitle\nSpring 2025 Enrollment\nWinter 2025 Enrollment\nEtc.\n\nNow the wide layout becomes tidy - what’s going on?!"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#tidy-or-not-3",
    "href": "Lectures/Lec02/Lec02.html#tidy-or-not-3",
    "title": "PSTAT 100: Lecture 02",
    "section": " Tidy or Not?",
    "text": "Tidy or Not?\nA Brief Interlude\n\nFirstly, I’ll stress this again: I view the main point of the tidy framework as a way to link the semantics and the structure of a dataset.\nFrom that point of view, there is nothing inherently “incorrect” about modifying our variables and observations as we did on the previous slide to make the wide layout tidy.\nHowever, I believe it “puts the cart before the horse” - in the field, we typically start with the semantics, and then structure the data around the semantics. Changing the semantics to match the structure (though not incorrect) is a little backwards."
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#tidy-or-not-4",
    "href": "Lectures/Lec02/Lec02.html#tidy-or-not-4",
    "title": "PSTAT 100: Lecture 02",
    "section": " Tidy or Not?",
    "text": "Tidy or Not?\nA Brief Interlude\n\nThere’s another reason adopting these second set of variables is not the best idea, and it has to do with the notion of updating a data frame.\nSuppose we gain additional data, from Summer 2025.\n\nIn the second set of semantics, we’d have to add an entirely new variable to incorporate this new information.\nIn the first set of semantics (where we simply have a Quarter variable and an Enrollment variable), we can update out dataset by simply adding a new observation (which is much more efficient.)\n\n\n\n\n“[…] it is surprisingly difficult to precisely define variables and observations in general.” – Wickham, 2004; page 4"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#tidy-data-1",
    "href": "Lectures/Lec02/Lec02.html#tidy-data-1",
    "title": "PSTAT 100: Lecture 02",
    "section": " Tidy Data",
    "text": "Tidy Data\nPros and Cons\n\nSo, yes, there is some subjectivity regarding what we classify as variables.\n\nBut, to reiterate a point from yesterday: a data dictionary often takes the guesswork out of things.\n\nFinally, I’d like to make another note: messy (the opposite of tidy) datasets sometimes have their benefits!\nFor example, messy datasets can actually appear (visually) more succinct than their tidy counterparts, which is why you’ll sometimes see messy datasets presented in reports or presentations.\nBut, tidy data is usually preferred in the analysis stage of the DSL, as computers are a bit better-equipped at handling tidy data than they are at handling messy data."
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#tidy-data-2",
    "href": "Lectures/Lec02/Lec02.html#tidy-data-2",
    "title": "PSTAT 100: Lecture 02",
    "section": " Tidy Data",
    "text": "Tidy Data\nExample: Blood Pressures\nData Description: The systolic and diastolic blood pressures of 3 individuals was recorded.\n\nData Dictionary:DataTidy Constraints\n\n\n\n\nName: Name of the individual\nSystolic BP: Systolic blood pressure (in mm HG)\nDiastolic BP: Systolic blood pressure (in mm HG)\n\n\n\n\n\n\n\nName\nType\nMeasurement\n\n\n\n\nAnurag\nSystolic\n100\n\n\nAnurag\nDiastolic\n70\n\n\nBiyonka\nSystolic\n101\n\n\nBiyonka\nDiastolic\n72\n\n\nChae\nSystolic\n99\n\n\nChae\nDiastolic\n68\n\n\n\n\n\n\n\nEach variable forms a column\nEach observation forms a row\nEach type of observational unit forms a table\n\n\nBased on the provided data dictionary, is this data frame tidy?"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#interlude",
    "href": "Lectures/Lec02/Lec02.html#interlude",
    "title": "PSTAT 100: Lecture 02",
    "section": " Interlude",
    "text": "Interlude\nLine Plots\n\nI’d like to motivate our discussion on tidying data by way of statistical visualizations\n\nWe’ll talk more about these next lecture.\n\nFor now, I’d like to introduce the notion of a line plot, which is a common plot used to display the change in a numerical quantity over time.\n\nTime is represented on the horizontal axis, and the quantity in question is displayed on the vertical axis."
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#interlude-1",
    "href": "Lectures/Lec02/Lec02.html#interlude-1",
    "title": "PSTAT 100: Lecture 02",
    "section": " Interlude",
    "text": "Interlude\nLine Plots\n\nSource: Google Trends"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#interlude-2",
    "href": "Lectures/Lec02/Lec02.html#interlude-2",
    "title": "PSTAT 100: Lecture 02",
    "section": " Interlude",
    "text": "Interlude\nLine Plots\n\nSource"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#line-plot",
    "href": "Lectures/Lec02/Lec02.html#line-plot",
    "title": "PSTAT 100: Lecture 02",
    "section": " Line Plot",
    "text": "Line Plot\nEnrollments Over Time\n\nLet’s say we want to make a line graph, plotting how the different courses’ enrollments changed over time (perhaps even using colors to separate the different courses).\n\n\n\n\n    Course              Title S25 W25 F24 M24 S24 W24 F23 M23 S23 W23 F22 M22\n  PSTAT 5A UNDERSTANDING DATA 167 222 213  76 258 283 549 110 212 279 499 116\n  PSTAT 5H         STATISTICS  11  14  30  NA  31  24  25  NA  31  22   4  NA\n PSTAT 5LS STAT LIFE SCIENCES 355 340 348  59 304 299  NA  39 299 294  NA  63\n   PSTAT 8 TRANS DS PROB STAT  70 105 137  22  83 134 132  18  86 156  70  23\n S22 W22\n 194 278\n  NA  NA\n 294 284\n  59  NA\n [ reached 'max' / getOption(\"max.print\") -- omitted 43 rows ]\n\n\n\n\nHow do we tell R what to put on the x-axis, when the “time” values are embedded as column headers?"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#line-plot-1",
    "href": "Lectures/Lec02/Lec02.html#line-plot-1",
    "title": "PSTAT 100: Lecture 02",
    "section": " Line Plot",
    "text": "Line Plot\nEnrollments Over Time\n\nWe do not have this problem with the long (tidy) format:\n\n\n\n\n    Course              Title Quarter Enrollment\n  PSTAT 5A UNDERSTANDING DATA     S25        167\n  PSTAT 5H         STATISTICS     S25         11\n PSTAT 5LS STAT LIFE SCIENCES     S25        355\n   PSTAT 8 TRANS DS PROB STAT     S25         70\n  PSTAT 10 DATA SCIENCE PRINC     S25        235\n [ reached 'max' / getOption(\"max.print\") -- omitted 653 rows ]\n\n\n\n\nNow the Quarter variable clearly shows up as its own column, making it much easier to access using R. This is one of the benefits of tidiness.\nThe question we now turn to is: how to we transform the wide layout into the long layout?"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#dataframe-transformations",
    "href": "Lectures/Lec02/Lec02.html#dataframe-transformations",
    "title": "PSTAT 100: Lecture 02",
    "section": " Dataframe Transformations",
    "text": "Dataframe Transformations\nMelting\n\nThe answer: an operation known as melting.\nTo illustrate the melting operation, let’s consider a simpler mock dataset.\nWe imagine 3 subjects were each administered two dosages of a drug. Their heart rate (in bpm) after each dose was recorded, and stored in a dataframe."
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#dataframe-transformations-1",
    "href": "Lectures/Lec02/Lec02.html#dataframe-transformations-1",
    "title": "PSTAT 100: Lecture 02",
    "section": " Dataframe Transformations",
    "text": "Dataframe Transformations\nMelting\n\nOriginal DataframeMolten Dataframe\n\n\n\n\n\n\n\n\n\n\n\n\n \nA\nB\n\n\n\n\nJane\n62\n65\n\n\nJohn\n71\n75\n\n\nJack\n64\n70\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nDosage\nHeartrate\n\n\n\n\nJane\nA\n62\n\n\nJohn\nA\n71\n\n\nJack\nA\n64\n\n\nJane\nB\n65\n\n\nJohn\nB\n75\n\n\nJack\nB\n70\n\n\n\n\n\n\n\n\n\n\n\nThe original dataframe is “wide” whereas the molten dataframe is “long”."
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#dataframe-transformations-2",
    "href": "Lectures/Lec02/Lec02.html#dataframe-transformations-2",
    "title": "PSTAT 100: Lecture 02",
    "section": " Dataframe Transformations",
    "text": "Dataframe Transformations\nMelting\n\nWe still have a Name variable / column"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#dataframe-transformations-3",
    "href": "Lectures/Lec02/Lec02.html#dataframe-transformations-3",
    "title": "PSTAT 100: Lecture 02",
    "section": " Dataframe Transformations",
    "text": "Dataframe Transformations\nMelting\n\nThe values from previously separate columns have now been concatenated into a single column"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#dataframe-transformations-4",
    "href": "Lectures/Lec02/Lec02.html#dataframe-transformations-4",
    "title": "PSTAT 100: Lecture 02",
    "section": " Dataframe Transformations",
    "text": "Dataframe Transformations\nMelting\n\nThe old column headers (which were values!) now appear as values in a new column."
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#dataframe-transformations-5",
    "href": "Lectures/Lec02/Lec02.html#dataframe-transformations-5",
    "title": "PSTAT 100: Lecture 02",
    "section": " Dataframe Transformations",
    "text": "Dataframe Transformations\nMelting\n\nAs such, we can think of melting as an operation parametrized by the following:\n\nColvars (i.e. columns that are already variables)\nA new variable containing the concatenated data values from the previously separate columns\nA new variable/column containing the old column headers"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#dataframe-transformations-6",
    "href": "Lectures/Lec02/Lec02.html#dataframe-transformations-6",
    "title": "PSTAT 100: Lecture 02",
    "section": " Dataframe Transformations",
    "text": "Dataframe Transformations\nMelting\n\n\nAs such, we can think of melting as an operation parametrized by the following:\n\nColvars (i.e. columns that are already variables)\nA new variable containing the concatenated data values from the previously separate columns\nA new variable/column containing the old column headers"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#dataframe-transformations-7",
    "href": "Lectures/Lec02/Lec02.html#dataframe-transformations-7",
    "title": "PSTAT 100: Lecture 02",
    "section": " Dataframe Transformations",
    "text": "Dataframe Transformations\nMelting\n\n\nAs such, we can think of melting as an operation parametrized by the following:\n\nColvars (i.e. columns that are already variables)\nA new variable containing the concatenated data values from the previously separate columns\nA new variable/column containing the old column headers"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#dataframe-transformations-8",
    "href": "Lectures/Lec02/Lec02.html#dataframe-transformations-8",
    "title": "PSTAT 100: Lecture 02",
    "section": " Dataframe Transformations",
    "text": "Dataframe Transformations\nMelting\n\n\nAs such, we can think of melting as an operation parametrized by the following:\n\nColvars (i.e. columns that are already variables)\nA new variable containing the concatenated data values from the previously separate columns\nA new variable/column containing the old column headers"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#melting-in-r",
    "href": "Lectures/Lec02/Lec02.html#melting-in-r",
    "title": "PSTAT 100: Lecture 02",
    "section": " Melting in R",
    "text": "Melting in R\nVia the reshape2::melt() Function\n\nmelt(\n1  data,\n2  id.vars,\n3  measure.vars,\n4  variable.name = \"variable\",\n  ...,\n  na.rm = FALSE,\n  value.name = \"value\",\n  factorsAsStrings = TRUE\n)\n\n\n1\n\nThe name of the dataframe\n\n2\n\nThe name of the colvars\n\n3\n\nThe name of the column whose values will be split post-melt\n\n4\n\nAn optional specification of what you want the new variable column to be called (e.g. Dosage, in our previous example)\n\n\n\n\nHover over the bubbled numbers for a description of what each argument represents"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#melting-in-r-1",
    "href": "Lectures/Lec02/Lec02.html#melting-in-r-1",
    "title": "PSTAT 100: Lecture 02",
    "section": " Melting in R",
    "text": "Melting in R\nVia the tidyverse::pivot_longer() Function\n\npivot_longer(\n1  data,\n2  cols,\n  ...,\n3  names_to = \"name\",\n  ...,\n4  values_to = \"value\",\n  ...\n)\n\n\n1\n\nThe name of the dataframe\n\n2\n\nThe name of the non-colvars\n\n3\n\nThe name of the new column containing old column names\n\n4\n\nThe name of the new column containing values post-split\n\n\n\n\n\nYou’ll likely see me use melt() more often than pivot_longer(), however that is mainly personal preference!"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#melting-in-r-2",
    "href": "Lectures/Lec02/Lec02.html#melting-in-r-2",
    "title": "PSTAT 100: Lecture 02",
    "section": " Melting in R",
    "text": "Melting in R\nComparison\n\nOriginal DataframeUsing melt()Using pivot_longer()\n\n\n\n\nExpand Code\ndosage_df &lt;- data.frame(\n  Name = c(\"Jane\", \"John\", \"Jack\"),\n  A = c(62, 71, 64),\n  B = c(65, 75, 70)\n)\n\ndosage_df %&gt;% pander()\n\n\n\n\n\n\n\n\n\n\nName\nA\nB\n\n\n\n\nJane\n62\n65\n\n\nJohn\n71\n75\n\n\nJack\n64\n70\n\n\n\n\n\n\n\n\n\nExpand Code\ndosage_df %&gt;%\n  melt(\n    id.vars = \"Name\",\n    variable.name = \"Dosage\",\n    value.name = \"Heart_Rate\"\n  ) %&gt;% pander()\n\n\n\n\n\n\n\n\n\n\nName\nDosage\nHeart_Rate\n\n\n\n\nJane\nA\n62\n\n\nJohn\nA\n71\n\n\nJack\nA\n64\n\n\nJane\nB\n65\n\n\nJohn\nB\n75\n\n\nJack\nB\n70\n\n\n\n\n\n\n\n\n\nExpand Code\ndosage_df %&gt;%\n  pivot_longer(\n    cols = !c(\"Name\"),\n    names_to = \"Dosage\",\n    values_to = \"Heart_Rate\",\n    cols_vary = \"slowest\"         ## optional\n  ) %&gt;% pander()\n\n\n\n\n\n\n\n\n\n\nName\nDosage\nHeart_Rate\n\n\n\n\nJane\nA\n62\n\n\nJohn\nA\n71\n\n\nJack\nA\n64\n\n\nJane\nB\n65\n\n\nJohn\nB\n75\n\n\nJack\nB\n70\n\n\n\n\n\n\n\n\n\nThe inverse of melting is called pivoting, and will be discussed further in Lab 02."
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#live-demo",
    "href": "Lectures/Lec02/Lec02.html#live-demo",
    "title": "PSTAT 100: Lecture 02",
    "section": " Live Demo!",
    "text": "Live Demo!\n\n\n\n\n\n\nLive Demo\n\n\nTime for our first live demo! Feel free to boot up your laptops and follow along; I’ve uploaded the enrollments datset to our course computing server. In this demo we’ll:\n\n\nMelt the enrollments dataset\nGenerate a line graph displaying the change in enrollments over time within lower-division undergraduate PSTAT courses\nInterpret the results"
  },
  {
    "objectID": "Lectures/Lec02/Lec02.html#next-time",
    "href": "Lectures/Lec02/Lec02.html#next-time",
    "title": "PSTAT 100: Lecture 02",
    "section": " Next Time",
    "text": "Next Time\nAnd Coming Up\n\nNext lecture, we’ll explore statistical visualizations further.\nDuring our first Lab session this afternoon, you’ll get practice with some dataframe manipulation commands from the tidyverse\n\nThe last problem on the first homework will also give you a chance to practice some of these\n\nStart thinking about who you want to work with on the Mid-Quarter Project!\n\nAs a reminder, you are required to work in groups of 3-5 on the project.\nYou must finalize (and submit) your groups by Monday of next week."
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics",
    "href": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics",
    "title": "PSTAT 100: Lecture 04",
    "section": " The Grammar of Graphics",
    "text": "The Grammar of Graphics\n\nMost of us can probably make a graph pretty easily, with a pen, paper, and a ruler.\nBut what are the actual components that go into a visualization?\n\nThis is an important question to answer in order to be able to make computers generate graphs and visualizations.\n\nHopefully everyone had a chance to at least skim through the paper that was linked as reading for today, so you should all know that one answer to this question can be found in the so-called grammar of graphics\nFirst proposed by Leland Wilkinson in 1999, and then modified by Hadley Wickham in the 2000s."
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics-1",
    "href": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics-1",
    "title": "PSTAT 100: Lecture 04",
    "section": " The Grammar of Graphics",
    "text": "The Grammar of Graphics\n\nFirst, we need data (remember this from earlier this week?)\nNext, we need to specify axes / a coordinate system\n\nWhat variable goes on the x-axis? What about the y-axis? Should we include a radial axis? Should we make a map?\n\nFinally, we need geometric objects (shortened to geoms)\n\nDo we need bars or points? Lines or sectors? Etc.\n\nAesthetics are additional attributes of the geoms, to which variables can be mapped (e.g. coordinates of points, heights of bars, etc.)\n\nBe careful to distinguish the aesthetics from the aesthetic mappings - the latter is what maps the data to the former."
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#common-aesthetics",
    "href": "Lectures/Lec04/Lec04.html#common-aesthetics",
    "title": "PSTAT 100: Lecture 04",
    "section": " Common Aesthetics",
    "text": "Common Aesthetics"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics-2",
    "href": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics-2",
    "title": "PSTAT 100: Lecture 04",
    "section": " The Grammar of Graphics",
    "text": "The Grammar of Graphics\nExample\n\n\nNote that (at least for this class), we are treating x- and y-coordinates as aesthetics."
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics-3",
    "href": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics-3",
    "title": "PSTAT 100: Lecture 04",
    "section": " The Grammar of Graphics",
    "text": "The Grammar of Graphics\nggplot2\n\n\n\nThe ggplot2 package in R (part of the tidyverse) uses precisely this framework to generate graphics.\n\nIn fact, the gg stands for “grammar of graphics”\n\n\n\n\n\n\n\n\n\nggplot(\n1   data = NULL,\n2   mapping = aes(),\n   ...) +\n3 geom_&lt;name&gt;(\n    mapping = aes(),\n    … ) +\n    …\n\n\n1\n\nThe data\n\n2\n\nThe mapping of variables to aesthetics\n\n3\n\nThe geoms (as many as necessary, possibly with additional/different aesthetics and mappings)"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics-4",
    "href": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics-4",
    "title": "PSTAT 100: Lecture 04",
    "section": " The Grammar of Graphics",
    "text": "The Grammar of Graphics\nggplot2\n\n\nCode\n1commute_times %&gt;%\n  ggplot(\n2    aes(x = `Commute Dist.`,\n3        y = `Commute Time`)\n  ) +\n4  geom_point()\n\n\n\n1\n\nThe dataframe is called commute_times\n\n2\n\nWe want Commute Distance on the horizontal axis\n\n3\n\nWe want Commute Time on the vertical axis\n\n4\n\nWe want points (i.e. we want to generate a scatterplot)"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics-5",
    "href": "Lectures/Lec04/Lec04.html#the-grammar-of-graphics-5",
    "title": "PSTAT 100: Lecture 04",
    "section": " The Grammar of Graphics",
    "text": "The Grammar of Graphics\nggplot2\n\n\nCode\ncommute_times %&gt;%             \n  ggplot(\n    aes(x = `Commute Dist.`, \n        y = `Commute Time`)\n  ) +\n1  geom_point(size = 4) +\n2  ggtitle(\"Scatterplot of Commute Time vs. Commute Distance\") +\n3  theme_minimal(base_size = 18)\n\n\n\n1\n\nIncrease the point size\n\n2\n\nAdd a title\n\n3\n\nAdd a theme to the plot"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\n\nThe World Bank is a collection of organization aiming to study the effects of poverty worldwide.\n\nYou can read more about them at their website.\n\nTo motivate our discussions on visualizations, we’ll be taking a look at some data collected by the World Bank. The variables included are:\n\n\n\n\n\n\nCountry Name\nCountry Code (abbreviation)\nContinent\nYear of observation\nGDP (Gross Domestic Product)\n\n\n\nFemale Life Expectancy at Birth\nMale Life Expectancy at Birth\nTotal Life Expectancy at Birth\nFemale Adult Literacy Rate\nMale Adult Literacy Rate\nTotal Adult Literacy Rate\n\n\n\nFemale Youth Literacy Rate\nMale Youth Literacy Rate\nTotal Youth Literacy Rate\nPopulation"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset-1",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset-1",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\n\nwb &lt;- read.csv(\"data/wb_cont.csv\", check.names = FALSE)\nwb %&gt;% head(100)\n\n           Country Name Country Code     Continent\n1           Afghanistan          AFG          Asia\n2           Afghanistan          AFG          Asia\n3           Afghanistan          AFG          Asia\n4           Afghanistan          AFG          Asia\n5           Afghanistan          AFG          Asia\n6           Afghanistan          AFG          Asia\n7           Afghanistan          AFG          Asia\n8           Afghanistan          AFG          Asia\n9           Afghanistan          AFG          Asia\n10          Afghanistan          AFG          Asia\n11          Afghanistan          AFG          Asia\n12              Albania          ALB        Europe\n13              Albania          ALB        Europe\n14              Albania          ALB        Europe\n15              Albania          ALB        Europe\n16              Albania          ALB        Europe\n17              Albania          ALB        Europe\n18              Albania          ALB        Europe\n19              Albania          ALB        Europe\n20              Albania          ALB        Europe\n21              Albania          ALB        Europe\n22              Albania          ALB        Europe\n23              Algeria          DZA        Africa\n24              Algeria          DZA        Africa\n25              Algeria          DZA        Africa\n26              Algeria          DZA        Africa\n27              Algeria          DZA        Africa\n28              Algeria          DZA        Africa\n29              Algeria          DZA        Africa\n30              Algeria          DZA        Africa\n31              Algeria          DZA        Africa\n32              Algeria          DZA        Africa\n33              Algeria          DZA        Africa\n34       American Samoa          ASM North America\n35       American Samoa          ASM North America\n36       American Samoa          ASM North America\n37       American Samoa          ASM North America\n38       American Samoa          ASM North America\n39       American Samoa          ASM North America\n40       American Samoa          ASM North America\n41       American Samoa          ASM North America\n42       American Samoa          ASM North America\n43       American Samoa          ASM North America\n44       American Samoa          ASM North America\n45              Andorra          AND        Europe\n46              Andorra          AND        Europe\n47              Andorra          AND        Europe\n48              Andorra          AND        Europe\n49              Andorra          AND        Europe\n50              Andorra          AND        Europe\n51              Andorra          AND        Europe\n52              Andorra          AND        Europe\n53              Andorra          AND        Europe\n54              Andorra          AND        Europe\n55              Andorra          AND        Europe\n56               Angola          AGO        Africa\n57               Angola          AGO        Africa\n58               Angola          AGO        Africa\n59               Angola          AGO        Africa\n60               Angola          AGO        Africa\n61               Angola          AGO        Africa\n62               Angola          AGO        Africa\n63               Angola          AGO        Africa\n64               Angola          AGO        Africa\n65               Angola          AGO        Africa\n66               Angola          AGO        Africa\n67  Antigua and Barbuda          ATG North America\n68  Antigua and Barbuda          ATG North America\n69  Antigua and Barbuda          ATG North America\n70  Antigua and Barbuda          ATG North America\n71  Antigua and Barbuda          ATG North America\n72  Antigua and Barbuda          ATG North America\n73  Antigua and Barbuda          ATG North America\n74  Antigua and Barbuda          ATG North America\n75  Antigua and Barbuda          ATG North America\n76  Antigua and Barbuda          ATG North America\n77  Antigua and Barbuda          ATG North America\n78            Argentina          ARG South America\n79            Argentina          ARG South America\n80            Argentina          ARG South America\n81            Argentina          ARG South America\n82            Argentina          ARG South America\n83            Argentina          ARG South America\n84            Argentina          ARG South America\n85            Argentina          ARG South America\n86            Argentina          ARG South America\n87            Argentina          ARG South America\n88            Argentina          ARG South America\n89              Armenia          ARM        Europe\n90              Armenia          ARM        Europe\n91              Armenia          ARM        Europe\n92              Armenia          ARM        Europe\n93              Armenia          ARM        Europe\n94              Armenia          ARM        Europe\n95              Armenia          ARM        Europe\n96              Armenia          ARM        Europe\n97              Armenia          ARM        Europe\n98              Armenia          ARM        Europe\n99              Armenia          ARM        Europe\n100               Aruba          ABW North America\n                                                     Series Name         1960\n1                                              GDP (current US$)           NA\n2                       Life expectancy at birth, female (years) 3.354900e+01\n3                         Life expectancy at birth, male (years) 3.213600e+01\n4                        Life expectancy at birth, total (years) 3.279900e+01\n5   Literacy rate, adult female (% of females ages 15 and above)           NA\n6       Literacy rate, adult male (% of males ages 15 and above)           NA\n7     Literacy rate, adult total (% of people ages 15 and above)           NA\n8          Literacy rate, youth female (% of females ages 15-24)           NA\n9              Literacy rate, youth male (% of males ages 15-24)           NA\n10           Literacy rate, youth total (% of people ages 15-24)           NA\n11                                             Population, total 9.035043e+06\n12                                             GDP (current US$)           NA\n13                      Life expectancy at birth, female (years) 5.887700e+01\n14                        Life expectancy at birth, male (years) 5.400500e+01\n15                       Life expectancy at birth, total (years) 5.641300e+01\n16  Literacy rate, adult female (% of females ages 15 and above)           NA\n17      Literacy rate, adult male (% of males ages 15 and above)           NA\n18    Literacy rate, adult total (% of people ages 15 and above)           NA\n19         Literacy rate, youth female (% of females ages 15-24)           NA\n20             Literacy rate, youth male (% of males ages 15-24)           NA\n21           Literacy rate, youth total (% of people ages 15-24)           NA\n22                                             Population, total 1.608800e+06\n23                                             GDP (current US$) 2.723615e+09\n24                      Life expectancy at birth, female (years) 4.385800e+01\n25                        Life expectancy at birth, male (years) 3.822500e+01\n26                       Life expectancy at birth, total (years) 4.083900e+01\n27  Literacy rate, adult female (% of females ages 15 and above)           NA\n28      Literacy rate, adult male (% of males ages 15 and above)           NA\n29    Literacy rate, adult total (% of people ages 15 and above)           NA\n30         Literacy rate, youth female (% of females ages 15-24)           NA\n31             Literacy rate, youth male (% of males ages 15-24)           NA\n32           Literacy rate, youth total (% of people ages 15-24)           NA\n33                                             Population, total 1.142492e+07\n34                                             GDP (current US$)           NA\n35                      Life expectancy at birth, female (years) 6.710700e+01\n36                        Life expectancy at birth, male (years) 6.317600e+01\n37                       Life expectancy at birth, total (years) 6.505300e+01\n38  Literacy rate, adult female (% of females ages 15 and above)           NA\n39      Literacy rate, adult male (% of males ages 15 and above)           NA\n40    Literacy rate, adult total (% of people ages 15 and above)           NA\n41         Literacy rate, youth female (% of females ages 15-24)           NA\n42             Literacy rate, youth male (% of males ages 15-24)           NA\n43           Literacy rate, youth total (% of people ages 15-24)           NA\n44                                             Population, total 2.013300e+04\n45                                             GDP (current US$)           NA\n46                      Life expectancy at birth, female (years) 7.508100e+01\n47                        Life expectancy at birth, male (years) 6.910900e+01\n48                       Life expectancy at birth, total (years) 7.209400e+01\n49  Literacy rate, adult female (% of females ages 15 and above)           NA\n50      Literacy rate, adult male (% of males ages 15 and above)           NA\n51    Literacy rate, adult total (% of people ages 15 and above)           NA\n52         Literacy rate, youth female (% of females ages 15-24)           NA\n53             Literacy rate, youth male (% of males ages 15-24)           NA\n54           Literacy rate, youth total (% of people ages 15-24)           NA\n55                                             Population, total 9.510000e+03\n56                                             GDP (current US$)           NA\n57                      Life expectancy at birth, female (years) 3.973900e+01\n58                        Life expectancy at birth, male (years) 3.624800e+01\n59                       Life expectancy at birth, total (years) 3.793300e+01\n60  Literacy rate, adult female (% of females ages 15 and above)           NA\n61      Literacy rate, adult male (% of males ages 15 and above)           NA\n62    Literacy rate, adult total (% of people ages 15 and above)           NA\n63         Literacy rate, youth female (% of females ages 15-24)           NA\n64             Literacy rate, youth male (% of males ages 15-24)           NA\n65           Literacy rate, youth total (% of people ages 15-24)           NA\n66                                             Population, total 5.231654e+06\n67                                             GDP (current US$)           NA\n68                      Life expectancy at birth, female (years) 6.475500e+01\n69                        Life expectancy at birth, male (years) 6.011700e+01\n70                       Life expectancy at birth, total (years) 6.263500e+01\n71  Literacy rate, adult female (% of females ages 15 and above)           NA\n72      Literacy rate, adult male (% of males ages 15 and above)           NA\n73    Literacy rate, adult total (% of people ages 15 and above)           NA\n74         Literacy rate, youth female (% of females ages 15-24)           NA\n75             Literacy rate, youth male (% of males ages 15-24)           NA\n76           Literacy rate, youth total (% of people ages 15-24)           NA\n77                                             Population, total 5.560300e+04\n78                                             GDP (current US$)           NA\n79                      Life expectancy at birth, female (years) 6.778900e+01\n80                        Life expectancy at birth, male (years) 6.120200e+01\n81                       Life expectancy at birth, total (years) 6.424200e+01\n82  Literacy rate, adult female (% of females ages 15 and above)           NA\n83      Literacy rate, adult male (% of males ages 15 and above)           NA\n84    Literacy rate, adult total (% of people ages 15 and above)           NA\n85         Literacy rate, youth female (% of females ages 15-24)           NA\n86             Literacy rate, youth male (% of males ages 15-24)           NA\n87           Literacy rate, youth total (% of people ages 15-24)           NA\n88                                             Population, total 2.038604e+07\n89                                             GDP (current US$)           NA\n90                      Life expectancy at birth, female (years) 6.215000e+01\n91                        Life expectancy at birth, male (years) 5.612300e+01\n92                       Life expectancy at birth, total (years) 5.906300e+01\n93  Literacy rate, adult female (% of females ages 15 and above)           NA\n94      Literacy rate, adult male (% of males ages 15 and above)           NA\n95    Literacy rate, adult total (% of people ages 15 and above)           NA\n96         Literacy rate, youth female (% of females ages 15-24)           NA\n97             Literacy rate, youth male (% of males ages 15-24)           NA\n98           Literacy rate, youth total (% of people ages 15-24)           NA\n99                                             Population, total 1.863705e+06\n100                                            GDP (current US$)           NA\n            1961         1962         1963         1964         1965\n1             NA           NA           NA           NA           NA\n2   3.404300e+01 3.450200e+01 3.494500e+01 3.542800e+01 3.590000e+01\n3   3.262600e+01 3.309800e+01 3.354300e+01 3.400400e+01 3.443800e+01\n4   3.329100e+01 3.375700e+01 3.420100e+01 3.467300e+01 3.512400e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  9.214083e+06 9.404406e+06 9.604487e+06 9.814318e+06 1.003601e+07\n12            NA           NA           NA           NA           NA\n13  5.999500e+01 6.104700e+01 6.208600e+01 6.304800e+01 6.393400e+01\n14  5.502800e+01 5.600000e+01 5.693800e+01 5.782400e+01 5.867700e+01\n15  5.748800e+01 5.849400e+01 5.947900e+01 6.040400e+01 6.127300e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  1.659800e+06 1.711319e+06 1.762621e+06 1.814135e+06 1.864791e+06\n23  2.434747e+09 2.001445e+09 2.702982e+09 2.909316e+09 3.136284e+09\n24  4.377000e+01 4.270600e+01 4.360700e+01 4.342900e+01 4.327000e+01\n25  3.819400e+01 3.681300e+01 4.267400e+01 4.254300e+01 4.242600e+01\n26  4.079200e+01 3.952700e+01 4.314300e+01 4.298700e+01 4.284600e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  1.162888e+07 1.180077e+07 1.198212e+07 1.217981e+07 1.236598e+07\n34            NA           NA           NA           NA           NA\n35  6.791600e+01 6.842700e+01 6.856700e+01 6.845400e+01 6.821100e+01\n36  6.362800e+01 6.388800e+01 6.406000e+01 6.410100e+01 6.404400e+01\n37  6.564800e+01 6.600800e+01 6.616100e+01 6.613500e+01 6.599600e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  2.066600e+04 2.129800e+04 2.196600e+04 2.267300e+04 2.340600e+04\n45            NA           NA           NA           NA           NA\n46  7.574400e+01 7.637200e+01 7.687100e+01 7.735200e+01 7.768800e+01\n47  6.945400e+01 6.973500e+01 6.992400e+01 7.017500e+01 7.038600e+01\n48  7.257300e+01 7.299300e+01 7.329800e+01 7.362400e+01 7.385600e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  1.028300e+04 1.108600e+04 1.191500e+04 1.276400e+04 1.363400e+04\n56            NA           NA           NA           NA           NA\n57  3.988500e+01 4.021800e+01 4.050700e+01 4.081300e+01 4.112000e+01\n58  3.426600e+01 3.448900e+01 3.472000e+01 3.499600e+01 3.523600e+01\n59  3.690200e+01 3.716800e+01 3.741900e+01 3.770400e+01 3.796800e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  5.301583e+06 5.354310e+06 5.408320e+06 5.464187e+06 5.521981e+06\n67            NA           NA           NA           NA           NA\n68  6.552000e+01 6.623200e+01 6.700200e+01 6.778600e+01 6.858400e+01\n69  6.076600e+01 6.139100e+01 6.203600e+01 6.272800e+01 6.340700e+01\n70  6.333500e+01 6.399500e+01 6.469700e+01 6.542800e+01 6.617100e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  5.654000e+04 5.733600e+04 5.813800e+04 5.902000e+04 5.997000e+04\n78            NA 2.445060e+10 1.827212e+10 2.560525e+10 2.834471e+10\n79  6.823600e+01 6.828200e+01 6.857500e+01 6.853700e+01 6.881900e+01\n80  6.152600e+01 6.147400e+01 6.165000e+01 6.160900e+01 6.178300e+01\n81  6.463100e+01 6.461800e+01 6.485500e+01 6.481600e+01 6.505300e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  2.072628e+07 2.107254e+07 2.142170e+07 2.176945e+07 2.211263e+07\n89            NA           NA           NA           NA           NA\n90  6.259800e+01 6.303800e+01 6.346700e+01 6.388100e+01 6.427700e+01\n91  5.653800e+01 5.694400e+01 5.733900e+01 5.771700e+01 5.807300e+01\n92  5.949410e+01 5.991668e+01 6.032827e+01 6.072383e+01 6.109934e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  1.927484e+06 1.991689e+06 2.056023e+06 2.120135e+06 2.183635e+06\n100           NA           NA           NA           NA           NA\n            1966         1967         1968         1969         1970\n1             NA           NA           NA           NA           NA\n2   3.638000e+01 3.685100e+01 3.728100e+01 3.775800e+01 3.826100e+01\n3   3.487700e+01 3.532400e+01 3.582500e+01 3.628700e+01 3.674800e+01\n4   3.558300e+01 3.604200e+01 3.651000e+01 3.697900e+01 3.746000e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.026640e+07 1.050596e+07 1.075692e+07 1.101741e+07 1.129013e+07\n12            NA           NA           NA           NA           NA\n13  6.481400e+01 6.564200e+01 6.647600e+01 6.723700e+01 6.794600e+01\n14  5.954300e+01 6.036400e+01 6.115100e+01 6.188800e+01 6.258100e+01\n15  6.214900e+01 6.297600e+01 6.378800e+01 6.453800e+01 6.523400e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  1.914573e+06 1.965598e+06 2.022272e+06 2.081695e+06 2.135479e+06\n23  3.039859e+09 3.370870e+09 3.852147e+09 4.257253e+09 4.863527e+09\n24  4.315500e+01 4.312200e+01 4.318900e+01 4.338100e+01 4.373800e+01\n25  4.234700e+01 4.234300e+01 4.242600e+01 4.260600e+01 4.292600e+01\n26  4.274500e+01 4.273100e+01 4.280600e+01 4.299100e+01 4.332800e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  1.259007e+07 1.287612e+07 1.317261e+07 1.347596e+07 1.378372e+07\n34            NA           NA           NA           NA           NA\n35  5.858300e+01 6.801900e+01 6.812800e+01 6.846500e+01 6.902000e+01\n36  5.803300e+01 6.385200e+01 6.383000e+01 6.391800e+01 6.404600e+01\n37  5.828400e+01 6.580700e+01 6.584700e+01 6.605000e+01 6.636400e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  2.413600e+04 2.486300e+04 2.561400e+04 2.637500e+04 2.702600e+04\n45            NA           NA           NA           NA 7.861771e+07\n46  7.790900e+01 7.797900e+01 7.800200e+01 7.798800e+01 7.807500e+01\n47  7.058300e+01 7.074100e+01 7.093400e+01 7.111100e+01 7.135300e+01\n48  7.402000e+01 7.411900e+01 7.422000e+01 7.429600e+01 7.445200e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  1.462600e+04 1.583700e+04 1.717600e+04 1.855500e+04 1.997700e+04\n56            NA           NA           NA           NA           NA\n57  4.148700e+01 4.183700e+01 4.223000e+01 4.257700e+01 4.296400e+01\n58  3.548000e+01 3.584900e+01 3.618000e+01 3.655900e+01 3.690800e+01\n59  3.825800e+01 3.861600e+01 3.896800e+01 3.932900e+01 3.968800e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  5.581386e+06 5.641807e+06 5.702699e+06 5.763685e+06 5.852788e+06\n67            NA           NA           NA           NA           NA\n68  6.935300e+01 7.009300e+01 7.077800e+01 7.139700e+01 7.196600e+01\n69  6.408500e+01 6.469800e+01 6.527800e+01 6.582900e+01 6.631500e+01\n70  6.690200e+01 6.758600e+01 6.823000e+01 6.882700e+01 6.937100e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.090000e+04 6.183700e+04 6.280900e+04 6.381900e+04 6.452800e+04\n78  2.863047e+10 2.425667e+10 2.643686e+10 3.125628e+10 3.158421e+10\n79  6.909500e+01 6.928800e+01 6.919300e+01 6.913300e+01 6.956400e+01\n80  6.215700e+01 6.212600e+01 6.177900e+01 6.155300e+01 6.216500e+01\n81  6.539800e+01 6.546700e+01 6.523400e+01 6.508500e+01 6.564700e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  2.245389e+07 2.279906e+07 2.315058e+07 2.350871e+07 2.387833e+07\n89            NA           NA           NA           NA           NA\n90  6.465300e+01 6.500800e+01 6.534300e+01 6.565800e+01 6.595400e+01\n91  5.840700e+01 5.871500e+01 5.899900e+01 5.925800e+01 5.949300e+01\n92  6.145383e+01 6.178476e+01 6.209363e+01 6.237995e+01 6.264471e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  2.246159e+06 2.307492e+06 2.367319e+06 2.424030e+06 2.475633e+06\n100           NA           NA           NA           NA           NA\n            1971         1972         1973         1974         1975\n1             NA           NA           NA           NA           NA\n2   3.875200e+01 3.925500e+01 3.977800e+01 4.029100e+01 4.081300e+01\n3   3.720200e+01 3.768100e+01 3.821300e+01 3.873400e+01 3.926100e+01\n4   3.793200e+01 3.842300e+01 3.895100e+01 3.946900e+01 3.999400e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.156767e+07 1.185370e+07 1.215800e+07 1.246913e+07 1.277395e+07\n12            NA           NA           NA           NA           NA\n13  6.861200e+01 6.924600e+01 6.984400e+01 7.040000e+01 7.091800e+01\n14  6.324600e+01 6.387000e+01 6.444200e+01 6.495400e+01 6.542500e+01\n15  6.589600e+01 6.652600e+01 6.710700e+01 6.763300e+01 6.812000e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  2.187853e+06 2.243126e+06 2.296752e+06 2.350124e+06 2.404831e+06\n23  5.077183e+09 6.766744e+09 8.707859e+09 1.320987e+10 1.555790e+10\n24  4.423400e+01 4.489400e+01 4.567900e+01 4.660700e+01 4.766900e+01\n25  4.334400e+01 4.389500e+01 4.455300e+01 4.533700e+01 4.622100e+01\n26  4.378200e+01 4.438400e+01 4.510200e+01 4.595300e+01 4.692100e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  1.409894e+07 1.442707e+07 1.477115e+07 1.513350e+07 1.567860e+07\n34            NA           NA           NA           NA           NA\n35  6.969600e+01 7.029400e+01 7.069800e+01 7.104000e+01 7.133100e+01\n36  6.425800e+01 6.454100e+01 6.496000e+01 6.528900e+01 6.559400e+01\n37  6.677000e+01 6.718600e+01 6.760400e+01 6.795000e+01 6.825600e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  2.753300e+04 2.799500e+04 2.843600e+04 2.887500e+04 2.939000e+04\n45  8.940661e+07 1.134144e+08 1.508416e+08 1.865571e+08 2.201126e+08\n46  7.819300e+01 7.846100e+01 7.875100e+01 7.907200e+01 7.939100e+01\n47  7.158300e+01 7.185500e+01 7.208400e+01 7.231100e+01 7.251400e+01\n48  7.461500e+01 7.486400e+01 7.509600e+01 7.534000e+01 7.556700e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  2.144200e+04 2.295700e+04 2.452300e+04 2.613000e+04 2.777300e+04\n56            NA           NA           NA           NA           NA\n57  4.331100e+01 4.370200e+01 4.404000e+01 4.441900e+01 4.417900e+01\n58  3.731600e+01 3.770100e+01 3.814300e+01 3.853100e+01 3.793600e+01\n59  4.007600e+01 4.046900e+01 4.087100e+01 4.126000e+01 4.081700e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  5.991102e+06 6.174262e+06 6.388528e+06 6.613367e+06 6.842947e+06\n67            NA           NA           NA           NA           NA\n68  7.248700e+01 7.295700e+01 7.337400e+01 7.377700e+01 7.414500e+01\n69  6.678900e+01 6.722300e+01 6.763600e+01 6.802100e+01 6.837400e+01\n70  6.986100e+01 7.030400e+01 7.071000e+01 7.109500e+01 7.144700e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.472900e+04 6.461500e+04 6.434200e+04 6.405800e+04 6.383900e+04\n78  3.329320e+10 3.473300e+10 5.254400e+10 7.243678e+10 5.243865e+10\n79  6.941700e+01 6.976400e+01 7.008700e+01 7.037100e+01 7.091300e+01\n80  6.221000e+01 6.251700e+01 6.267100e+01 6.280800e+01 6.336700e+01\n81  6.561900e+01 6.595300e+01 6.618600e+01 6.640500e+01 6.696500e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  2.425721e+07 2.464433e+07 2.504600e+07 2.546135e+07 2.587411e+07\n89            NA           NA           NA           NA           NA\n90  6.623200e+01 6.647500e+01 6.671500e+01 6.695900e+01 6.721700e+01\n91  5.970500e+01 5.991400e+01 6.010800e+01 6.029700e+01 6.048300e+01\n92  6.288890e+01 6.311449e+01 6.333093e+01 6.354676e+01 6.376788e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  2.525345e+06 2.577079e+06 2.630860e+06 2.686445e+06 2.743660e+06\n100           NA           NA           NA           NA           NA\n            1976         1977         1978         1979         1980\n1             NA           NA           NA           NA           NA\n2   4.133300e+01 4.188000e+01 4.147900e+01 4.088100e+01 4.137900e+01\n3   3.978700e+01 4.036300e+01 3.885500e+01 3.709000e+01 3.742800e+01\n4   4.051800e+01 4.108200e+01 4.008600e+01 3.884400e+01 3.925800e+01\n5             NA           NA           NA 5.000000e+00           NA\n6             NA           NA           NA 3.000000e+01           NA\n7             NA           NA           NA 1.800000e+01           NA\n8             NA           NA           NA 1.100000e+01           NA\n9             NA           NA           NA 4.600000e+01           NA\n10            NA           NA           NA 3.000000e+01           NA\n11  1.305985e+07 1.334076e+07 1.361144e+07 1.365557e+07 1.316931e+07\n12            NA           NA           NA           NA 1.578102e+09\n13  7.139900e+01 7.185200e+01 7.226900e+01 7.259700e+01 7.296700e+01\n14  6.586100e+01 6.627100e+01 6.662500e+01 6.682800e+01 6.704000e+01\n15  6.857000e+01 6.899200e+01 6.936700e+01 6.961700e+01 6.990300e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  2.458526e+06 2.513546e+06 2.566266e+06 2.617832e+06 2.671997e+06\n23  1.772824e+10 2.097211e+10 2.636449e+10 3.324371e+10 4.234583e+10\n24  4.890300e+01 5.027900e+01 5.182200e+01 5.378000e+01 5.603100e+01\n25  4.721900e+01 4.828600e+01 4.949300e+01 5.114200e+01 5.310400e+01\n26  4.803400e+01 4.924900e+01 5.061500e+01 5.240900e+01 5.451200e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  1.640917e+07 1.701599e+07 1.750697e+07 1.803666e+07 1.860717e+07\n34            NA           NA           NA           NA           NA\n35  7.159000e+01 7.182200e+01 7.203100e+01 7.224000e+01 7.253800e+01\n36  6.579500e+01 6.603000e+01 6.619800e+01 6.645100e+01 6.674700e+01\n37  6.847500e+01 6.870100e+01 6.888100e+01 6.911400e+01 6.941300e+01\n38            NA           NA           NA           NA 9.700000e+01\n39            NA           NA           NA           NA 9.700000e+01\n40            NA           NA           NA           NA 9.700000e+01\n41            NA           NA           NA           NA 9.700000e+01\n42            NA           NA           NA           NA 9.800000e+01\n43            NA           NA           NA           NA 9.800000e+01\n44  2.995900e+04 3.052100e+04 3.107600e+04 3.161100e+04 3.240300e+04\n45  2.272839e+08 2.539979e+08 3.080203e+08 4.115487e+08 4.463778e+08\n46  7.978500e+01 8.015400e+01 8.056900e+01 8.097500e+01 8.137000e+01\n47  7.278700e+01 7.305400e+01 7.335700e+01 7.366300e+01 7.395600e+01\n48  7.586900e+01 7.615400e+01 7.648800e+01 7.681900e+01 7.713700e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  2.943600e+04 3.109700e+04 3.273500e+04 3.430600e+04 3.578200e+04\n56            NA           NA           NA           NA 5.930503e+09\n57  4.423300e+01 4.458500e+01 4.488900e+01 4.518400e+01 4.547000e+01\n58  3.788200e+01 3.831200e+01 3.870000e+01 3.906200e+01 3.941100e+01\n59  4.081200e+01 4.121500e+01 4.157300e+01 4.191300e+01 4.224200e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  7.074664e+06 7.317829e+06 7.576734e+06 7.847207e+06 8.133872e+06\n67            NA 7.749630e+07 8.803333e+07 1.095852e+08 1.324407e+08\n68  7.450200e+01 7.488300e+01 7.526200e+01 7.559500e+01 7.585300e+01\n69  6.872700e+01 6.906800e+01 6.940300e+01 6.972900e+01 7.002200e+01\n70  7.179400e+01 7.214900e+01 7.250000e+01 7.282300e+01 7.309400e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.376200e+04 6.386200e+04 6.403800e+04 6.427400e+04 6.451300e+04\n78  5.116950e+10 5.678100e+10 8.904945e+10 6.925233e+10 7.696192e+10\n79  7.098300e+01 7.155900e+01 7.170800e+01 7.200100e+01 7.204700e+01\n80  6.340600e+01 6.394400e+01 6.453500e+01 6.507200e+01 6.528200e+01\n81  6.703000e+01 6.759500e+01 6.799900e+01 6.843400e+01 6.857600e+01\n82            NA           NA           NA           NA 9.400000e+01\n83            NA           NA           NA           NA 9.400000e+01\n84            NA           NA           NA           NA 9.400000e+01\n85            NA           NA           NA           NA 9.700000e+01\n86            NA           NA           NA           NA 9.600000e+01\n87            NA           NA           NA           NA 9.700000e+01\n88  2.628228e+07 2.670180e+07 2.713216e+07 2.756890e+07 2.801160e+07\n89            NA           NA           NA           NA           NA\n90  6.748800e+01 6.778400e+01 6.808800e+01 6.839800e+01 6.870600e+01\n91  6.068100e+01 6.089200e+01 6.113400e+01 6.141400e+01 6.174100e+01\n92  6.400149e+01 6.425395e+01 6.452620e+01 6.482083e+01 6.513856e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  2.818165e+06 2.912827e+06 3.012807e+06 3.078501e+06 3.107415e+06\n100           NA           NA           NA           NA           NA\n            1981         1982         1983         1984         1985\n1             NA           NA           NA           NA           NA\n2   4.169500e+01 3.951800e+01 4.009300e+01 3.642200e+01 3.710100e+01\n3   3.743300e+01 3.325100e+01 3.359900e+01 2.782300e+01 2.839300e+01\n4   3.940600e+01 3.605800e+01 3.651700e+01 3.147300e+01 3.213200e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.193758e+07 1.099138e+07 1.091798e+07 1.119022e+07 1.142685e+07\n12  1.808177e+09 1.861163e+09 1.881413e+09 1.857338e+09 1.897050e+09\n13  7.328700e+01 7.361800e+01 7.397000e+01 7.432900e+01 7.468400e+01\n14  6.721000e+01 6.744100e+01 6.765800e+01 6.786700e+01 6.811500e+01\n15  7.014500e+01 7.042500e+01 7.070500e+01 7.098400e+01 7.128200e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  2.726056e+06 2.784278e+06 2.843960e+06 2.904429e+06 2.964762e+06\n23  4.434859e+10 4.520717e+10 4.880137e+10 5.369855e+10 5.793787e+10\n24  5.908400e+01 6.124700e+01 6.274200e+01 6.408600e+01 6.543100e+01\n25  5.587600e+01 5.804800e+01 5.984800e+01 6.142700e+01 6.293800e+01\n26  5.742200e+01 5.959400e+01 6.125100e+01 6.272200e+01 6.415500e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  1.922070e+07 1.987235e+07 2.055812e+07 2.127197e+07 2.200854e+07\n34            NA           NA           NA           NA           NA\n35  7.287500e+01 7.307000e+01 7.318700e+01 7.327500e+01 7.351100e+01\n36  6.705400e+01 6.734300e+01 6.759300e+01 6.781900e+01 6.800700e+01\n37  6.973100e+01 6.997500e+01 7.016300e+01 7.032600e+01 7.053200e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  3.358400e+04 3.490900e+04 3.627100e+04 3.766700e+04 3.910300e+04\n45  3.889833e+08 3.759147e+08 3.278500e+08 3.300731e+08 3.467427e+08\n46  8.169000e+01 8.197100e+01 8.219600e+01 8.240400e+01 8.257100e+01\n47  7.419900e+01 7.440300e+01 7.454800e+01 7.465400e+01 7.471900e+01\n48  7.739100e+01 7.761700e+01 7.778700e+01 7.791600e+01 7.800600e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  3.716900e+04 3.876400e+04 4.056500e+04 4.227300e+04 4.382500e+04\n56  5.550483e+09 5.550483e+09 5.784342e+09 6.131475e+09 7.554065e+09\n57  4.575000e+01 4.601600e+01 4.545600e+01 4.568600e+01 4.589100e+01\n58  3.973800e+01 4.005400e+01 3.892300e+01 3.921300e+01 3.948000e+01\n59  4.255600e+01 4.285700e+01 4.197200e+01 4.224500e+01 4.249500e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  8.435607e+06 8.751648e+06 9.082983e+06 9.425917e+06 9.779120e+06\n67  1.493778e+08 1.664259e+08 1.848481e+08 2.121926e+08 2.463444e+08\n68  7.605000e+01 7.623700e+01 7.638100e+01 7.649900e+01 7.657300e+01\n69  7.028800e+01 7.051900e+01 7.070300e+01 7.084000e+01 7.092600e+01\n70  7.332000e+01 7.352500e+01 7.368400e+01 7.380800e+01 7.387300e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.466500e+04 6.478500e+04 6.493400e+04 6.488200e+04 6.459100e+04\n78  7.867684e+10 8.430749e+10 1.039791e+11 1.169151e+11 8.815089e+10\n79  7.243600e+01 7.255700e+01 7.270600e+01 7.277800e+01 7.340200e+01\n80  6.545500e+01 6.555900e+01 6.600200e+01 6.605400e+01 6.647400e+01\n81  6.885800e+01 6.897300e+01 6.929000e+01 6.935300e+01 6.987900e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  2.846396e+07 2.892426e+07 2.939133e+07 2.986309e+07 3.033644e+07\n89            NA           NA           NA           NA           NA\n90  6.901100e+01 6.931900e+01 6.962100e+01 6.991500e+01 7.020100e+01\n91  6.212200e+01 6.254800e+01 6.299900e+01 6.342600e+01 6.378600e+01\n92  6.548249e+01 6.585093e+01 6.622924e+01 6.659137e+01 6.691527e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  3.135349e+06 3.163144e+06 3.191539e+06 3.224547e+06 3.260432e+06\n100           NA           NA           NA           NA           NA\n            1986         1987         1988         1989         1990\n1             NA           NA           NA           NA           NA\n2   4.207200e+01 4.260300e+01 4.596200e+01 4.704200e+01 4.770300e+01\n3   3.527000e+01 3.560100e+01 4.074200e+01 4.213200e+01 4.271200e+01\n4   3.840000e+01 3.883100e+01 4.323800e+01 4.449600e+01 4.511800e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.142007e+07 1.138782e+07 1.152330e+07 1.187409e+07 1.204566e+07\n12  2.097326e+09 2.080796e+09 2.051236e+09 2.253090e+09 2.028554e+09\n13  7.513800e+01 7.547700e+01 7.572600e+01 7.595600e+01 7.619500e+01\n14  6.843700e+01 6.872700e+01 6.894000e+01 6.917400e+01 6.941200e+01\n15  7.166500e+01 7.198100e+01 7.221700e+01 7.245700e+01 7.271000e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  3.022635e+06 3.083605e+06 3.142336e+06 3.227943e+06 3.286542e+06\n23  6.369201e+10 6.674582e+10 5.908940e+10 5.563472e+10 6.204851e+10\n24  6.648600e+01 6.718900e+01 6.765700e+01 6.807900e+01 6.824200e+01\n25  6.411600e+01 6.511300e+01 6.617900e+01 6.685600e+01 6.708800e+01\n26  6.527300e+01 6.613000e+01 6.691000e+01 6.746100e+01 6.765800e+01\n27            NA 3.600000e+01           NA           NA           NA\n28            NA 6.300000e+01           NA           NA           NA\n29            NA 5.000000e+01           NA           NA           NA\n30            NA 6.200000e+01           NA           NA           NA\n31            NA 8.600000e+01           NA           NA           NA\n32            NA 7.400000e+01           NA           NA           NA\n33  2.274550e+07 2.344362e+07 2.410954e+07 2.475448e+07 2.537581e+07\n34            NA           NA           NA           NA           NA\n35  7.388700e+01 7.429100e+01 7.466300e+01 7.485200e+01 7.524200e+01\n36  6.801700e+01 6.793400e+01 6.777100e+01 6.773900e+01 6.777200e+01\n37  7.070400e+01 7.082800e+01 7.088300e+01 7.092900e+01 7.110700e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  4.057100e+04 4.207200e+04 4.361500e+04 4.519100e+04 4.664000e+04\n45  4.819960e+08 6.112999e+08 7.214259e+08 7.954896e+08 1.028990e+09\n46  8.277500e+01 8.296000e+01 8.311700e+01 8.323500e+01 8.338700e+01\n47  7.479000e+01 7.484500e+01 7.503300e+01 7.528100e+01 7.581500e+01\n48  7.810700e+01 7.818900e+01 7.836400e+01 7.855700e+01 7.896100e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  4.573400e+04 4.765300e+04 4.941600e+04 5.062000e+04 5.259700e+04\n56  7.072536e+09 8.084412e+09 8.769837e+09 1.020178e+10 1.122952e+10\n57  4.607200e+01 4.462400e+01 4.512500e+01 4.531500e+01 4.543000e+01\n58  3.975900e+01 3.744100e+01 3.823400e+01 3.846800e+01 3.863900e+01\n59  4.273900e+01 4.078600e+01 4.147100e+01 4.169800e+01 4.185400e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  1.013945e+07 1.049786e+07 1.086129e+07 1.123856e+07 1.162636e+07\n67  2.975370e+08 3.468407e+08 4.113741e+08 4.551481e+08 4.786926e+08\n68  7.660300e+01 7.659000e+01 7.653200e+01 7.632800e+01 7.633800e+01\n69  7.096900e+01 7.097700e+01 7.094400e+01 7.081800e+01 7.079600e+01\n70  7.389300e+01 7.387300e+01 7.381100e+01 7.362800e+01 7.360200e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.427600e+04 6.394600e+04 6.362300e+04 6.332500e+04 6.306600e+04\n78  1.058724e+11 1.088109e+11 1.268902e+11 7.662973e+10 1.413526e+11\n79  7.381000e+01 7.421900e+01 7.462300e+01 7.503900e+01 7.487800e+01\n80  6.685200e+01 6.725600e+01 6.763200e+01 6.800800e+01 6.834700e+01\n81  7.028100e+01 7.069900e+01 7.109700e+01 7.150200e+01 7.161500e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  3.081198e+07 3.129176e+07 3.178053e+07 3.227095e+07 3.275590e+07\n89            NA           NA           NA           NA 2.256863e+09\n90  7.047500e+01 7.073700e+01 5.356100e+01 7.123300e+01 7.146100e+01\n91  6.403800e+01 6.414200e+01 5.168500e+01 6.398100e+01 6.382400e+01\n92  6.717800e+01 6.735907e+01 5.260012e+01 6.751856e+01 6.754937e+01\n93            NA           NA           NA 9.800000e+01           NA\n94            NA           NA           NA 9.900000e+01           NA\n95            NA           NA           NA 9.900000e+01           NA\n96            NA           NA           NA 1.000000e+02           NA\n97            NA           NA           NA 1.000000e+02           NA\n98            NA           NA           NA 1.000000e+02           NA\n99  3.294847e+06 3.328520e+06 3.355125e+06 3.443100e+06 3.552128e+06\n100 4.055866e+08 4.877095e+08 5.966480e+08 6.955307e+08 7.648045e+08\n            1991         1992         1993         1994         1995\n1             NA           NA           NA           NA           NA\n2   4.828200e+01 4.960700e+01 5.229600e+01 5.313500e+01 5.369400e+01\n3   4.295900e+01 4.376500e+01 4.975500e+01 4.888300e+01 5.053600e+01\n4   4.552100e+01 4.656900e+01 5.102100e+01 5.096900e+01 5.210300e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.223888e+07 1.327897e+07 1.494317e+07 1.625079e+07 1.706584e+07\n12  1.099559e+09 6.521750e+08 1.185315e+09 1.880951e+09 2.392765e+09\n13  7.645200e+01 7.672000e+01 7.700000e+01 7.720600e+01 7.740700e+01\n14  6.970500e+01 7.001400e+01 7.038000e+01 7.056600e+01 7.073400e+01\n15  7.300100e+01 7.330300e+01 7.363800e+01 7.383700e+01 7.402200e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  3.266790e+06 3.247039e+06 3.227287e+06 3.207536e+06 3.187784e+06\n23  4.571568e+10 4.800313e+10 4.994558e+10 4.254318e+10 4.176429e+10\n24  6.851200e+01 6.872700e+01 6.913900e+01 6.921900e+01 6.953500e+01\n25  6.690100e+01 6.677000e+01 6.654800e+01 6.552400e+01 6.600300e+01\n26  6.769200e+01 6.772500e+01 6.779700e+01 6.728400e+01 6.769100e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  2.598793e+07 2.662857e+07 2.727705e+07 2.788728e+07 2.847019e+07\n34            NA           NA           NA           NA           NA\n35  7.555100e+01 7.578400e+01 7.566200e+01 7.555400e+01 7.542200e+01\n36  6.788300e+01 6.803400e+01 6.816100e+01 6.828500e+01 6.837500e+01\n37  7.131200e+01 7.151100e+01 7.154000e+01 7.156900e+01 7.156500e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  4.788200e+04 4.903800e+04 5.015900e+04 5.125100e+04 5.231600e+04\n45  1.106891e+09 1.209992e+09 1.007090e+09 1.017544e+09 1.178745e+09\n46  8.347100e+01 8.360900e+01 8.382300e+01 8.408500e+01 8.429400e+01\n47  7.636700e+01 7.702100e+01 7.754900e+01 7.807100e+01 7.820700e+01\n48  7.934600e+01 7.979400e+01 8.018600e+01 8.058700e+01 8.080400e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  5.666700e+04 6.020000e+04 6.327200e+04 6.461200e+04 6.391200e+04\n56  1.060378e+10 8.307811e+09 5.768720e+09 4.438321e+09 5.538749e+09\n57  4.684400e+01 4.556300e+01 4.672300e+01 4.774500e+01 4.816000e+01\n58  4.099100e+01 3.924300e+01 3.822700e+01 3.981900e+01 4.414500e+01\n59  4.381200e+01 4.226700e+01 4.219000e+01 4.356700e+01 4.613900e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  1.202353e+07 1.242371e+07 1.282714e+07 1.324976e+07 1.369978e+07\n67  5.043074e+08 5.251037e+08 5.656333e+08 6.250519e+08 6.160148e+08\n68  7.622000e+01 7.612800e+01 7.616800e+01 7.634700e+01 7.652600e+01\n69  7.069500e+01 7.062200e+01 7.059400e+01 7.062100e+01 7.060700e+01\n70  7.347200e+01 7.338600e+01 7.339000e+01 7.349300e+01 7.357600e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.338700e+04 6.440400e+04 6.558700e+04 6.684300e+04 6.818900e+04\n78  1.897200e+11 2.287789e+11 2.367417e+11 2.574400e+11 2.580318e+11\n79  7.534400e+01 7.549600e+01 7.570700e+01 7.590900e+01 7.617000e+01\n80  6.868100e+01 6.869100e+01 6.889200e+01 6.950100e+01 6.952100e+01\n81  7.202000e+01 7.209600e+01 7.230300e+01 7.273200e+01 7.286400e+01\n82  9.600000e+01           NA           NA           NA           NA\n83  9.600000e+01           NA           NA           NA           NA\n84  9.600000e+01           NA           NA           NA           NA\n85  9.900000e+01           NA           NA           NA           NA\n86  9.800000e+01           NA           NA           NA           NA\n87  9.800000e+01           NA           NA           NA           NA\n88  3.323029e+07 3.369353e+07 3.415272e+07 3.461349e+07 3.507002e+07\n89  2.069870e+09 1.272835e+09 1.201313e+09 1.315159e+09 1.468317e+09\n90  7.169900e+01 7.189600e+01 7.214400e+01 7.237500e+01 7.261900e+01\n91  6.374900e+01 6.374000e+01 6.400100e+01 6.436400e+01 6.482800e+01\n92  6.762705e+01 6.771854e+01 6.797320e+01 6.827180e+01 6.862849e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  3.613977e+06 3.571861e+06 3.453332e+06 3.364610e+06 3.307581e+06\n100 8.720670e+08 9.586592e+08 1.083240e+09 1.245810e+09 1.320670e+09\n            1996         1997         1998         1999         2000\n1             NA           NA           NA           NA 3.521418e+09\n2   5.442600e+01 5.472000e+01 5.439200e+01 5.596600e+01 5.655500e+01\n3   5.126000e+01 5.172500e+01 5.063600e+01 5.310200e+01 5.346300e+01\n4   5.283000e+01 5.321200e+01 5.248700e+01 5.453200e+01 5.500500e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  1.776327e+07 1.845209e+07 1.916000e+07 1.988778e+07 2.013033e+07\n12  3.199641e+09 2.258514e+09 2.545965e+09 3.212122e+09 3.480355e+09\n13  7.753300e+01 7.705200e+01 7.772500e+01 7.782200e+01 7.792600e+01\n14  7.079800e+01 6.986600e+01 7.109200e+01 7.140500e+01 7.180400e+01\n15  7.411300e+01 7.338300e+01 7.435700e+01 7.456800e+01 7.482600e+01\n16            NA           NA           NA           NA           NA\n17            NA           NA           NA           NA           NA\n18            NA           NA           NA           NA           NA\n19            NA           NA           NA           NA           NA\n20            NA           NA           NA           NA           NA\n21            NA           NA           NA           NA           NA\n22  3.168033e+06 3.148281e+06 3.128530e+06 3.108778e+06 3.089027e+06\n23  4.694155e+10 4.817761e+10 4.818778e+10 4.864067e+10 5.479040e+10\n24  6.991800e+01 7.051700e+01 7.103100e+01 7.151000e+01 7.194400e+01\n25  6.665000e+01 6.732400e+01 6.775000e+01 6.875400e+01 6.928900e+01\n26  6.821900e+01 6.885900e+01 6.932700e+01 7.008800e+01 7.057600e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  2.903304e+07 2.957930e+07 3.005413e+07 3.047435e+07 3.090389e+07\n34            NA           NA           NA           NA           NA\n35  7.532200e+01 7.524600e+01 7.489000e+01 7.459100e+01 7.435100e+01\n36  6.846800e+01 6.857100e+01 6.871300e+01 6.882200e+01 6.891100e+01\n37  7.157600e+01 7.160600e+01 7.154200e+01 7.148400e+01 7.144300e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  5.335300e+04 5.436200e+04 5.533400e+04 5.624800e+04 5.685500e+04\n45  1.224024e+09 1.180646e+09 1.211954e+09 1.240295e+09 1.432606e+09\n46  8.451000e+01 8.471300e+01 8.486400e+01 8.506800e+01 8.509800e+01\n47  7.839200e+01 7.847900e+01 7.857700e+01 7.885600e+01 7.935300e+01\n48  8.100900e+01 8.114500e+01 8.128000e+01 8.155000e+01 8.186300e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  6.398400e+04 6.470000e+04 6.538200e+04 6.571000e+04 6.568500e+04\n56  7.526447e+09 7.648377e+09 6.506230e+09 6.152923e+09 9.129595e+09\n57  4.840200e+01 4.868400e+01 4.804700e+01 4.900300e+01 4.913200e+01\n58  4.445700e+01 4.471600e+01 4.295400e+01 4.279900e+01 4.396300e+01\n59  4.641800e+01 4.668800e+01 4.545200e+01 4.580800e+01 4.650100e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  1.417097e+07 1.466041e+07 1.515937e+07 1.566724e+07 1.619487e+07\n67  6.791111e+08 7.343926e+08 7.897630e+08 8.355148e+08 9.005519e+08\n68  7.694900e+01 7.730400e+01 7.751700e+01 7.786400e+01 7.829500e+01\n69  7.071800e+01 7.078200e+01 7.082600e+01 7.099100e+01 7.125900e+01\n70  7.383900e+01 7.404500e+01 7.418700e+01 7.445600e+01 7.481900e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  6.961200e+04 7.105300e+04 7.241200e+04 7.366600e+04 7.491200e+04\n78  2.721498e+11 2.928590e+11 2.989482e+11 2.835230e+11 2.842038e+11\n79  7.643300e+01 7.683800e+01 7.687600e+01 7.707500e+01 7.728800e+01\n80  6.965600e+01 6.995000e+01 6.993500e+01 7.026300e+01 7.049800e+01\n81  7.305600e+01 7.340700e+01 7.341200e+01 7.368300e+01 7.391000e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  3.551379e+07 3.594779e+07 3.637286e+07 3.679468e+07 3.721398e+07\n89  1.596969e+09 1.639492e+09 1.893726e+09 1.845482e+09 1.911564e+09\n90  7.286500e+01 7.311800e+01 7.339700e+01 7.368700e+01 7.580000e+01\n91  6.533100e+01 6.584700e+01 6.637300e+01 6.687700e+01 7.010000e+01\n92  6.900612e+01 6.939383e+01 6.979934e+01 7.019895e+01 7.288049e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA 1.000000e+02\n97            NA           NA           NA           NA 1.000000e+02\n98            NA           NA           NA           NA 1.000000e+02\n99  3.278735e+06 3.246289e+06 3.208401e+06 3.167286e+06 3.221100e+06\n100 1.379888e+09 1.531844e+09 1.665363e+09 1.722905e+09 1.873453e+09\n            2001         2002         2003         2004         2005\n1   2.813572e+09 3.825701e+09 4.520947e+09 5.224897e+09 6.203257e+09\n2   5.708900e+01 5.744200e+01 5.847200e+01 5.907300e+01 5.958800e+01\n3   5.394100e+01 5.498600e+01 5.584900e+01 5.651900e+01 5.688000e+01\n4   5.551100e+01 5.622500e+01 5.717100e+01 5.781000e+01 5.824700e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  2.028431e+07 2.137812e+07 2.273305e+07 2.356065e+07 2.440457e+07\n12  3.922101e+09 4.348068e+09 5.611496e+09 7.184686e+09 8.052077e+09\n13  7.803100e+01 7.814200e+01 7.832900e+01 7.875300e+01 7.930300e+01\n14  7.220400e+01 7.252900e+01 7.286400e+01 7.324200e+01 7.366300e+01\n15  7.508300e+01 7.529900e+01 7.555700e+01 7.595100e+01 7.642700e+01\n16  9.800000e+01           NA           NA           NA           NA\n17  9.900000e+01           NA           NA           NA           NA\n18  9.900000e+01           NA           NA           NA           NA\n19  9.900000e+01           NA           NA           NA 9.949000e+01\n20  9.900000e+01           NA           NA           NA           NA\n21  9.900000e+01           NA           NA           NA           NA\n22  3.060173e+06 3.051010e+06 3.039616e+06 3.026939e+06 3.011487e+06\n23  5.941340e+10 6.151610e+10 7.348226e+10 9.191368e+10 1.070466e+11\n24  7.229500e+01 7.284200e+01 7.302700e+01 7.364200e+01 7.396200e+01\n25  6.982300e+01 7.050500e+01 7.083700e+01 7.147800e+01 7.176000e+01\n26  7.102500e+01 7.164400e+01 7.190600e+01 7.253600e+01 7.283600e+01\n27            NA 6.000000e+01           NA           NA           NA\n28            NA 7.900000e+01           NA           NA           NA\n29            NA 7.000000e+01           NA           NA           NA\n30            NA 8.600000e+01           NA           NA           NA\n31            NA 9.400000e+01           NA           NA           NA\n32            NA 9.000000e+01           NA           NA           NA\n33  3.133122e+07 3.175084e+07 3.217582e+07 3.262829e+07 3.310925e+07\n34            NA 5.120000e+08 5.240000e+08 5.090000e+08 5.000000e+08\n35  7.448300e+01 7.465700e+01 7.459000e+01 7.512500e+01 7.512500e+01\n36  6.904100e+01 6.923100e+01 6.918300e+01 6.979100e+01 6.997300e+01\n37  7.157300e+01 7.175500e+01 7.169800e+01 7.227700e+01 7.238200e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  5.705300e+04 5.706200e+04 5.697100e+04 5.681800e+04 5.661700e+04\n45  1.548266e+09 1.764280e+09 2.366942e+09 2.900245e+09 3.161084e+09\n46  8.516700e+01 8.513000e+01 8.511600e+01 8.497900e+01 8.527200e+01\n47  7.977800e+01 8.026600e+01 8.073400e+01 8.099000e+01 8.124000e+01\n48  8.216200e+01 8.244800e+01 8.271800e+01 8.281500e+01 8.308600e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  6.585200e+04 6.650600e+04 6.948600e+04 7.432500e+04 7.742100e+04\n56  8.936079e+09 1.528559e+10 1.781270e+10 2.355206e+10 3.697090e+10\n57  5.004700e+01 5.036700e+01 5.218100e+01 5.307400e+01 5.405100e+01\n58  4.416200e+01 4.544600e+01 4.825800e+01 4.917000e+01 5.020300e+01\n59  4.703200e+01 4.787400e+01 5.021800e+01 5.112300e+01 5.213000e+01\n60  5.400000e+01           NA           NA           NA           NA\n61  8.300000e+01           NA           NA           NA           NA\n62  6.700000e+01           NA           NA           NA           NA\n63  6.300000e+01           NA           NA           NA           NA\n64  8.400000e+01           NA           NA           NA           NA\n65  7.200000e+01           NA           NA           NA           NA\n66  1.674721e+07 1.732770e+07 1.794371e+07 1.860042e+07 1.929116e+07\n67  8.775148e+08 8.979889e+08 9.479556e+08 1.026181e+09 1.143715e+09\n68  7.859200e+01 7.851900e+01 7.827600e+01 7.817900e+01 7.829800e+01\n69  7.153100e+01 7.181800e+01 7.215300e+01 7.227200e+01 7.223600e+01\n70  7.510800e+01 7.523700e+01 7.531300e+01 7.532900e+01 7.536400e+01\n71  9.900000e+01           NA           NA           NA           NA\n72  9.800000e+01           NA           NA           NA           NA\n73  9.900000e+01           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  7.606900e+04 7.703200e+04 7.788400e+04 7.871900e+04 7.961100e+04\n78  2.686968e+11 9.772400e+10 1.275870e+11 1.646579e+11 1.987371e+11\n79  7.764200e+01 7.791100e+01 7.780800e+01 7.817700e+01 7.863200e+01\n80  7.063700e+01 7.070400e+01 7.079600e+01 7.150000e+01 7.176700e+01\n81  7.415400e+01 7.431200e+01 7.430700e+01 7.487100e+01 7.523100e+01\n82  9.700000e+01           NA           NA           NA           NA\n83  9.700000e+01           NA           NA           NA           NA\n84  9.700000e+01           NA           NA           NA           NA\n85  9.900000e+01           NA           NA           NA           NA\n86  9.900000e+01           NA           NA           NA           NA\n87  9.900000e+01           NA           NA           NA           NA\n88  3.762482e+07 3.802935e+07 3.842428e+07 3.881592e+07 3.921679e+07\n89  2.118468e+09 2.376335e+09 2.807061e+09 3.576615e+09 4.900470e+09\n90  7.610000e+01 7.590000e+01 7.590000e+01 7.610000e+01 7.620000e+01\n91  7.000000e+01 6.990000e+01 6.990000e+01 7.010000e+01 7.010000e+01\n92  7.297561e+01 7.282683e+01 7.282683e+01 7.302683e+01 7.307561e+01\n93  9.900000e+01           NA           NA           NA           NA\n94  1.000000e+02           NA           NA           NA           NA\n95  9.900000e+01           NA           NA           NA           NA\n96  1.000000e+02           NA           NA           NA           NA\n97  1.000000e+02           NA           NA           NA           NA\n98  1.000000e+02           NA           NA           NA           NA\n99  3.211800e+06 3.199800e+06 3.182500e+06 3.164900e+06 3.146400e+06\n100 1.896457e+09 1.961844e+09 2.044112e+09 2.254831e+09 2.360017e+09\n            2006         2007         2008         2009         2010\n1   6.971758e+09 9.747886e+09 1.010930e+10 1.241615e+10 1.585667e+10\n2   6.012300e+01 6.080400e+01 6.142800e+01 6.179100e+01 6.228300e+01\n3   5.697400e+01 5.712200e+01 5.798400e+01 5.868100e+01 5.909700e+01\n4   5.855300e+01 5.895600e+01 5.970800e+01 6.024800e+01 6.070200e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  2.542409e+07 2.590985e+07 2.648262e+07 2.746610e+07 2.828409e+07\n12  8.896075e+09 1.067732e+10 1.288135e+10 1.204421e+10 1.192693e+10\n13  7.994300e+01 8.058400e+01 8.107600e+01 8.128200e+01 8.110800e+01\n14  7.418300e+01 7.492200e+01 7.553100e+01 7.584200e+01 7.582500e+01\n15  7.699400e+01 7.769100e+01 7.824800e+01 7.850900e+01 7.841400e+01\n16            NA           NA 9.500000e+01           NA           NA\n17            NA           NA 9.700000e+01           NA           NA\n18            NA           NA 9.600000e+01           NA           NA\n19            NA           NA 9.900000e+01 9.661000e+01           NA\n20            NA           NA 9.900000e+01 9.482000e+01           NA\n21            NA           NA 9.900000e+01 9.568000e+01           NA\n22  2.992547e+06 2.970017e+06 2.947314e+06 2.927519e+06 2.913021e+06\n23  1.230843e+11 1.424827e+11 1.803838e+11 1.503173e+11 1.777851e+11\n24  7.428300e+01 7.455600e+01 7.482700e+01 7.507400e+01 7.531900e+01\n25  7.200300e+01 7.219200e+01 7.246400e+01 7.272100e+01 7.301700e+01\n26  7.311600e+01 7.334600e+01 7.361800e+01 7.387100e+01 7.414400e+01\n27  6.400000e+01           NA 6.800000e+01           NA           NA\n28  8.100000e+01           NA 8.300000e+01           NA           NA\n29  7.300000e+01           NA 7.500000e+01           NA           NA\n30  8.900000e+01           NA 9.200000e+01           NA           NA\n31  9.400000e+01           NA 9.600000e+01           NA           NA\n32  9.200000e+01           NA 9.400000e+01           NA           NA\n33  3.362351e+07 3.418942e+07 3.481696e+07 3.549044e+07 3.618824e+07\n34  4.930000e+08 5.180000e+08 5.600000e+08 6.750000e+08 5.730000e+08\n35  7.504300e+01 7.494700e+01 7.503000e+01 7.312300e+01 7.519900e+01\n36  7.006100e+01 7.007200e+01 7.011600e+01 6.878900e+01 7.024000e+01\n37  7.239700e+01 7.236500e+01 7.243000e+01 7.083900e+01 7.258700e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  5.637400e+04 5.611300e+04 5.582800e+04 5.552800e+04 5.522800e+04\n45  3.459338e+09 3.957625e+09 4.102319e+09 3.688976e+09 3.449926e+09\n46  8.559300e+01 8.597600e+01 8.629200e+01 8.661100e+01 8.668400e+01\n47  8.150100e+01 8.167600e+01 8.184600e+01 8.203700e+01 8.213800e+01\n48  8.337400e+01 8.363200e+01 8.385500e+01 8.410000e+01 8.419700e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  7.958500e+04 8.187700e+04 8.349500e+04 8.388800e+04 8.070600e+04\n56  5.238103e+10 6.526642e+10 8.853867e+10 7.030720e+10 8.379947e+10\n57  5.481100e+01 5.604100e+01 5.716200e+01 5.812900e+01 5.922100e+01\n58  5.110700e+01 5.234500e+01 5.338600e+01 5.430800e+01 5.525300e+01\n59  5.296500e+01 5.420000e+01 5.528100e+01 5.622500e+01 5.724200e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  2.001528e+07 2.077856e+07 2.157866e+07 2.241477e+07 2.329482e+07\n67  1.303548e+09 1.487300e+09 1.557541e+09 1.386444e+09 1.298256e+09\n68  7.857500e+01 7.881700e+01 7.916500e+01 7.950900e+01 7.987900e+01\n69  7.225400e+01 7.243200e+01 7.277800e+01 7.304900e+01 7.330500e+01\n70  7.550600e+01 7.572000e+01 7.607500e+01 7.638600e+01 7.670100e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  8.060400e+04 8.170400e+04 8.291200e+04 8.417300e+04 8.532000e+04\n78  2.325573e+11 2.875305e+11 3.615580e+11 3.329765e+11 4.236274e+11\n79  7.843700e+01 7.792500e+01 7.857700e+01 7.859300e+01 7.873200e+01\n80  7.202100e+01 7.157400e+01 7.219200e+01 7.244900e+01 7.254200e+01\n81  7.527900e+01 7.478300e+01 7.542800e+01 7.557700e+01 7.568000e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  3.962212e+07 4.001676e+07 4.042415e+07 4.085483e+07 4.128869e+07\n89  6.384452e+09 9.206301e+09 1.166204e+10 8.647937e+09 9.260286e+09\n90  7.600000e+01 7.610000e+01 7.630000e+01 7.630000e+01 7.640000e+01\n91  6.980000e+01 6.980000e+01 7.000000e+01 7.000000e+01 7.010000e+01\n92  7.282439e+01 7.287317e+01 7.307317e+01 7.307317e+01 7.317317e+01\n93            NA           NA           NA           NA           NA\n94            NA           NA           NA           NA           NA\n95            NA           NA           NA           NA           NA\n96            NA           NA           NA           NA           NA\n97            NA           NA           NA           NA           NA\n98            NA           NA           NA           NA           NA\n99  3.127100e+06 3.107400e+06 3.087100e+06 3.066000e+06 3.044800e+06\n100 2.469783e+09 2.677641e+09 2.843025e+09 2.553793e+09 2.453597e+09\n            2011         2012         2013         2014         2015\n1   1.780510e+10 1.990733e+10 2.014642e+10 2.049713e+10 1.913422e+10\n2   6.285200e+01 6.334400e+01 6.381400e+01 6.400900e+01 6.417800e+01\n3   5.962500e+01 6.009900e+01 6.053400e+01 6.049500e+01 6.036300e+01\n4   6.125000e+01 6.173500e+01 6.218800e+01 6.226000e+01 6.227000e+01\n5   1.700000e+01           NA           NA           NA 1.708624e+01\n6   4.500000e+01           NA           NA           NA 5.021210e+01\n7   3.100000e+01           NA           NA           NA 3.375384e+01\n8   3.200000e+01           NA           NA           NA 2.548416e+01\n9   6.200000e+01           NA           NA           NA 5.773505e+01\n10  4.700000e+01           NA           NA           NA 3.582084e+01\n11  2.934771e+07 3.056003e+07 3.162270e+07 3.279252e+07 3.383176e+07\n12  1.289076e+10 1.231983e+10 1.277622e+10 1.322815e+10 1.138685e+10\n13  8.091600e+01 8.058900e+01 8.038700e+01 8.026700e+01 8.045100e+01\n14  7.579200e+01 7.566000e+01 7.566600e+01 7.583000e+01 7.628100e+01\n15  7.830300e+01 7.808400e+01 7.799500e+01 7.802900e+01 7.835800e+01\n16  9.600000e+01 9.600000e+01           NA           NA           NA\n17  9.800000e+01 9.800000e+01           NA           NA           NA\n18  9.700000e+01 9.700000e+01           NA           NA           NA\n19  9.900000e+01 9.900000e+01           NA           NA           NA\n20  9.900000e+01 9.900000e+01           NA           NA           NA\n21  9.900000e+01 9.900000e+01           NA           NA           NA\n22  2.905195e+06 2.900401e+06 2.895092e+06 2.889104e+06 2.880703e+06\n23  2.183319e+11 2.271437e+11 2.297014e+11 2.389427e+11 1.874939e+11\n24  7.554700e+01 7.576900e+01 7.598600e+01 7.618300e+01 7.637700e+01\n25  7.326600e+01 7.349300e+01 7.368000e+01 7.385000e+01 7.399200e+01\n26  7.438300e+01 7.460900e+01 7.480900e+01 7.499200e+01 7.515900e+01\n27            NA           NA           NA           NA           NA\n28            NA           NA           NA           NA           NA\n29            NA           NA           NA           NA           NA\n30            NA           NA           NA           NA           NA\n31            NA           NA           NA           NA           NA\n32            NA           NA           NA           NA           NA\n33  3.690338e+07 3.764617e+07 3.841417e+07 3.920503e+07 4.001953e+07\n34  5.700000e+08 6.400000e+08 6.380000e+08 6.430000e+08 6.730000e+08\n35  7.528600e+01 7.537200e+01 7.541800e+01 7.529600e+01 7.526800e+01\n36  7.029600e+01 7.030900e+01 7.037900e+01 7.033000e+01 7.029400e+01\n37  7.266200e+01 7.270900e+01 7.276900e+01 7.268700e+01 7.265400e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  5.489500e+04 5.448900e+04 5.400600e+04 5.346600e+04 5.287800e+04\n45  3.629134e+09 3.188653e+09 3.193513e+09 3.271686e+09 2.789881e+09\n46  8.669200e+01 8.666900e+01 8.665200e+01 8.662600e+01 8.658400e+01\n47  8.218800e+01 8.227100e+01 8.236100e+01 8.249300e+01 8.258100e+01\n48  8.429600e+01 8.433400e+01 8.440600e+01 8.448500e+01 8.453200e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  7.778300e+04 7.683400e+04 7.519400e+04 7.373700e+04 7.217400e+04\n56  1.117897e+11 1.280529e+11 1.323391e+11 1.359668e+11 9.049642e+10\n57  6.021000e+01 6.115700e+01 6.200900e+01 6.272800e+01 6.341200e+01\n58  5.597600e+01 5.667700e+01 5.740400e+01 5.806800e+01 5.868000e+01\n59  5.809300e+01 5.891600e+01 5.970500e+01 6.039600e+01 6.104200e+01\n60            NA           NA           NA 5.300000e+01 5.192598e+01\n61            NA           NA           NA 8.000000e+01 8.377277e+01\n62            NA           NA           NA 6.600000e+01 6.623586e+01\n63            NA           NA           NA 7.100000e+01 6.742760e+01\n64            NA           NA           NA 8.500000e+01 8.396919e+01\n65            NA           NA           NA 7.700000e+01 7.566081e+01\n66  2.421835e+07 2.517739e+07 2.616562e+07 2.716077e+07 2.815780e+07\n67  1.281337e+09 1.327107e+09 1.325426e+09 1.378830e+09 1.437756e+09\n68  8.023400e+01 8.037900e+01 8.032500e+01 8.013800e+01 7.997300e+01\n69  7.357900e+01 7.358800e+01 7.353700e+01 7.343800e+01 7.353600e+01\n70  7.702300e+01 7.710000e+01 7.705000e+01 7.691200e+01 7.689200e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  8.633200e+04 8.726000e+04 8.806400e+04 8.876500e+04 8.940900e+04\n78  5.301581e+11 5.459824e+11 5.520251e+11 5.263197e+11 5.947493e+11\n79  7.940200e+01 7.867200e+01 7.862300e+01 7.915000e+01 7.979500e+01\n80  7.273900e+01 7.285100e+01 7.296300e+01 7.330300e+01 7.336700e+01\n81  7.610000e+01 7.580200e+01 7.582900e+01 7.626800e+01 7.660000e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  4.173066e+07 4.216172e+07 4.258246e+07 4.302407e+07 4.347701e+07\n89  1.014211e+10 1.061932e+10 1.112146e+10 1.160951e+10 1.055334e+10\n90  7.730000e+01 7.750000e+01 7.790000e+01 7.810000e+01 7.820000e+01\n91  7.050000e+01 7.090000e+01 7.150000e+01 7.180000e+01 7.170000e+01\n92  7.381707e+01 7.411951e+01 7.462195e+01 7.487317e+01 7.487073e+01\n93  1.000000e+02           NA           NA           NA           NA\n94  1.000000e+02           NA           NA           NA           NA\n95  1.000000e+02           NA           NA           NA           NA\n96  1.000000e+02           NA           NA           NA           NA\n97  1.000000e+02           NA           NA           NA           NA\n98  1.000000e+02           NA           NA           NA           NA\n99  3.027900e+06 3.024100e+06 3.022000e+06 3.013800e+06 3.004600e+06\n100 2.637859e+09 2.615208e+09 2.727850e+09 2.790850e+09 2.962907e+09\n            2016         2017         2018         2019         2020\n1   1.811657e+10 1.875346e+10 1.805322e+10 1.879944e+10 1.995593e+10\n2   6.464000e+01 6.560600e+01 6.594200e+01 6.614400e+01 6.465600e+01\n3   6.066100e+01 5.938800e+01 5.917500e+01 5.991000e+01 5.845500e+01\n4   6.264600e+01 6.240600e+01 6.244300e+01 6.294100e+01 6.145400e+01\n5             NA           NA           NA           NA           NA\n6             NA           NA           NA           NA           NA\n7             NA           NA           NA           NA           NA\n8             NA           NA           NA           NA           NA\n9             NA           NA           NA           NA           NA\n10            NA           NA           NA           NA           NA\n11  3.470061e+07 3.568894e+07 3.674304e+07 3.785612e+07 3.906898e+07\n12  1.186120e+10 1.301973e+10 1.537951e+10 1.558511e+10 1.524146e+10\n13  8.062500e+01 8.079500e+01 8.100100e+01 8.106000e+01 8.034500e+01\n14  7.666200e+01 7.699700e+01 7.744800e+01 7.783400e+01 7.542900e+01\n15  7.864300e+01 7.890000e+01 7.923800e+01 7.946700e+01 7.782400e+01\n16            NA 9.904904e+01           NA           NA           NA\n17            NA 9.857200e+01           NA           NA           NA\n18            NA 9.881623e+01           NA           NA           NA\n19            NA 9.952556e+01           NA           NA           NA\n20            NA 9.858999e+01           NA           NA           NA\n21            NA 9.902406e+01           NA           NA           NA\n22  2.876101e+06 2.873457e+06 2.866376e+06 2.854191e+06 2.837849e+06\n23  1.807638e+11 1.898809e+11 1.945545e+11 1.934597e+11 1.648734e+11\n24  7.657000e+01 7.675000e+01 7.692800e+01 7.709100e+01 7.494300e+01\n25  7.410600e+01 7.417700e+01 7.425500e+01 7.435000e+01 7.173300e+01\n26  7.531000e+01 7.543100e+01 7.555500e+01 7.568200e+01 7.325700e+01\n27            NA           NA 7.532297e+01 7.421020e+01           NA\n28            NA           NA 8.742296e+01           NA           NA\n29            NA           NA 8.140784e+01           NA           NA\n30            NA           NA 9.725216e+01 9.798970e+01           NA\n31            NA           NA 9.759406e+01 6.479000e+01           NA\n32            NA           NA 9.742652e+01 7.403000e+01           NA\n33  4.085072e+07 4.168930e+07 4.250504e+07 4.329455e+07 4.404209e+07\n34  6.710000e+08 6.120000e+08 6.390000e+08 6.470000e+08 7.210000e+08\n35  7.530500e+01 7.558800e+01 7.568700e+01 7.572300e+01 7.568200e+01\n36  7.024000e+01 7.030400e+01 7.021100e+01 7.010500e+01 6.999500e+01\n37  7.264000e+01 7.280100e+01 7.279400e+01 7.275100e+01 7.267200e+01\n38            NA           NA           NA           NA           NA\n39            NA           NA           NA           NA           NA\n40            NA           NA           NA           NA           NA\n41            NA           NA           NA           NA           NA\n42            NA           NA           NA           NA           NA\n43            NA           NA           NA           NA           NA\n44  5.224500e+04 5.158600e+04 5.090800e+04 5.020900e+04 4.976100e+04\n45  2.896610e+09 3.000162e+09 3.218420e+09 3.155149e+09 2.891001e+09\n46  8.646800e+01 8.632200e+01 8.619600e+01 8.610100e+01 8.384000e+01\n47  8.256900e+01 8.246200e+01 8.235900e+01 8.218300e+01 7.582300e+01\n48  8.448900e+01 8.435900e+01 8.424200e+01 8.409800e+01 7.941800e+01\n49            NA           NA           NA           NA           NA\n50            NA           NA           NA           NA           NA\n51            NA           NA           NA           NA           NA\n52            NA           NA           NA           NA           NA\n53            NA           NA           NA           NA           NA\n54            NA           NA           NA           NA           NA\n55  7.218100e+04 7.376300e+04 7.516200e+04 7.647400e+04 7.738000e+04\n56  5.276162e+10 7.369015e+10 7.945069e+10 7.089796e+10 4.850156e+10\n57  6.400900e+01 6.452700e+01 6.505700e+01 6.550600e+01 6.577400e+01\n58  5.923700e+01 5.972700e+01 6.019900e+01 6.060900e+01 6.050900e+01\n59  6.161900e+01 6.212200e+01 6.262200e+01 6.305100e+01 6.311600e+01\n60            NA           NA           NA           NA           NA\n61            NA           NA           NA           NA           NA\n62            NA           NA           NA           NA           NA\n63            NA           NA           NA           NA           NA\n64            NA           NA           NA           NA           NA\n65            NA           NA           NA           NA           NA\n66  2.918307e+07 3.023484e+07 3.129716e+07 3.237563e+07 3.345113e+07\n67  1.489693e+09 1.531152e+09 1.661530e+09 1.725352e+09 1.410796e+09\n68  7.992300e+01 7.988000e+01 7.988700e+01 7.984400e+01 7.981300e+01\n69  7.371100e+01 7.385900e+01 7.404000e+01 7.414300e+01 7.415700e+01\n70  7.696800e+01 7.703000e+01 7.713200e+01 7.716800e+01 7.716100e+01\n71            NA           NA           NA           NA           NA\n72            NA           NA           NA           NA           NA\n73            NA           NA           NA           NA           NA\n74            NA           NA           NA           NA           NA\n75            NA           NA           NA           NA           NA\n76            NA           NA           NA           NA           NA\n77  8.996900e+04 9.046800e+04 9.092600e+04 9.136400e+04 9.184600e+04\n78  5.575323e+11 6.436284e+11 5.248199e+11 4.477547e+11 3.857405e+11\n79  7.913100e+01 7.920400e+01 7.950500e+01 7.943900e+01 7.878300e+01\n80  7.304400e+01 7.379100e+01 7.395100e+01 7.416300e+01 7.298100e+01\n81  7.610500e+01 7.654300e+01 7.677000e+01 7.684700e+01 7.587800e+01\n82            NA           NA           NA           NA           NA\n83            NA           NA           NA           NA           NA\n84            NA           NA           NA           NA           NA\n85            NA           NA           NA           NA           NA\n86            NA           NA           NA           NA           NA\n87            NA           NA           NA           NA           NA\n88  4.390031e+07 4.428889e+07 4.465488e+07 4.497346e+07 4.519196e+07\n89  1.054614e+10 1.152746e+10 1.245794e+10 1.361929e+10 1.264170e+10\n90  7.830000e+01 7.870000e+01 7.900000e+01 7.950000e+01 7.860000e+01\n91  7.160000e+01 7.190000e+01 7.240000e+01 7.310000e+01 6.840000e+01\n92  7.486829e+01 7.521707e+01 7.561951e+01 7.622195e+01 7.337561e+01\n93  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n94  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n95  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n96  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n97  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n98  1.000000e+02 1.000000e+02           NA           NA 1.000000e+02\n99  2.992300e+06 2.979400e+06 2.969000e+06 2.962500e+06 2.961500e+06\n100 2.983635e+09 3.092429e+09 3.276184e+09 3.395799e+09 2.481857e+09\n            2021         2022         2023 2024\n1   1.426000e+10 1.449724e+10 1.723305e+10   NA\n2   6.407900e+01 6.723600e+01 6.753600e+01   NA\n3   5.705200e+01 6.394100e+01 6.446700e+01   NA\n4   6.041700e+01 6.561700e+01 6.603500e+01   NA\n5   2.300000e+01 2.659656e+01           NA   NA\n6   5.200000e+01           NA           NA   NA\n7   3.700000e+01           NA           NA   NA\n8   4.200000e+01 4.417171e+01           NA   NA\n9   7.100000e+01 8.340000e+01           NA   NA\n10  5.600000e+01 6.266000e+01           NA   NA\n11  4.000041e+07 4.057884e+07 4.145476e+07   NA\n12  1.803201e+10 1.901724e+10 2.354718e+10   NA\n13  7.900200e+01 8.078100e+01 8.144600e+01   NA\n14  7.474200e+01 7.675100e+01 7.772800e+01   NA\n15  7.684400e+01 7.876900e+01 7.960200e+01   NA\n16            NA 9.830000e+01           NA   NA\n17            NA 9.870000e+01           NA   NA\n18            NA 9.850000e+01           NA   NA\n19            NA 9.990000e+01           NA   NA\n20            NA 9.910000e+01           NA   NA\n21            NA 9.950000e+01           NA   NA\n22  2.811666e+06 2.777689e+06 2.745972e+06   NA\n23  1.862312e+11 2.256385e+11 2.476262e+11   NA\n24  7.665000e+01 7.759200e+01 7.769600e+01   NA\n25  7.384500e+01 7.474000e+01 7.489500e+01   NA\n26  7.520800e+01 7.612900e+01 7.626100e+01   NA\n27            NA           NA           NA   NA\n28            NA           NA           NA   NA\n29            NA           NA           NA   NA\n30            NA           NA           NA   NA\n31            NA           NA           NA   NA\n32            NA           NA           NA   NA\n33  4.476110e+07 4.547739e+07 4.616422e+07   NA\n34  7.500000e+08 8.710000e+08           NA   NA\n35  7.573000e+01 7.579400e+01 7.583800e+01   NA\n36  7.002300e+01 7.005500e+01 7.020200e+01   NA\n37  7.270800e+01 7.275200e+01 7.285200e+01   NA\n38            NA           NA           NA   NA\n39            NA           NA           NA   NA\n40            NA           NA           NA   NA\n41            NA           NA           NA   NA\n42            NA           NA           NA   NA\n43            NA           NA           NA   NA\n44  4.922500e+04 4.834200e+04 4.752100e+04   NA\n45  3.324648e+09 3.380613e+09 3.785067e+09   NA\n46  8.467800e+01 8.607500e+01 8.610700e+01   NA\n47  8.021600e+01 8.208300e+01 8.210000e+01   NA\n48  8.233100e+01 8.401600e+01 8.404100e+01   NA\n49            NA           NA           NA   NA\n50            NA           NA           NA   NA\n51            NA           NA           NA   NA\n52            NA           NA           NA   NA\n53            NA           NA           NA   NA\n54            NA           NA           NA   NA\n55  7.836400e+04 7.970500e+04 8.085600e+04   NA\n56  6.650513e+10 1.043997e+11 8.482465e+10   NA\n57  6.544100e+01 6.675300e+01 6.714400e+01   NA\n58  6.049800e+01 6.174800e+01 6.209900e+01   NA\n59  6.295800e+01 6.424600e+01 6.461700e+01   NA\n60            NA 6.250000e+01           NA   NA\n61            NA 8.280000e+01           NA   NA\n62            NA 7.240000e+01           NA   NA\n63            NA 8.070000e+01           NA   NA\n64            NA 8.590000e+01           NA   NA\n65            NA 8.330000e+01           NA   NA\n66  3.453243e+07 3.563503e+07 3.674991e+07   NA\n67  1.601367e+09 1.867733e+09 2.033085e+09   NA\n68  7.975700e+01 8.015400e+01 8.029400e+01   NA\n69  7.429500e+01 7.446100e+01 7.454900e+01   NA\n70  7.719700e+01 7.748300e+01 7.759800e+01   NA\n71            NA           NA           NA   NA\n72            NA           NA           NA   NA\n73            NA           NA           NA   NA\n74            NA           NA           NA   NA\n75            NA           NA           NA   NA\n76            NA           NA           NA   NA\n77  9.234900e+04 9.284000e+04 9.331600e+04   NA\n78  4.865641e+11 6.327901e+11 6.460753e+11   NA\n79  7.686000e+01 7.831800e+01 7.987500e+01   NA\n80  7.111300e+01 7.324900e+01 7.480500e+01   NA\n81  7.394800e+01 7.580600e+01 7.739500e+01   NA\n82            NA           NA           NA   NA\n83            NA           NA           NA   NA\n84            NA           NA           NA   NA\n85            NA           NA           NA   NA\n86            NA           NA           NA   NA\n87            NA           NA           NA   NA\n88  4.531228e+07 4.540790e+07 4.553840e+07   NA\n89  1.387891e+10 1.951351e+10 2.408575e+10   NA\n90  7.740000e+01 7.830000e+01 8.100000e+01   NA\n91  6.740000e+01 7.140000e+01 7.410000e+01   NA\n92  7.227805e+01 7.476585e+01 7.746585e+01   NA\n93            NA           NA           NA   NA\n94            NA           NA           NA   NA\n95            NA           NA           NA   NA\n96            NA           NA           NA   NA\n97            NA           NA           NA   NA\n98            NA           NA           NA   NA\n99  2.962300e+06 2.969200e+06 2.990900e+06   NA\n100 2.929447e+09 3.279344e+09 3.648573e+09   NA"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset-2",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset-2",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\nA Couple of Review Questions\n\nIs the dataframe tidy?\nIf not, what operation(s) are needed to tidy the dataframe?\n\n\nAnswers:\n\n\nThe dataframe is not tidy.\nWe need to both melt (to get the years in their own column) and pivot (to split the series names into separate columns; you’ll get practice with this in lab today)"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset-3",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset-3",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\nTidying\n\n\nCode\nwb_tidy &lt;- wb %&gt;% melt(\n  id.vars = c(\"Country Name\", \"Country Code\", \"Continent\", \"Series Name\"),\n  variable.name = \"Year\"\n) %&gt;%\n  pivot_wider(\n    names_from = `Series Name`\n  )\n\nwb_tidy %&gt;% head(100)\n\n\n# A tibble: 100 × 15\n   `Country Name`      `Country Code` Continent     Year  `GDP (current US$)`\n   &lt;chr&gt;               &lt;chr&gt;          &lt;chr&gt;         &lt;fct&gt;               &lt;dbl&gt;\n 1 Afghanistan         AFG            Asia          1960                  NA \n 2 Albania             ALB            Europe        1960                  NA \n 3 Algeria             DZA            Africa        1960          2723615451.\n 4 American Samoa      ASM            North America 1960                  NA \n 5 Andorra             AND            Europe        1960                  NA \n 6 Angola              AGO            Africa        1960                  NA \n 7 Antigua and Barbuda ATG            North America 1960                  NA \n 8 Argentina           ARG            South America 1960                  NA \n 9 Armenia             ARM            Europe        1960                  NA \n10 Aruba               ABW            North America 1960                  NA \n# ℹ 90 more rows\n# ℹ 10 more variables: `Life expectancy at birth, female (years)` &lt;dbl&gt;,\n#   `Life expectancy at birth, male (years)` &lt;dbl&gt;,\n#   `Life expectancy at birth, total (years)` &lt;dbl&gt;,\n#   `Literacy rate, adult female (% of females ages 15 and above)` &lt;dbl&gt;,\n#   `Literacy rate, adult male (% of males ages 15 and above)` &lt;dbl&gt;,\n#   `Literacy rate, adult total (% of people ages 15 and above)` &lt;dbl&gt;, …"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset-4",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset-4",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\nGDP vs. Life Expectancy, in 2014\n\n\nCode\nwb_tidy %&gt;% \n  filter(\n    Year == \"2014\"\n  ) %&gt;%\n  ggplot(aes(x = `Life expectancy at birth, total (years)`,\n             y = `GDP (current US$)`)) +\n  geom_point(size = 3) +\n  theme_minimal(base_size = 18) +\n  ggtitle(\"GDP vs. Life Expectancy\", subtitle = \"In 2014\")"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset-5",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset-5",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\nGDP vs. Life Expectancy, in 2014\n\nIt’s difficult to read this plot; the points are all clustered together.\n\nThis is because GDP has a huge spread!\n\nAs such, it will be beneficial to apply a transformation to the vertical axis.\nSpecifically, let’s see what happens if we compare log(GDP) to Total Life Expectancy."
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset-6",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset-6",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\nGDP vs. Life Expectancy, in 2014\n\n\nCode\nwb_tidy %&gt;% \n  filter(\n    Year == \"2014\"\n  ) %&gt;%\n  ggplot(aes(x = `Life expectancy at birth, total (years)`,\n             y = `GDP (current US$)`)) +\n  geom_point(size = 3) +\n  theme_minimal(base_size = 18) +\n  ggtitle(\"GDP vs. Life Expectancy\", subtitle = \"In 2014\") +\n  scale_y_log10() + ylab(\"log(GDP), in USD\")"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset-7",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset-7",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\nVariations across continents?\n\nFrom this last plot, it appears as though, on average, higher GDPs correspond to higher life expectancies at birth.\nQuestion: how (if at all) does this relationship change across continents?\n\nIn other words, how can we incorporate information from the Continent variable into our plot?\n\nAnswer: using aesthetics!\n\nFor example, we could color code each point based on the continent it belongs to."
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset-8",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset-8",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\nVariations across continents?\n\n\nCode\nwb_tidy %&gt;% \n  filter(\n    Year == \"2014\"\n  ) %&gt;%\n  ggplot(aes(x = `Life expectancy at birth, total (years)`,\n             y = `GDP (current US$)`)) +\n  geom_point(aes(colour = Continent), size = 3) +\n  theme_minimal(base_size = 18) +\n  ggtitle(\"GDP vs. Life Expectancy\", subtitle = \"In 2014\") +\n  scale_y_log10() + ylab(\"log(GDP), in USD\") +\n  labs(colour = \"Continent\")"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset-9",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset-9",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\nVariations across continents?\n\n\nCode\nwb_tidy %&gt;% \n  filter(\n    Year == \"2014\"\n  ) %&gt;%\n  ggplot(aes(x = `Life expectancy at birth, total (years)`,\n             y = `GDP (current US$)`)) +\n  geom_point(aes(colour = Continent,\n                 shape = Continent), size = 3) +\n  theme_minimal(base_size = 18) +\n  ggtitle(\"GDP vs. Life Expectancy\", subtitle = \"In 2014\") +\n  scale_y_log10() + ylab(\"log(GDP), in USD\") +\n  labs(colour = \"Continent\")"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset-10",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset-10",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\nVariations across continents?\n\nOkay, that’s a start!\n\nWe now have information about continents displayed in our graph.\nNote how neat that is - we have three variables displayed on a single graph!\n\nBut, this plot is difficult to read; the continents are all layered on top of each other.\nA useful trick to overcome this is called facetting, where we essentially break our plot up into a collection of plots.\nIn ggplot2, facetting is relatively easy, using either facet_wrap() or facet_grid()."
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#world-bank-dataset-11",
    "href": "Lectures/Lec04/Lec04.html#world-bank-dataset-11",
    "title": "PSTAT 100: Lecture 04",
    "section": " World Bank Dataset",
    "text": "World Bank Dataset\nVariations across continents?\n\n\nCode\nwb_tidy %&gt;% \n  filter(\n    Year == \"2014\"\n  ) %&gt;%\n  ggplot(aes(x = `Life expectancy at birth, total (years)`,\n             y = `GDP (current US$)`)) +\n  geom_point(size = 3) +\n  facet_wrap(~Continent) + \n  theme_minimal(base_size = 18) +\n  ggtitle(\"GDP vs. Life Expectancy\", subtitle = \"In 2014\") +\n  scale_y_log10() + ylab(\"log(GDP), in USD\") +\n  labs(colour = \"Continent\")"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#some-takeaways",
    "href": "Lectures/Lec04/Lec04.html#some-takeaways",
    "title": "PSTAT 100: Lecture 04",
    "section": " Some Takeaways",
    "text": "Some Takeaways\n\nHopefully this mini case study illustrated a few things:\n\nThe beauty (again) of tidy data\nHow we can encode multivariate information into a plot using aesthetics\nHow transformations can mitigate the effects of skew\nHow faceting can be used to overcome “busy” plots\n\nAs another example, we can explore the mtcars dataset (which is one of the datasets that comes pre-installed with R)\n\nCollected in 1974 by the Motor Trend US magazine, this dataset contains information on 32 different automobiles (including things like miles per gallon, number of cylinders, gross horsepower, etc.)"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#mtcars",
    "href": "Lectures/Lec04/Lec04.html#mtcars",
    "title": "PSTAT 100: Lecture 04",
    "section": " mtcars",
    "text": "mtcars\nCheck Your Understanding\n\n\n\n\n\n\n\n\n\n\n\n\n\nHow many variables are being compared?\nWhat aesthetic is each mapped to?"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#principles-of-good-visualization",
    "href": "Lectures/Lec04/Lec04.html#principles-of-good-visualization",
    "title": "PSTAT 100: Lecture 04",
    "section": " Principles of Good Visualization",
    "text": "Principles of Good Visualization\nSetting Goals\n\nWhen setting out to make a plot, it’s important to be intentional about our goals.\nThere are two main types of plots: exploratory, and presentation-quality.\n\n\n\nExploratoryPresentation-Quality\n\n\n\n\nSummarize trends/patterns before performing more sophisticated statistical analyses\nDetails not too important; quantity over quality\n\n\n\n\n\n\nHighly curated for maximal impact and understandability\nCurate for communication; quality over quantity"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#principles-of-good-visualizations",
    "href": "Lectures/Lec04/Lec04.html#principles-of-good-visualizations",
    "title": "PSTAT 100: Lecture 04",
    "section": " Principles of Good Visualizations",
    "text": "Principles of Good Visualizations\nTips and Tricks\nHere are some tips I’ve found useful when crafting visualizations\n\n\n\nKeep things simple. You can (and in many cases should) try to communicate as much information as is effective. But, don’t take it to an extreme.\n\n\n\n\n\n3D-Styling is almost NEVER effective. As neat and “cool” as 3D barplots might be, the 3D-styling elements often obfuscate the plot’s true meaning\n\n\n\n\n\nBeware of Scales and Areas. We;ll talk about this one more in a bit - spoiler alert, pie charts are a notoriously bad graphic!"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#principles-of-good-visualizations-1",
    "href": "Lectures/Lec04/Lec04.html#principles-of-good-visualizations-1",
    "title": "PSTAT 100: Lecture 04",
    "section": " Principles of Good Visualizations",
    "text": "Principles of Good Visualizations\nTips and Tricks\n\n\nLabel Axes, and Title your Plots. This one should (hopefully) be self-explanatory, but make sure you are using descriptive (but not overly complex) labels for your axes, and make sure your plots are titled.\n\n\nInterpret your plots. All too often I see “floating” plots - that is, figures that appear mysteriously and suddenly with no explanation whatsoever. No matter how self-explanatory you think your plot is, make sure you actively describe it and its conclusions somewhere in your report."
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#color-scales",
    "href": "Lectures/Lec04/Lec04.html#color-scales",
    "title": "PSTAT 100: Lecture 04",
    "section": " Color Scales",
    "text": "Color Scales\nQualitative\n\nThere are three main types of color scales: qualitative, sequential, and diverging.\nColors in a qualitative scale are meant to look visually different from one another, with no order, while still being “equal”.\n\nGood when trying to color according to a categorial (i.e. qualitative) variable"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#color-scales-1",
    "href": "Lectures/Lec04/Lec04.html#color-scales-1",
    "title": "PSTAT 100: Lecture 04",
    "section": " Color Scales",
    "text": "Color Scales\nQualitative Color Scale\n\nSource: Fundamentals of Data Visualization, by Claus Wilke"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#color-scales-2",
    "href": "Lectures/Lec04/Lec04.html#color-scales-2",
    "title": "PSTAT 100: Lecture 04",
    "section": " Color Scales",
    "text": "Color Scales\nSequential\n\nA sequential color scale ranges from light to dark (or dark to light).\nColors in a sequential scale are designed to convey an ordering, or hierarchy of values.\n\nUse when there is a natural direction, but not necessarily a meaningful “middle point”\nCan be based on a single hue, or across multiple hues\nMore akin to what we colloquially call “gradients”"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#color-scales-3",
    "href": "Lectures/Lec04/Lec04.html#color-scales-3",
    "title": "PSTAT 100: Lecture 04",
    "section": " Color Scales",
    "text": "Color Scales\nSequential Color Scale\n\nSource: Fundamentals of Data Visualization, by Claus Wilke"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#color-scales-4",
    "href": "Lectures/Lec04/Lec04.html#color-scales-4",
    "title": "PSTAT 100: Lecture 04",
    "section": " Color Scales",
    "text": "Color Scales\nDiverging Color Scale\n\nColors in a diverging scale are designed to convey an ordering, or hierarchy of values in two directions (positive or negative)\n\nAccomplished by effectively “stitching” together two sequential scales at a common, neutral midpoint.\nBy construction, the midpoint is naturally highlighted so only use a diverging scale if there is a natural middle point (or if you want to highlight the two extremes)."
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#color-scales-5",
    "href": "Lectures/Lec04/Lec04.html#color-scales-5",
    "title": "PSTAT 100: Lecture 04",
    "section": " Color Scales",
    "text": "Color Scales\nDiverging Color Scale\n\nSource: Fundamentals of Data Visualization, by Claus Wilke"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#color-scales-6",
    "href": "Lectures/Lec04/Lec04.html#color-scales-6",
    "title": "PSTAT 100: Lecture 04",
    "section": " Color Scales",
    "text": "Color Scales\n\nSource: Fundamentals of Data Visualization, by Claus Wilke"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#color-scales-7",
    "href": "Lectures/Lec04/Lec04.html#color-scales-7",
    "title": "PSTAT 100: Lecture 04",
    "section": " Color Scales",
    "text": "Color Scales\n\nSource: Fundamentals of Data Visualization, by Claus Wilke"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#your-turn",
    "href": "Lectures/Lec04/Lec04.html#your-turn",
    "title": "PSTAT 100: Lecture 04",
    "section": " Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nYour Turn!\n\n\nSuppose we want to use color to encode information about the following variables. Identify the scale/s that is/are most appropriate.\n\n\nDistinguishing between different Majors\nDistinguishing between different unemployment rates (i.e. on a map)\nDistinguishing between different countries’ GDPs, and highlighting a change that occurs as GDP increases.\n\n\n\n\n\n\n\n\n−+\n03:00"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#cvd-and-accessibility",
    "href": "Lectures/Lec04/Lec04.html#cvd-and-accessibility",
    "title": "PSTAT 100: Lecture 04",
    "section": " CVD and Accessibility",
    "text": "CVD and Accessibility\n\nEspecially when it comes to presentation-oriented graphics, accessibility is key.\nOne thing to keep in mind that many readers may suffer from Color-Vision Deficiency (CVD; aka colorblindness), and may not be able to easily perceive differences in colors.\n\nDeuteranomaly: difficulty perceiving green\nProtanomaly: difficulty perceiving red\nTritanomaly: difficulty perceiving blue\n\n\n\n\n\n\n\n\n\nTrichromatic persons (i.e. people with no colorblindness) possess all three retinal cone cell types (and have cone cell types that function “as expected”, and are therefore able to process and perceive red, green, and blue light\n\nImage Source: https://www.aao.org/eye-health/anatomy/cones"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#cvd-and-accessibility-1",
    "href": "Lectures/Lec04/Lec04.html#cvd-and-accessibility-1",
    "title": "PSTAT 100: Lecture 04",
    "section": " CVD and Accessibility",
    "text": "CVD and Accessibility"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#cvd-and-accessibility-2",
    "href": "Lectures/Lec04/Lec04.html#cvd-and-accessibility-2",
    "title": "PSTAT 100: Lecture 04",
    "section": " CVD and Accessibility",
    "text": "CVD and Accessibility"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#cvd-and-accessibility-3",
    "href": "Lectures/Lec04/Lec04.html#cvd-and-accessibility-3",
    "title": "PSTAT 100: Lecture 04",
    "section": " CVD and Accessibility",
    "text": "CVD and Accessibility\nThe Okabe-Ito Palette\n\n\n\npalette.colors(palette = \"Okabe-Ito\")\n\n[1] \"#000000\" \"#E69F00\" \"#56B4E9\" \"#009E73\" \"#F0E442\" \"#0072B2\" \"#D55E00\"\n[8] \"#CC79A7\" \"#999999\"\n\n\n\n\nAnother resource: https://www.color-blindness.com/coblis-color-blindness-simulator/"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#interlude",
    "href": "Lectures/Lec04/Lec04.html#interlude",
    "title": "PSTAT 100: Lecture 04",
    "section": " Interlude",
    "text": "Interlude\nColor Specification Schemes\n\nA quick interlude- some of you may be wondering what all these codes and hashtags mean.\nThere are a few different color specification schemes (i.e. ways to express colors in a more rigorous manner).\nRGB: “Red Green Blue”. Represents each color as a triple of values (between 0 and 255), specifying the amount of Red, Green, and Blue to be included in the hue\n\nE.g. (255, 0, 0): pure red\nE.g. (127, 0, 127): what color would this make?"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#interlude-1",
    "href": "Lectures/Lec04/Lec04.html#interlude-1",
    "title": "PSTAT 100: Lecture 04",
    "section": " Interlude",
    "text": "Interlude\nColor Specification Schemes\n\nNice! But, not always predictable.\n\nRGB specifications can be as few as 3 digits long, or as many as 9 digits long.\n\nThe hexadecimal (more colloquially referred to as hex) color specification scheme also specifies the amount of red, green, and blue in a hue, but does so in six characters.\n\n\n\n\n\n\n\n\nEach digit is written using hexadecimal notation\n\n0 – 9 correspond to our “familiar” values 0 through 9\nA – F correspond to “familiar” (decimal) values 10 through 15."
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#interlude-2",
    "href": "Lectures/Lec04/Lec04.html#interlude-2",
    "title": "PSTAT 100: Lecture 04",
    "section": " Interlude",
    "text": "Interlude\nHex Color Scheme"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#interlude-3",
    "href": "Lectures/Lec04/Lec04.html#interlude-3",
    "title": "PSTAT 100: Lecture 04",
    "section": " Interlude",
    "text": "Interlude\nHex Color Scheme\n\n\nCode\nset.seed(100)    ## for reproducibility\nx &lt;- rnorm(1000)\ndata.frame(x) %&gt;% ggplot(aes(x = x)) +\n  geom_histogram(bins = 13, col = \"white\", fill = \"#dbbae6\") +\n  ggtitle(\"Sample Histogram\") +\n  theme_minimal(base_size = 18)"
  },
  {
    "objectID": "Lectures/Lec04/Lec04.html#next-time",
    "href": "Lectures/Lec04/Lec04.html#next-time",
    "title": "PSTAT 100: Lecture 04",
    "section": " Next Time",
    "text": "Next Time\nAnd Coming Up\n\nOn Monday, we’ll start exploring other (numerical) ways of summarizing data.\nIn lab today, we’ll cover a brief introduction to databases, and ways to combine two or more dataframes together.\nPlease don’t forget to finish Homework 1, which is due 11:59pm this Sunday!!!\n\nYou have all the information needed to complete all the problems now.\nFor the final problem, keep in mind the principles of visualization we talked about today!"
  },
  {
    "objectID": "Pages/Projects/MQP.html",
    "href": "Pages/Projects/MQP.html",
    "title": "Mid-Quarter Project",
    "section": "",
    "text": "As has been stated a few times before, the Mid-Quarter Project this quarter must be submitted in groups. To ensure you have ample time to work on a project as a group, I am asking that you finalize your group members by no later than 11:59 pm on Tuesday July 1, 2025. A corresponding Gradescope assignment has been posted as well.\n Click Here for Further Instructions\n\nWelcome to the PSTAT 100 mid-quarter project! Please keep in mind that projects will be (intentionally) a bit open-ended. This is because most “real-world” data science projects - whether they be in industry or in academia - are also open-ended. Instead of having a set series of questions that can be answered with only one or two methods, project-type questions can often be answered in many different ways, using a variety different techniques.\nSome things to keep in mind:\n\nDon’t try to answer the report questions as a list. Though this report will ask you to answer a series of questions (and you should do your best to answer all of the questions asked of you!), you shouldn’t just list out the answers. Rather, write full sentences, and always justify your answers with references to plots or outputs of code.\nDo NOT include code in your report outside of the appendix. This may seem counterintuitive at first glance, but this is actually a very common practice in report-writing: you should relegate all of your code to an appendix, opting to include only the results in the main body of your report. (Remember that you can always leverage the echo = F option in your code chunks!)\nIt’s okay to Google (as long as you’re honest)! No matter how experienced a data scientist may be, there inevitably comes a time when they will encounter something they don’t know how to do. As such, Google is a data scientist’s best friend! The best way to learn how to do things is to try and figure them out. (Of course, we are always happy to help during Office Hours as well.) All I ask is that, in the Works Cited/References portion of your lab, you please make an indication that you did use Google for something.\nDescribe and interpret ALL graphs and tables. In general, you should never simply generate a graph and/or table and “leave it alone”- all of your graphs, tables, etc. should have some sort of verbal interpretation and/or discussion in your report. For example, what does your graph tell you? How is it that your graph conveys the information that it does?\nEnsure your plots are presentation-quality. This means:\n\nYou should clearly label axes, and ensure your plot and legends have appropriate titles\nYou should carefully consider which (if any) color scales to use."
  },
  {
    "objectID": "Pages/Projects/MQP.html#additional-information-poverty-line",
    "href": "Pages/Projects/MQP.html#additional-information-poverty-line",
    "title": "Mid-Quarter Project",
    "section": "Additional Information: Poverty Line",
    "text": "Additional Information: Poverty Line\nThe United States Department of Health and Human Services (HHS) established the following guidelines for poverty in 2025:\n\nSource: https://aspe.hhs.gov/topics/poverty-economic-mobility/poverty-guidelines\n\n\nPersons in family/household\nPoverty guideline\n\n\n\n\n1\n$15,650\n\n\n2\n$21,150\n\n\n3\n$26,650\n\n\n4\n$32,150\n\n\n5\n$37,650\n\n\n6\n$43,150\n\n\n7\n$48,650\n\n\n8\n$54,150\n\n\n\n\n\n\n\n\n\nAction Item\n\n\n\nGenerate a map that displays the proportion of single households (i.e. households consisting of only one individual) within each state that fall below the above-established poverty line."
  },
  {
    "objectID": "Pages/Projects/MQP.html#part-i-household-level",
    "href": "Pages/Projects/MQP.html#part-i-household-level",
    "title": "Mid-Quarter Project",
    "section": "Part I: Household Level",
    "text": "Part I: Household Level\nIn the first part of the project, we explore various factor at the household level. This means you should only need to use the hhpub24.csv file (and possible the fips_abbrev.csv file as well).\n\nBegin your report with a short paragraph describing what a Core Based Statistical Area (CBSA) is. (The intent is for you to Google - just remember to cite your sources!) Focus on how CBSA codes can be used to identify geographic regions.\nPick three different levels of household incomes. For each level, generate a map that displays the number of households in each state that fall into the selected income level. Comment on any similarities and/or differences between the plots; also comment on how the overall populations of each state might explain any patterns you are seeing.\nGenerate a map that displays the proportion of households within each state that fall below above-established poverty lines. This means households of any size, that fall below the corresponding poverty line; that is, you’ll need to do some aggregations/calculations. Note: the income brackets in the dataset do not correspond perfectly with the above-mentioned guidelines for poverty. It is up to you to decide how you want to address this, however make sure you clearly state how you decided to address this issue.\nDisplay the distribution of different housing types (houses/apartments, mobile homes, student dormitories, etc.) within the Los Angeles-Long Beach-Anaheim and the New York-Newark-Jersey City areas. Comment on any similarities and/or differences. (Hint: How can CBSAs be used to extract information from the relevant geographical regions?)\n\nImportant: The categories on your plots should be descriptively labeled. For instance, you shouldn’t have a bar whose label is just “1” - the labels for the categories should be verbose descriptions like “houses/apartments”, “mobile homes”, etc. To achieve this, consider creating a data frame which converts the id values (1, 2, 3, 4) to their descriptive labels (“houses/apartments”, etc.), and then joining this with your main dataframe.\n\nCompare and contrast the proportion of single individuals living in houses and/or apartments that fall below the poverty line in the Los Angeles-Long Beach-Anaheim and the New York-Newark-Jersey City areas. Be sure to describe how you calculated these percentages, and propose a handful of explanations for any differences/similarities between them.\nAre there any missing values in the dataset? Were any values imputed, and, if so, what proportion of values were imputed?"
  },
  {
    "objectID": "Pages/Projects/MQP.html#part-ii-family-level",
    "href": "Pages/Projects/MQP.html#part-ii-family-level",
    "title": "Mid-Quarter Project",
    "section": "Part II: Family Level",
    "text": "Part II: Family Level\nIn the second part of this project, we explore the data at the family level. Of particular interest to us are the medical-related expenditures\n\nAmong same-sex couples, what is the distribution of families living below and/or above the poverty line? For this problem, use the poverty guidlines established in the FAMLIS variable and not the HHS guidelines from above.\nGenerate a plot that displays differences in the amount different family types (opposite-sex, same-sex, male single, and female single) paid in medical premiums, and comment on any differences/similarities.\n\nImportant: Again, the categories on your plots should be descriptively labeled - don’t use 1, 2, 3, 4, and instead use labels like \"opposite-sex\",\"same-sex\", etc.\n\nWhen it comes to the total amount each family paid in premiums, some values have been imputed. What proportion of values were imputed? What is the distribution of imputation methods? One of the imputation methods is listed as “hotdeck imputation”. Using Google, provide a verbal description of how this imputation method words."
  },
  {
    "objectID": "Pages/Projects/MQP.html#footnotes",
    "href": "Pages/Projects/MQP.html#footnotes",
    "title": "Mid-Quarter Project",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nof or relating to maps↩︎"
  },
  {
    "objectID": "Pages/Info/staff.html",
    "href": "Pages/Info/staff.html",
    "title": "Course Staff",
    "section": "",
    "text": "INSTRUCTOR: Ethan P. Marzban (He/Him)\n\nHello! My name is Ethan P. Marzban (he/him), and I’m currently a PhD student in the Department of Statistics here at UCSB. My current research intersects several sub-fields of statistics, including mathematical statistics, nonparametric statistics, and Bayesian statistics. I’m also passionate about Stats/Data Science Education! In my free time, I enjoy playing the piano, drinking boba, and talking about cats. I’m super excited to be your instructor this quarter!\nEmail: epmarzban@pstat.ucsb.edu\n\n\n\nOffice Hours\nLocation\n\n\n\n\nWednesdays, 3:30 - 4:30 pm\nGirvetz 2123\n\n\nFridays, 9:30 - 10:30 am\nZoom\n\n\n\n\n\nTEACHING ASSISTANT (TA): Erika McPhillips (She/Her)\n\nHello, my name is Erika McPhillips, and I’m a Statistics PhD student. My research focuses on creating and applying Gaussian process machine learning models to spatiotemporal data. I use these methods to make long-term forecasts of climate variables and crop yields, as well as to model magma movement and volcanic eruptions. As a TA, I’ve primarily supported Data Science courses at UCSB, especially the Data Science Capstone, which I’ve been involved with for the past four years. Outside of research and teaching, I enjoy spending time with my friends, family, and cats, working on side NLP projects, and working out at the gym. Feel free to reach out with any questions throughout the course. I’m looking forward to being your TA this summer!\nEmail: elm00@pstat.ucsb.edu\n\n\n\nOffice Hours\nLocation\n\n\n\n\nTuesdays, 4:15 - 5:15 pm\nSouth Hall 2421\n\n\nThursdays, 4:15 - 5:15 pm\nSouth Hall 2421"
  },
  {
    "objectID": "Pages/Lab00/quarto.html",
    "href": "Pages/Lab00/quarto.html",
    "title": "Lab 00: Introduction to Quarto",
    "section": "",
    "text": "# no required packages for this lab\n\n\n\nThis lab covers the following topics:\n\nBasics of Markdown syntax\nBasics of LaTeX syntax\nCode chunk options in .qmd files\n\n\n\n\n\nPortions of Chapter 28 and Chapter 29 in R4DS"
  },
  {
    "objectID": "Pages/Lab00/quarto.html#lab-objectives",
    "href": "Pages/Lab00/quarto.html#lab-objectives",
    "title": "Lab 00: Introduction to Quarto",
    "section": "",
    "text": "This lab covers the following topics:\n\nBasics of Markdown syntax\nBasics of LaTeX syntax\nCode chunk options in .qmd files"
  },
  {
    "objectID": "Pages/Lab00/quarto.html#relevant-textbook-chapterssections",
    "href": "Pages/Lab00/quarto.html#relevant-textbook-chapterssections",
    "title": "Lab 00: Introduction to Quarto",
    "section": "",
    "text": "Portions of Chapter 28 and Chapter 29 in R4DS"
  },
  {
    "objectID": "Pages/solutions.html",
    "href": "Pages/solutions.html",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "",
    "text": "Important\n\n\n\nBelow are solutions to selected assignment. Some things to keep in mind:\n\nThere may be typos, so please proceed with caution (feel free to ask during Office Hours!)\nThere are often many different ways to approach a problem, each of them “correct”! As such, if you work through a problem in a different way than the solutions that’s fine - your way is not necessarily wrong."
  },
  {
    "objectID": "Pages/solutions.html#labs",
    "href": "Pages/solutions.html#labs",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Labs",
    "text": "Labs\n\n\n\nLab01\n\n\n\nLab02"
  },
  {
    "objectID": "Pages/solutions.html#homework",
    "href": "Pages/solutions.html#homework",
    "title": "PSTAT 100: Data Science Concepts and Analysis",
    "section": "Homework",
    "text": "Homework\n\n\n\nHW01"
  }
]